{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on Human Observed Dataset with concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "maxAcc = 0.0\n",
    "maxIter = 0\n",
    "C_Lambda = 0.03 #for regularization of closed form\n",
    "TrainingPercent = 70\n",
    "ValidationPercent = 15\n",
    "TestPercent = 15\n",
    "M = 18 # no of basis function\n",
    "PHI = [] #Matrix for basis function\n",
    "IsSynthetic = False\n",
    "\n",
    "def GetTargetVector(filePath,k):\n",
    "    t = []\n",
    "    with open(filePath, 'rU') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:  \n",
    "            t.append(int(row[k]))\n",
    "    #print(\"Raw Training Generated..\")\n",
    "    return t\n",
    "#append the csv file data in dataMatrix\n",
    "def GenerateRawData(filePath, IsSynthetic,k):    \n",
    "    dataMatrix = [] \n",
    "    with open(filePath, 'rU') as fi:\n",
    "        reader = csv.reader(fi)\n",
    "        for row in reader:\n",
    "            dataRow = []\n",
    "            for column in row[0:k]:\n",
    "\n",
    "                dataRow.append(float(column))\n",
    "            dataMatrix.append(dataRow)   \n",
    "    dataMatrix = np.transpose(dataMatrix)\n",
    "    return dataMatrix\n",
    "\n",
    "def GenerateTrainingTarget(rawTraining,TrainingPercent = 80):\n",
    "    TrainingLen = int(math.ceil(len(rawTraining)*(TrainingPercent*0.01)))\n",
    "    t           = rawTraining[:TrainingLen]\n",
    "    #print(str(TrainingPercent) + \"% Training Target Generated..\")\n",
    "    return t\n",
    "\n",
    "def GenerateTrainingDataMatrix(rawData, TrainingPercent = 80):\n",
    "    T_len = int(math.ceil(len(rawData[0])*0.01*TrainingPercent))\n",
    "    d2 = rawData[:,0:T_len]\n",
    "    #print(str(TrainingPercent) + \"% Training Data Generated..\")\n",
    "    return d2\n",
    "\n",
    "def GenerateValData(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData[0])*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    dataMatrix = rawData[:,TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Data Generated..\")  \n",
    "    return dataMatrix\n",
    "\n",
    "def GenerateValTargetVector(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData)*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    t =rawData[TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Target Data Generated..\")\n",
    "    return t\n",
    "#Big sigma contains variance at the diagonal elements\n",
    "#Big sigma contains variance at the diagonal elements\n",
    "def GenerateBigSigma(Data, MuMatrix,TrainingPercent,IsSynthetic):\n",
    "    print(len(Data)) #rows 41#\n",
    "    print(len(Data[0])) #columns 69k\n",
    "    print(Data.shape)\n",
    "    BigSigma    = np.zeros((len(Data),len(Data)))\n",
    "    DataT       = np.transpose(Data)\n",
    "    print(len(DataT[0]))#column\n",
    "    print(DataT.shape)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))        \n",
    "    varVect     = []\n",
    "    for i in range(0,len(DataT[0])):#all columns of one feature\n",
    "        vct = []\n",
    "        for j in range(0,int(TrainingLen)):\n",
    "            vct.append(Data[i][j])    \n",
    "        varVect.append(np.var(vct))# variance of each feature vector as diagonal\n",
    "    \n",
    "    for j in range(len(Data)):\n",
    "        BigSigma[j][j] = varVect[j]\n",
    "    if IsSynthetic == True:\n",
    "        BigSigma = np.dot(3,BigSigma)\n",
    "    else:\n",
    "        BigSigma = np.dot(200,BigSigma)\n",
    "    ##print (\"BigSigma Generated..\")\n",
    "    return BigSigma\n",
    "\n",
    "def GetScalar(DataRow,MuRow, BigSigInv):#computing exponent function of gaussian basis function\n",
    "    R = np.subtract(DataRow,MuRow)\n",
    "    T = np.dot(BigSigInv,np.transpose(R))  \n",
    "    L = np.dot(R,T)\n",
    "    return L\n",
    "\n",
    "def GetRadialBasisOut(DataRow,MuRow, BigSigInv):    # compute phi matrix\n",
    "    phi_x = math.exp(-0.5*GetScalar(DataRow,MuRow,BigSigInv))\n",
    "    return phi_x\n",
    "\n",
    "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 80):\n",
    "    DataT = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
    "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
    "    BigSigInv = np.linalg.inv(BigSigma)\n",
    "    for  C in range(0,len(MuMatrix)):\n",
    "        for R in range(0,int(TrainingLen)):\n",
    "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
    "    #print (\"PHI Generated..\")\n",
    "    return PHI\n",
    "#Computation of closed form solution to obtain weights\n",
    "def GetWeightsClosedForm(PHI, T, Lambda):\n",
    "    Lambda_I = np.identity(len(PHI[0]))\n",
    "    for i in range(0,len(PHI[0])):\n",
    "        Lambda_I[i][i] = Lambda\n",
    "    PHI_T       = np.transpose(PHI)\n",
    "    PHI_SQR     = np.dot(PHI_T,PHI)\n",
    "    PHI_SQR_LI  = np.add(Lambda_I,PHI_SQR)\n",
    "    PHI_SQR_INV = np.linalg.inv(PHI_SQR_LI)\n",
    "    INTER       = np.dot(PHI_SQR_INV, PHI_T)\n",
    "    W           = np.dot(INTER, T)\n",
    "    ##print (\"Training Weights Generated..\")\n",
    "    return W\n",
    "\n",
    "\n",
    "#For obtaining validation erms , testing erms and training erms\n",
    "def GetValTest(VAL_PHI,W):\n",
    "    Y = np.dot(W,np.transpose(VAL_PHI))\n",
    "    ##print (\"Test Out Generated..\")\n",
    "    return Y\n",
    "#get erms by subtracting actual value - obtained value and then squaring it \n",
    "#and then summing all of them.\n",
    "def GetErms(VAL_TEST_OUT,ValDataAct):\n",
    "    sum = 0.0\n",
    "    t=0\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    val = 0.0\n",
    "    for i in range (0,len(VAL_TEST_OUT)):\n",
    "        sum = sum + math.pow((ValDataAct[i] - VAL_TEST_OUT[i]),2)\n",
    "        if(int(np.around(VAL_TEST_OUT[i], 0)) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(VAL_TEST_OUT)))\n",
    "    ##print (\"Accuracy Generated..\")\n",
    "    ##print (\"Validation E_RMS : \" + str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "    return (str(accuracy) + ',' +  str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: 'U' mode is deprecated\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1109,)\n",
      "(18, 1109)\n",
      "(237,)\n",
      "(18, 237)\n",
      "(237,)\n",
      "(18, 237)\n",
      "18\n",
      "1583\n",
      "(18, 1583)\n",
      "18\n",
      "(1583, 18)\n"
     ]
    }
   ],
   "source": [
    "RawTarget = GetTargetVector('final1600.csv',18)\n",
    "RawData   = GenerateRawData('final1600.csv',IsSynthetic,18)\n",
    "\n",
    "TrainingTarget = np.array(GenerateTrainingTarget(RawTarget,TrainingPercent))\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)\n",
    "print(TrainingTarget.shape)\n",
    "print(TrainingData.shape)\n",
    "\n",
    "ValDataAct = np.array(GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget))))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "TestDataAct = np.array(GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct))))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "\n",
    "ErmsArr = []\n",
    "AccuracyArr = []\n",
    "#In order to get different Mu specify value of M in K- Means\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(np.transpose(TrainingData))\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "BigSigma     = GenerateBigSigma(RawData, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(RawData, Mu, BigSigma, TrainingPercent)\n",
    "W            = GetWeightsClosedForm(TRAINING_PHI,TrainingTarget,(C_Lambda)) \n",
    "\n",
    "TEST_PHI     = GetPhiMatrix(TestData, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(ValData, Mu, BigSigma, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "W_Now        = np.zeros(18) #Randomly intiliaze weight at the beguning\n",
    "\n",
    "La           = 2\n",
    "learningRate = 0.01 #determines the step size for updating weights\n",
    "L_Erms_Val   = []\n",
    "L_Erms_TR    = []\n",
    "L_Erms_Test  = []\n",
    "W_Mat        = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #process of updation of wts acc to stochastic gradient descent solution\n",
    "    #print ('---------Iteration: ' + str(i) + '--------------')\n",
    "    Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),TRAINING_PHI[i])),TRAINING_PHI[i])\n",
    "    La_Delta_E_W  = np.dot(La,W_Now)\n",
    "    Delta_E       = np.add(Delta_E_D,La_Delta_E_W)    \n",
    "    Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "    W_T_Next      = W_Now + Delta_W\n",
    "    W_Now         = W_T_Next\n",
    "    \n",
    "    #-----------------TrainingData Accuracy---------------------#\n",
    "    TR_TEST_OUT   = GetValTest(TRAINING_PHI,W_T_Next) \n",
    "    Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "    L_Erms_TR.append(float(Erms_TR.split(',')[1]))\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "    VAL_TEST_OUT  = GetValTest(VAL_PHI,W_T_Next) \n",
    "    Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "    L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "    TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "    Erms_Test = GetErms(TEST_OUT,TestDataAct)\n",
    "    L_Erms_Test.append(float(Erms_Test.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBIT: abiseria\n",
      "personNo:50291145\n",
      "----------Gradient Descent Solution--------------------\n",
      "M = 18 \n",
      "Lambda  = 0.0001\n",
      "eta=0.003\n",
      "E_rms Training   = 0.49943\n",
      "E_rms Validation = 0.49939\n",
      "E_rms Testing    = 0.49968\n"
     ]
    }
   ],
   "source": [
    "print('UBIT: abiseria')\n",
    "print('personNo:50291145')\n",
    "print ('----------Gradient Descent Solution--------------------')\n",
    "print (\"M = 18 \\nLambda  = 0.0001\\neta=0.003\")\n",
    "print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Human Observed Dataset with concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = np.transpose(TrainingData)\n",
    "wnew = np.zeros(18)\n",
    "b =0 \n",
    "for i in range(1100):\n",
    "    #wnew = np.transpose(wnew)\n",
    "    z = np.dot(np.transpose(wnew),TrainingData[i]) + b\n",
    "    a = 1.0/(1.0+ math.exp(-z))\n",
    "    #wnext = wnew - eta*(a-y)*xi\n",
    "    wnext = wnew - np.dot(learningRate*(a-TrainingTarget[i]),TrainingData[i])\n",
    "    wnew = wnext\n",
    "    \n",
    "    b = b - learningRate*(a - TrainingTarget[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training = 54.36363636363637\n",
      "Accuracy Validation = 48.52320675105485\n",
      "Accuracy Testing = 48.728813559322035\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "def GetValTestLog(VAL_PHI,W):\n",
    "    for i in range(1100):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test.append(a) \n",
    "    return test\n",
    "TR_TEST_OUT   = GetValTestLog(TrainingData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "L_Erms_Val.append(float(Erms_Val.split(',')[0]))\n",
    "#print (\"Accuracy Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print(\"Accuracy Training = \" + str(float(Erms_TR.split(',')[0])))\n",
    "\n",
    "test = []\n",
    "ValData = np.transpose(ValData)\n",
    "def GetValTestLog(VAL_PHI,W):\n",
    "    for i in range(237):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test.append(a) \n",
    "    return test\n",
    "TR_TEST_OUT   = GetValTestLog(ValData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,ValDataAct)\n",
    "L_Erms_Val.append(float(Erms_Val.split(',')[0]))\n",
    "#print (\"Accuracy Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print(\"Accuracy Validation = \" + str(float(Erms_TR.split(',')[0])))\n",
    "\n",
    "test1 = []\n",
    "TestData = np.transpose(TestData)\n",
    "def GetTestLog(VAL_PHI,W):\n",
    "    for i in range(236):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test1.append(a) \n",
    "    return test1\n",
    "TR_TEST_OUT   = GetTestLog(TestData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,TestDataAct)\n",
    "L_Erms_Test.append(float(Erms_Test.split(',')[0]))\n",
    "#print (\"accuracy Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "print(\"Accuracy Testing = \" + str(float(Erms_TR.split(',')[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on Human Observed Dataset using subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: 'U' mode is deprecated\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'U' mode is deprecated\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1265,)\n",
      "(9, 1265)\n",
      "(158,)\n",
      "(9, 158)\n",
      "(158,)\n",
      "(9, 158)\n",
      "9\n",
      "1581\n",
      "(9, 1581)\n",
      "9\n",
      "(1581, 9)\n"
     ]
    }
   ],
   "source": [
    "M = 9\n",
    "RawTarget = GetTargetVector('final_sub.csv',9)\n",
    "RawData   = GenerateRawData('final_sub.csv',IsSynthetic,9)\n",
    "\n",
    "TrainingTarget = np.array(GenerateTrainingTarget(RawTarget,TrainingPercent))\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)\n",
    "print(TrainingTarget.shape)\n",
    "print(TrainingData.shape)\n",
    "\n",
    "ValDataAct = np.array(GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget))))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "TestDataAct = np.array(GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct))))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "\n",
    "ErmsArr = []\n",
    "AccuracyArr = []\n",
    "#In order to get different Mu specify value of M in K- Means\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(np.transpose(TrainingData))\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "BigSigma     = GenerateBigSigma(RawData, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(RawData, Mu, BigSigma, TrainingPercent)\n",
    "W            = GetWeightsClosedForm(TRAINING_PHI,TrainingTarget,(C_Lambda)) \n",
    "\n",
    "TEST_PHI     = GetPhiMatrix(TestData, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(ValData, Mu, BigSigma, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "W_Now        = np.zeros(9) #Randomly intiliaze weight at the beguning\n",
    "print(W_Now)\n",
    "La           = 2\n",
    "learningRate = 0.01 #determines the step size for updating weights\n",
    "L_Erms_Val   = []\n",
    "L_Erms_TR    = []\n",
    "L_Erms_Test  = []\n",
    "W_Mat        = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #process of updation of wts acc to stochastic gradient descent solution\n",
    "    #print ('---------Iteration: ' + str(i) + '--------------')\n",
    "    Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),TRAINING_PHI[i])),TRAINING_PHI[i])\n",
    "    La_Delta_E_W  = np.dot(La,W_Now)\n",
    "    Delta_E       = np.add(Delta_E_D,La_Delta_E_W)    \n",
    "    Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "    W_T_Next      = W_Now + Delta_W\n",
    "    W_Now         = W_T_Next\n",
    "    \n",
    "    #-----------------TrainingData Accuracy---------------------#\n",
    "    TR_TEST_OUT   = GetValTest(TRAINING_PHI,W_T_Next) \n",
    "    Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "    L_Erms_TR.append(float(Erms_TR.split(',')[1]))\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "    VAL_TEST_OUT  = GetValTest(VAL_PHI,W_T_Next) \n",
    "    Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "    L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "    TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "    Erms_Test = GetErms(TEST_OUT,TestDataAct)\n",
    "    L_Erms_Test.append(float(Erms_Test.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Gradient Descent Solution--------------------\n",
      "M = 9 \n",
      "Lambda  = 0.0001\n",
      "eta=0.003\n",
      "E_rms Training   = 0.50008\n",
      "E_rms Validation = 0.49995\n",
      "E_rms Testing    = 0.49511\n"
     ]
    }
   ],
   "source": [
    "print ('----------Gradient Descent Solution--------------------')\n",
    "print (\"M = 9 \\nLambda  = 0.0001\\neta=0.003\")\n",
    "print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on Human Observed Dataset with subtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = np.transpose(TrainingData)\n",
    "wnew = np.zeros(9)\n",
    "b =0 \n",
    "for i in range(1100):\n",
    "    #wnew = np.transpose(wnew)\n",
    "    z = np.dot(np.transpose(wnew),TrainingData[i]) + b\n",
    "    a = 1.0/(1.0+ math.exp(-z))\n",
    "    #wnext = wnew - eta*(a-y)*xi\n",
    "    wnext = wnew - np.dot(learningRate*(a-TrainingTarget[i]),TrainingData[i])\n",
    "    wnew = wnext\n",
    "    \n",
    "    b = b - learningRate*(a - TrainingTarget[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training = 49.18181818181818\n",
      "Accuracy Validation = 49.0\n",
      "Accuracy Testing = 49.0\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "def GetValTestLog(VAL_PHI,W):\n",
    "    for i in range(1100):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test.append(a) \n",
    "    return test\n",
    "TR_TEST_OUT   = GetValTestLog(TrainingData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "L_Erms_Val.append(float(Erms_Val.split(',')[0]))\n",
    "#print (\"Accuracy Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print(\"Accuracy Training = \" + str(float(Erms_TR.split(',')[0])))\n",
    "\n",
    "\n",
    "test = []\n",
    "ValData = np.transpose(ValData)\n",
    "def GetValTestLog(VAL_PHI,W):\n",
    "    for i in range(100):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test.append(a) \n",
    "    return test\n",
    "TR_TEST_OUT   = GetValTestLog(ValData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,ValDataAct)\n",
    "L_Erms_Val.append(float(Erms_Val.split(',')[0]))\n",
    "#print (\"Accuracy Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print(\"Accuracy Validation = \" + str(float(Erms_TR.split(',')[0])))\n",
    "\n",
    "test1 = []\n",
    "TestData = np.transpose(TestData)\n",
    "def GetTestLog(VAL_PHI,W):\n",
    "    for i in range(100):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test1.append(a) \n",
    "    return test1\n",
    "TR_TEST_OUT   = GetTestLog(TestData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,TestDataAct)\n",
    "L_Erms_Test.append(float(Erms_Test.split(',')[0]))\n",
    "#print (\"accuracy Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "print(\"Accuracy Testing = \" + str(float(Erms_TR.split(',')[0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras implementation on Human Observed Dataset with concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/apoorvabisaria/tensorflowml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def processData(dataset):\n",
    "    \n",
    "    # Why do we have to process?  We do not needvindexes, we only need values.\n",
    "    #We are converting the dataset back to array \n",
    "    #for further processing them to binary form\n",
    "    data   = dataset.iloc[:1481,0:18]\n",
    "    labels = dataset.iloc[:1481,18]\n",
    "    #to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "    #processedData  = encodeData(data)\n",
    "    #processedLabel = encodeLabel(labels)\n",
    "    print (data)\n",
    "    print(labels)\n",
    "    return data, labels\n",
    "\n",
    "def testData(dataset):\n",
    "    data   = dataset.iloc[1482:,0:18]\n",
    "    labels = dataset.iloc[1482:,18]\n",
    "    #to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "    #processedData  = encodeData(data)\n",
    "    #processedLabel = encodeLabel(labels)\n",
    "    #print (data)\n",
    "    #print(labels)\n",
    "    return data, labels\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "input_size = 18\n",
    "drop_out = 0.2\n",
    "first_dense_layer_nodes  = 512\n",
    "second_dense_layer = 512\n",
    "second_dense_layer_nodes = 1\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    # Why do we need a model? A model is a core data  srtucture in keras and used to organize layers.\n",
    "    # Why use Dense layer and then activation? We need to tell the system how the model is by specifying input and dense layer size,\n",
    "    #after specifying we apply activation.\n",
    "    # Why use sequential model with layers? sequential model is a linear way of stacking layers, \n",
    "    #where a layer connects just to the next layer. Here we have a fixed souce of input and output.\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    #relu always gives value such that if x<0 it will give 0 otherwise it will give the number itself\n",
    "    #activation function are used to map input to output\n",
    "    \n",
    "    # Why dropout? WE used dropout to avoid overfitting of model\n",
    "    model.add(Dropout(drop_out))\n",
    "    model.add(Dense(second_dense_layer))\n",
    "    model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    # Why Softmax?\n",
    "    # softmax is an activation function used when we are doing classification \n",
    "    #and softmax will give probabilities of various classes involved\n",
    "    model.summary()\n",
    "    \n",
    "    # Why use categorical_crossentropy? We use categorial cross entropy when the target is in categorical format\n",
    "    # Here we are distribuiting the number in 4 categories, thus using categorical crossentropy\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # optimizer allows the internal learnable parameter (weights)to get adjusted.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               9728      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,241\n",
      "Trainable params: 10,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1  1.1  0  3  2  2.1  1.2  3.1  2.2  1.3  1.4  1.5  2.3  0.1  1.6  1.7  \\\n",
      "0     2    1  1  0  2    2    1    2    1    3    1    1    0    2    3    1   \n",
      "1     1    1  1  0  0    2    0    1    2    2    1    1    3    2    2    1   \n",
      "2     3    0  1  3  2    1    0    2    2    2    4    1    3    2    1    1   \n",
      "3     1    1  1  3  2    0    0    0    2    1    0    0    1    0    2    2   \n",
      "4     1    2  1  0  0    2    1    0    2    1    1    1    0    0    3    3   \n",
      "5     1    1  1  1  2    2    0    0    2    2    2    1    0    0    2    0   \n",
      "6     0    1  1  1  2    2    0    4    2    2    1    1    2    2    2    1   \n",
      "7     2    2  1  3  2    2    0    2    2    1    1    2    3    2    2    1   \n",
      "8     2    1  1  0  2    1    0    0    2    2    1    1    3    0    2    1   \n",
      "9     2    1  1  0  2    1    0    0    1    2    0    1    0    0    3    0   \n",
      "10    2    0  1  1  2    2    1    2    1    2    0    1    1    0    2    0   \n",
      "11    3    4  1  3  2    3    1    2    2    3    4    2    2    0    2    1   \n",
      "12    1    2  1  2  2    2    1    0    1    1    2    0    2    0    1    1   \n",
      "13    1    1  1  0  2    2    1    1    2    2    1    1    0    2    2    2   \n",
      "14    3    4  1  0  2    2    0    3    2    2    4    1    3    2    3    1   \n",
      "15    1    0  1  3  2    2    1    4    2    0    1    1    3    2    1    1   \n",
      "16    2    4  1  1  2    1    0    4    2    2    2    1    0    1    2    2   \n",
      "17    1    1  1  0  0    2    1    1    1    2    3    1    0    2    2    0   \n",
      "18    2    4  0  2  2    3    0    3    2    1    1    0    1    0    3    1   \n",
      "19    3    1  1  0  0    3    0    3    2    1    1    0    3    2    1    1   \n",
      "20    3    2  1  0  2    2    0    2    2    3    1    1    2    2    2    1   \n",
      "21    2    2  1  0  0    2    1    1    1    0    4    0    2    0    2    0   \n",
      "22    2    1  1  3  2    3    0    2    2    2    0    1    3    2    3    0   \n",
      "23    2    4  1  2  2    1    0    1    2    3    4    0    2    2    1    1   \n",
      "24    2    0  1  1  0    2    0    0    2    1    0    1    1    2    2    1   \n",
      "25    2    2  1  3  1    2    1    2    2    0    1    1    0    2    1    2   \n",
      "26    1    1  1  0  2    1    0    1    2    3    1    1    3    2    1    0   \n",
      "27    1    0  1  3  2    2    3    1    2    2    1    0    0    2    3    1   \n",
      "28    2    2  1  0  2    2    3    2    2    2    1    1    3    2    2    2   \n",
      "29    1    1  1  0  0    1    1    2    1    0    1    1    0    0    2    2   \n",
      "...  ..  ... .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "1552  1    1  1  2  2    2    1    0    2    3    1    1    0    2    1    1   \n",
      "1553  2    0  1  3  2    1    3    1    2    3    1    1    3    1    3    0   \n",
      "1554  2    4  1  0  2    2    0    4    2    1    4    1    0    2    2    1   \n",
      "1555  0    0  1  3  2    2    0    0    2    1    2    1    2    2    2    1   \n",
      "1556  1    1  1  3  2    3    1    2    1    2    1    0    1    2    3    0   \n",
      "1557  1    1  1  3  0    2    0    1    2    0    4    1    3    2    2    1   \n",
      "1558  2    1  1  3  2    1    1    0    2    1    1    0    1    2    2    2   \n",
      "1559  2    1  1  3  2    1    1    4    2    3    2    1    0    1    2    1   \n",
      "1560  2    0  1  3  2    3    0    4    2    0    0    1    2    2    3    3   \n",
      "1561  0    1  1  3  2    1    1    2    1    1    1    1    0    0    3    3   \n",
      "1562  2    0  1  0  2    1    0    0    2    0    0    1    1    2    1    0   \n",
      "1563  3    4  1  3  2    2    0    1    2    2    1    1    1    2    2    0   \n",
      "1564  2    4  1  0  2    2    3    4    2    1    4    1    1    0    2    0   \n",
      "1565  2    4  1  2  2    1    0    1    2    2    1    2    3    2    3    1   \n",
      "1566  2    4  1  3  2    2    1    2    2    3    4    1    0    2    2    1   \n",
      "1567  3    4  1  0  2    1    0    4    2    0    1    0    2    2    1    1   \n",
      "1568  1    0  1  3  2    2    0    4    2    2    0    1    0    2    3    1   \n",
      "1569  1    1  1  0  0    3    3    4    2    0    0    0    3    2    3    0   \n",
      "1570  1    1  1  0  2    2    1    0    1    1    1    1    1    2    2    1   \n",
      "1571  0    1  0  2  2    3    0    3    2    3    0    0    2    0    3    3   \n",
      "1572  1    1  1  1  2    2    1    0    2    1    1    1    0    2    3    1   \n",
      "1573  3    1  1  3  2    2    2    1    2    2    2    1    3    2    2    2   \n",
      "1574  2    1  1  3  0    2    0    3    2    1    4    1    0    2    2    1   \n",
      "1575  0    1  1  3  2    1    1    2    1    3    4    1    3    2    3    1   \n",
      "1576  2    1  1  0  2    1    1    2    2    2    1    1    1    2    2    3   \n",
      "1577  2    0  1  0  2    1    0    3    2    1    1    0    2    2    2    1   \n",
      "1578  2    0  0  2  2    2    0    4    2    3    1    1    3    3    1    3   \n",
      "1579  2    2  1  3  2    3    0    3    2    3    1    1    3    2    2    2   \n",
      "1580  2    1  1  0  1    2    0    3    2    1    3    1    1    2    2    2   \n",
      "1581  3    0  1  0  2    1    0    3    2    3    2    0    2    2    3    0   \n",
      "\n",
      "      2.4  1.8  0.2  \n",
      "0       2    1    0  \n",
      "1       2    1    1  \n",
      "2       3    2    0  \n",
      "3       2    2    0  \n",
      "4       4    2    0  \n",
      "5       3    2    0  \n",
      "6       4    2    0  \n",
      "7       2    2    1  \n",
      "8       2    1    1  \n",
      "9       3    2    0  \n",
      "10      0    2    0  \n",
      "11      3    2    0  \n",
      "12      1    1    0  \n",
      "13      2    2    0  \n",
      "14      3    2    0  \n",
      "15      2    1    0  \n",
      "16      1    2    0  \n",
      "17      1    2    1  \n",
      "18      0    1    0  \n",
      "19      2    1    1  \n",
      "20      3    2    0  \n",
      "21      4    1    0  \n",
      "22      0    2    0  \n",
      "23      3    2    1  \n",
      "24      1    1    1  \n",
      "25      1    1    1  \n",
      "26      0    2    1  \n",
      "27      1    2    1  \n",
      "28      1    1    1  \n",
      "29      1    1    0  \n",
      "...   ...  ...  ...  \n",
      "1552    3    2    1  \n",
      "1553    1    2    1  \n",
      "1554    2    2    1  \n",
      "1555    0    1    1  \n",
      "1556    2    2    0  \n",
      "1557    0    2    0  \n",
      "1558    2    2    1  \n",
      "1559    3    2    1  \n",
      "1560    0    2    0  \n",
      "1561    4    2    0  \n",
      "1562    1    1    1  \n",
      "1563    1    1    1  \n",
      "1564    0    2    1  \n",
      "1565    2    2    0  \n",
      "1566    1    2    0  \n",
      "1567    4    2    0  \n",
      "1568    4    2    0  \n",
      "1569    3    2    1  \n",
      "1570    4    2    1  \n",
      "1571    0    2    1  \n",
      "1572    4    2    0  \n",
      "1573    0    1    1  \n",
      "1574    2    2    1  \n",
      "1575    3    2    1  \n",
      "1576    2    2    1  \n",
      "1577    0    2    0  \n",
      "1578    1    2    0  \n",
      "1579    1    1    1  \n",
      "1580    0    1    0  \n",
      "1581    4    2    1  \n",
      "\n",
      "[1582 rows x 19 columns]\n",
      "      1  1.1  0  3  2  2.1  1.2  3.1  2.2  1.3  1.4  1.5  2.3  0.1  1.6  1.7  \\\n",
      "0     2    1  1  0  2    2    1    2    1    3    1    1    0    2    3    1   \n",
      "1     1    1  1  0  0    2    0    1    2    2    1    1    3    2    2    1   \n",
      "2     3    0  1  3  2    1    0    2    2    2    4    1    3    2    1    1   \n",
      "3     1    1  1  3  2    0    0    0    2    1    0    0    1    0    2    2   \n",
      "4     1    2  1  0  0    2    1    0    2    1    1    1    0    0    3    3   \n",
      "5     1    1  1  1  2    2    0    0    2    2    2    1    0    0    2    0   \n",
      "6     0    1  1  1  2    2    0    4    2    2    1    1    2    2    2    1   \n",
      "7     2    2  1  3  2    2    0    2    2    1    1    2    3    2    2    1   \n",
      "8     2    1  1  0  2    1    0    0    2    2    1    1    3    0    2    1   \n",
      "9     2    1  1  0  2    1    0    0    1    2    0    1    0    0    3    0   \n",
      "10    2    0  1  1  2    2    1    2    1    2    0    1    1    0    2    0   \n",
      "11    3    4  1  3  2    3    1    2    2    3    4    2    2    0    2    1   \n",
      "12    1    2  1  2  2    2    1    0    1    1    2    0    2    0    1    1   \n",
      "13    1    1  1  0  2    2    1    1    2    2    1    1    0    2    2    2   \n",
      "14    3    4  1  0  2    2    0    3    2    2    4    1    3    2    3    1   \n",
      "15    1    0  1  3  2    2    1    4    2    0    1    1    3    2    1    1   \n",
      "16    2    4  1  1  2    1    0    4    2    2    2    1    0    1    2    2   \n",
      "17    1    1  1  0  0    2    1    1    1    2    3    1    0    2    2    0   \n",
      "18    2    4  0  2  2    3    0    3    2    1    1    0    1    0    3    1   \n",
      "19    3    1  1  0  0    3    0    3    2    1    1    0    3    2    1    1   \n",
      "20    3    2  1  0  2    2    0    2    2    3    1    1    2    2    2    1   \n",
      "21    2    2  1  0  0    2    1    1    1    0    4    0    2    0    2    0   \n",
      "22    2    1  1  3  2    3    0    2    2    2    0    1    3    2    3    0   \n",
      "23    2    4  1  2  2    1    0    1    2    3    4    0    2    2    1    1   \n",
      "24    2    0  1  1  0    2    0    0    2    1    0    1    1    2    2    1   \n",
      "25    2    2  1  3  1    2    1    2    2    0    1    1    0    2    1    2   \n",
      "26    1    1  1  0  2    1    0    1    2    3    1    1    3    2    1    0   \n",
      "27    1    0  1  3  2    2    3    1    2    2    1    0    0    2    3    1   \n",
      "28    2    2  1  0  2    2    3    2    2    2    1    1    3    2    2    2   \n",
      "29    1    1  1  0  0    1    1    2    1    0    1    1    0    0    2    2   \n",
      "...  ..  ... .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "1451  3    1  1  2  2    2    0    1    2    2    0    1    1    2    1    0   \n",
      "1452  1    2  1  1  2    2    0    1    2    1    2    1    0    2    2    1   \n",
      "1453  2    1  1  1  2    1    1    2    1    1    2    1    1    2    3    0   \n",
      "1454  3    1  1  0  2    1    0    3    2    3    1    0    2    2    2    0   \n",
      "1455  2    1  1  1  2    1    0    3    2    1    2    1    3    0    2    1   \n",
      "1456  2    0  0  0  2    1    0    0    2    1    4    0    1    2    2    0   \n",
      "1457  2    1  1  3  0    2    1    2    1    1    0    1    1    2    2    0   \n",
      "1458  0    1  1  0  2    2    3    3    2    1    1    1    1    2    1    3   \n",
      "1459  3    4  1  3  2    2    2    1    2    1    4    0    0    2    3    3   \n",
      "1460  3    4  1  0  2    2    3    4    2    2    1    1    2    0    2    2   \n",
      "1461  0    1  1  2  1    2    1    1    1    1    1    2    4    3    2    1   \n",
      "1462  2    0  1  3  2    2    1    1    2    1    1    1    0    1    2    0   \n",
      "1463  2    1  1  0  2    2    0    3    2    1    1    1    0    2    2    0   \n",
      "1464  1    0  1  0  2    2    0    1    1    2    1    1    0    2    2    2   \n",
      "1465  2    0  1  0  2    2    3    1    2    0    1    0    2    2    3    0   \n",
      "1466  2    1  1  2  0    2    1    0    1    2    0    0    2    2    2    0   \n",
      "1467  2    1  1  0  2    1    1    2    2    1    1    1    3    2    3    3   \n",
      "1468  3    4  1  3  2    2    0    1    2    2    1    0    1    2    3    0   \n",
      "1469  3    0  1  3  2    2    0    3    2    3    4    1    3    2    2    2   \n",
      "1470  2    0  1  1  2    2    3    2    2    1    1    0    1    2    1    0   \n",
      "1471  0    0  1  3  0    1    1    2    1    1    4    0    1    0    2    0   \n",
      "1472  2    1  1  1  0    1    1    2    1    0    2    1    0    0    2    2   \n",
      "1473  1    2  1  0  0    2    1    0    2    1    1    1    3    1    1    3   \n",
      "1474  3    4  1  0  2    2    1    0    2    2    2    1    0    0    2    1   \n",
      "1475  1    0  1  0  2    1    0    0    1    1    1    1    0    2    0    0   \n",
      "1476  3    1  1  3  2    2    2    1    2    0    1    1    1    0    2    0   \n",
      "1477  1    2  1  1  2    3    0    1    2    2    2    1    0    0    2    3   \n",
      "1478  2    0  1  1  2    2    0    4    2    1    4    1    3    2    3    1   \n",
      "1479  3    0  1  0  2    2    0    4    2    3    1    0    2    2    2    0   \n",
      "1480  2    1  0  2  2    2    0    0    2    2    2    1    0    0    2    3   \n",
      "\n",
      "      2.4  1.8  \n",
      "0       2    1  \n",
      "1       2    1  \n",
      "2       3    2  \n",
      "3       2    2  \n",
      "4       4    2  \n",
      "5       3    2  \n",
      "6       4    2  \n",
      "7       2    2  \n",
      "8       2    1  \n",
      "9       3    2  \n",
      "10      0    2  \n",
      "11      3    2  \n",
      "12      1    1  \n",
      "13      2    2  \n",
      "14      3    2  \n",
      "15      2    1  \n",
      "16      1    2  \n",
      "17      1    2  \n",
      "18      0    1  \n",
      "19      2    1  \n",
      "20      3    2  \n",
      "21      4    1  \n",
      "22      0    2  \n",
      "23      3    2  \n",
      "24      1    1  \n",
      "25      1    1  \n",
      "26      0    2  \n",
      "27      1    2  \n",
      "28      1    1  \n",
      "29      1    1  \n",
      "...   ...  ...  \n",
      "1451    1    2  \n",
      "1452    2    1  \n",
      "1453    1    2  \n",
      "1454    2    2  \n",
      "1455    3    2  \n",
      "1456    4    2  \n",
      "1457    2    1  \n",
      "1458    3    2  \n",
      "1459    3    2  \n",
      "1460    0    1  \n",
      "1461    2    1  \n",
      "1462    2    2  \n",
      "1463    1    2  \n",
      "1464    2    1  \n",
      "1465    3    2  \n",
      "1466    4    2  \n",
      "1467    1    2  \n",
      "1468    2    2  \n",
      "1469    1    2  \n",
      "1470    3    2  \n",
      "1471    1    1  \n",
      "1472    2    1  \n",
      "1473    1    2  \n",
      "1474    1    1  \n",
      "1475    3    2  \n",
      "1476    2    1  \n",
      "1477    2    2  \n",
      "1478    2    2  \n",
      "1479    0    2  \n",
      "1480    2    1  \n",
      "\n",
      "[1481 rows x 18 columns]\n",
      "0       0\n",
      "1       1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "5       0\n",
      "6       0\n",
      "7       1\n",
      "8       1\n",
      "9       0\n",
      "10      0\n",
      "11      0\n",
      "12      0\n",
      "13      0\n",
      "14      0\n",
      "15      0\n",
      "16      0\n",
      "17      1\n",
      "18      0\n",
      "19      1\n",
      "20      0\n",
      "21      0\n",
      "22      0\n",
      "23      1\n",
      "24      1\n",
      "25      1\n",
      "26      1\n",
      "27      1\n",
      "28      1\n",
      "29      0\n",
      "       ..\n",
      "1451    0\n",
      "1452    0\n",
      "1453    1\n",
      "1454    0\n",
      "1455    1\n",
      "1456    1\n",
      "1457    1\n",
      "1458    0\n",
      "1459    0\n",
      "1460    0\n",
      "1461    0\n",
      "1462    0\n",
      "1463    1\n",
      "1464    1\n",
      "1465    0\n",
      "1466    1\n",
      "1467    0\n",
      "1468    1\n",
      "1469    0\n",
      "1470    1\n",
      "1471    0\n",
      "1472    0\n",
      "1473    1\n",
      "1474    0\n",
      "1475    1\n",
      "1476    0\n",
      "1477    0\n",
      "1478    0\n",
      "1479    0\n",
      "1480    0\n",
      "Name: 0.2, Length: 1481, dtype: int64\n",
      "Train on 1184 samples, validate on 297 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1100\n",
      "1184/1184 [==============================] - 0s 141us/step - loss: 0.7133 - acc: 0.5177 - val_loss: 0.7077 - val_acc: 0.5152\n",
      "Epoch 2/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6974 - acc: 0.5270 - val_loss: 0.6846 - val_acc: 0.5421\n",
      "Epoch 3/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6861 - acc: 0.5633 - val_loss: 0.7051 - val_acc: 0.5152\n",
      "Epoch 4/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6871 - acc: 0.5389 - val_loss: 0.7136 - val_acc: 0.5118\n",
      "Epoch 5/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6829 - acc: 0.5431 - val_loss: 0.6915 - val_acc: 0.5387\n",
      "Epoch 6/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6730 - acc: 0.5794 - val_loss: 0.6982 - val_acc: 0.5219\n",
      "Epoch 7/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6707 - acc: 0.6149 - val_loss: 0.6829 - val_acc: 0.5455\n",
      "Epoch 8/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6758 - acc: 0.5878 - val_loss: 0.7003 - val_acc: 0.5152\n",
      "Epoch 9/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6714 - acc: 0.5904 - val_loss: 0.6867 - val_acc: 0.5253\n",
      "Epoch 10/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6719 - acc: 0.5861 - val_loss: 0.6822 - val_acc: 0.5522\n",
      "Epoch 11/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6698 - acc: 0.5777 - val_loss: 0.6874 - val_acc: 0.5657\n",
      "Epoch 12/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6618 - acc: 0.6022 - val_loss: 0.7093 - val_acc: 0.5253\n",
      "Epoch 13/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6671 - acc: 0.5912 - val_loss: 0.6921 - val_acc: 0.5354\n",
      "Epoch 14/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6592 - acc: 0.6014 - val_loss: 0.6918 - val_acc: 0.5690\n",
      "Epoch 15/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6546 - acc: 0.6140 - val_loss: 0.6840 - val_acc: 0.5455\n",
      "Epoch 16/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.6712 - acc: 0.5861 - val_loss: 0.6885 - val_acc: 0.5354\n",
      "Epoch 17/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.6510 - acc: 0.6402 - val_loss: 0.7214 - val_acc: 0.5185\n",
      "Epoch 18/1100\n",
      "1184/1184 [==============================] - 0s 29us/step - loss: 0.6533 - acc: 0.6182 - val_loss: 0.7293 - val_acc: 0.5152\n",
      "Epoch 19/1100\n",
      "1184/1184 [==============================] - 0s 29us/step - loss: 0.6593 - acc: 0.6123 - val_loss: 0.7670 - val_acc: 0.5051\n",
      "Epoch 20/1100\n",
      "1184/1184 [==============================] - 0s 34us/step - loss: 0.6555 - acc: 0.6199 - val_loss: 0.6872 - val_acc: 0.5286\n",
      "Epoch 21/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.6439 - acc: 0.6453 - val_loss: 0.6866 - val_acc: 0.5522\n",
      "Epoch 22/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6418 - acc: 0.6309 - val_loss: 0.6880 - val_acc: 0.5185\n",
      "Epoch 23/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6407 - acc: 0.6284 - val_loss: 0.7593 - val_acc: 0.5051\n",
      "Epoch 24/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6509 - acc: 0.6250 - val_loss: 0.7577 - val_acc: 0.5118\n",
      "Epoch 25/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6467 - acc: 0.6199 - val_loss: 0.6957 - val_acc: 0.5253\n",
      "Epoch 26/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6335 - acc: 0.6596 - val_loss: 0.8034 - val_acc: 0.4949\n",
      "Epoch 27/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6420 - acc: 0.6546 - val_loss: 0.7484 - val_acc: 0.5051\n",
      "Epoch 28/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6425 - acc: 0.6301 - val_loss: 0.7062 - val_acc: 0.5219\n",
      "Epoch 29/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6306 - acc: 0.6529 - val_loss: 0.7479 - val_acc: 0.5017\n",
      "Epoch 30/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6278 - acc: 0.6537 - val_loss: 0.6952 - val_acc: 0.5387\n",
      "Epoch 31/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6321 - acc: 0.6360 - val_loss: 0.6954 - val_acc: 0.5051\n",
      "Epoch 32/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6252 - acc: 0.6512 - val_loss: 0.6968 - val_acc: 0.5421\n",
      "Epoch 33/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6305 - acc: 0.6554 - val_loss: 0.6969 - val_acc: 0.5286\n",
      "Epoch 34/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6183 - acc: 0.6715 - val_loss: 0.7164 - val_acc: 0.5387\n",
      "Epoch 35/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6235 - acc: 0.6613 - val_loss: 0.7021 - val_acc: 0.5219\n",
      "Epoch 36/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6173 - acc: 0.6748 - val_loss: 0.7282 - val_acc: 0.5421\n",
      "Epoch 37/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6225 - acc: 0.6520 - val_loss: 0.7366 - val_acc: 0.5253\n",
      "Epoch 38/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6155 - acc: 0.6698 - val_loss: 0.7023 - val_acc: 0.5286\n",
      "Epoch 39/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6119 - acc: 0.6850 - val_loss: 0.7173 - val_acc: 0.5354\n",
      "Epoch 40/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6092 - acc: 0.6774 - val_loss: 0.7027 - val_acc: 0.5320\n",
      "Epoch 41/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6060 - acc: 0.6850 - val_loss: 0.7022 - val_acc: 0.5219\n",
      "Epoch 42/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6045 - acc: 0.6850 - val_loss: 0.7110 - val_acc: 0.5455\n",
      "Epoch 43/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6130 - acc: 0.6588 - val_loss: 0.7720 - val_acc: 0.5219\n",
      "Epoch 44/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6142 - acc: 0.6816 - val_loss: 0.7110 - val_acc: 0.5253\n",
      "Epoch 45/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6030 - acc: 0.6740 - val_loss: 0.7239 - val_acc: 0.5286\n",
      "Epoch 46/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5983 - acc: 0.6926 - val_loss: 0.7418 - val_acc: 0.5455\n",
      "Epoch 47/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5977 - acc: 0.6883 - val_loss: 0.7062 - val_acc: 0.5421\n",
      "Epoch 48/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5907 - acc: 0.6943 - val_loss: 0.7681 - val_acc: 0.5253\n",
      "Epoch 49/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5959 - acc: 0.6765 - val_loss: 0.7104 - val_acc: 0.5185\n",
      "Epoch 50/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.5945 - acc: 0.6943 - val_loss: 0.7343 - val_acc: 0.5253\n",
      "Epoch 51/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.5900 - acc: 0.6926 - val_loss: 0.7183 - val_acc: 0.5185\n",
      "Epoch 52/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.5873 - acc: 0.6968 - val_loss: 0.7398 - val_acc: 0.5455\n",
      "Epoch 53/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5901 - acc: 0.6951 - val_loss: 0.7458 - val_acc: 0.5387\n",
      "Epoch 54/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.5938 - acc: 0.6833 - val_loss: 0.7114 - val_acc: 0.5286\n",
      "Epoch 55/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.5813 - acc: 0.7137 - val_loss: 0.7200 - val_acc: 0.5354\n",
      "Epoch 56/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5781 - acc: 0.7111 - val_loss: 0.7301 - val_acc: 0.5152\n",
      "Epoch 57/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.5848 - acc: 0.6934 - val_loss: 0.8046 - val_acc: 0.5084\n",
      "Epoch 58/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5777 - acc: 0.7061 - val_loss: 0.7196 - val_acc: 0.5219\n",
      "Epoch 59/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5844 - acc: 0.7019 - val_loss: 0.7220 - val_acc: 0.5017\n",
      "Epoch 60/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5687 - acc: 0.7145 - val_loss: 0.7258 - val_acc: 0.5421\n",
      "Epoch 61/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5670 - acc: 0.7019 - val_loss: 0.7235 - val_acc: 0.5084\n",
      "Epoch 62/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5663 - acc: 0.7382 - val_loss: 0.7595 - val_acc: 0.5320\n",
      "Epoch 63/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5633 - acc: 0.7120 - val_loss: 0.7675 - val_acc: 0.5320\n",
      "Epoch 64/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5714 - acc: 0.7095 - val_loss: 0.7770 - val_acc: 0.5320\n",
      "Epoch 65/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5651 - acc: 0.7162 - val_loss: 0.7389 - val_acc: 0.5354\n",
      "Epoch 66/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5542 - acc: 0.7264 - val_loss: 0.7967 - val_acc: 0.4983\n",
      "Epoch 67/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5632 - acc: 0.7255 - val_loss: 0.7283 - val_acc: 0.5219\n",
      "Epoch 68/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5591 - acc: 0.7264 - val_loss: 0.7278 - val_acc: 0.5522\n",
      "Epoch 69/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5458 - acc: 0.7534 - val_loss: 0.8348 - val_acc: 0.4949\n",
      "Epoch 70/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5649 - acc: 0.7280 - val_loss: 0.8104 - val_acc: 0.5185\n",
      "Epoch 71/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.5549 - acc: 0.7331 - val_loss: 0.7587 - val_acc: 0.5253\n",
      "Epoch 72/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.5447 - acc: 0.7441 - val_loss: 0.7542 - val_acc: 0.5253\n",
      "Epoch 73/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.5512 - acc: 0.7289 - val_loss: 0.7274 - val_acc: 0.5219\n",
      "Epoch 74/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.5409 - acc: 0.7373 - val_loss: 0.7714 - val_acc: 0.5118\n",
      "Epoch 75/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.5424 - acc: 0.7348 - val_loss: 0.7476 - val_acc: 0.4916\n",
      "Epoch 76/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.5402 - acc: 0.7424 - val_loss: 0.7339 - val_acc: 0.5219\n",
      "Epoch 77/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5502 - acc: 0.7255 - val_loss: 0.7507 - val_acc: 0.5219\n",
      "Epoch 78/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5362 - acc: 0.7508 - val_loss: 0.7392 - val_acc: 0.5320\n",
      "Epoch 79/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5345 - acc: 0.7500 - val_loss: 0.8258 - val_acc: 0.5219\n",
      "Epoch 80/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.5488 - acc: 0.7272 - val_loss: 0.8127 - val_acc: 0.5354\n",
      "Epoch 81/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5310 - acc: 0.7559 - val_loss: 0.7510 - val_acc: 0.5421\n",
      "Epoch 82/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5325 - acc: 0.7551 - val_loss: 0.7394 - val_acc: 0.5320\n",
      "Epoch 83/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5241 - acc: 0.7593 - val_loss: 0.7813 - val_acc: 0.5185\n",
      "Epoch 84/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.5436 - acc: 0.7314 - val_loss: 0.7378 - val_acc: 0.5354\n",
      "Epoch 85/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5242 - acc: 0.7551 - val_loss: 0.7575 - val_acc: 0.5421\n",
      "Epoch 86/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.5255 - acc: 0.7568 - val_loss: 0.7908 - val_acc: 0.5253\n",
      "Epoch 87/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5322 - acc: 0.7340 - val_loss: 0.8398 - val_acc: 0.5219\n",
      "Epoch 88/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5194 - acc: 0.7652 - val_loss: 0.7704 - val_acc: 0.5522\n",
      "Epoch 89/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5159 - acc: 0.7475 - val_loss: 0.7498 - val_acc: 0.5152\n",
      "Epoch 90/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5296 - acc: 0.7323 - val_loss: 0.7913 - val_acc: 0.5320\n",
      "Epoch 91/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5348 - acc: 0.7221 - val_loss: 0.7464 - val_acc: 0.5219\n",
      "Epoch 92/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5090 - acc: 0.7736 - val_loss: 0.7595 - val_acc: 0.5320\n",
      "Epoch 93/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.5082 - acc: 0.7720 - val_loss: 0.7631 - val_acc: 0.5219\n",
      "Epoch 94/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5153 - acc: 0.7525 - val_loss: 0.7607 - val_acc: 0.5152\n",
      "Epoch 95/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.5095 - acc: 0.7677 - val_loss: 0.7530 - val_acc: 0.5219\n",
      "Epoch 96/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.5054 - acc: 0.7720 - val_loss: 0.7831 - val_acc: 0.5387\n",
      "Epoch 97/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5262 - acc: 0.7458 - val_loss: 0.7497 - val_acc: 0.5017\n",
      "Epoch 98/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4945 - acc: 0.7897 - val_loss: 0.7782 - val_acc: 0.5118\n",
      "Epoch 99/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4973 - acc: 0.7956 - val_loss: 0.8281 - val_acc: 0.5320\n",
      "Epoch 100/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.5200 - acc: 0.7399 - val_loss: 0.7552 - val_acc: 0.5051\n",
      "Epoch 101/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4928 - acc: 0.7736 - val_loss: 0.7533 - val_acc: 0.5253\n",
      "Epoch 102/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4956 - acc: 0.7812 - val_loss: 0.8255 - val_acc: 0.5017\n",
      "Epoch 103/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4985 - acc: 0.7652 - val_loss: 0.8074 - val_acc: 0.5354\n",
      "Epoch 104/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4985 - acc: 0.7627 - val_loss: 0.8038 - val_acc: 0.5253\n",
      "Epoch 105/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4925 - acc: 0.7745 - val_loss: 0.7739 - val_acc: 0.5286\n",
      "Epoch 106/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4846 - acc: 0.7939 - val_loss: 0.7690 - val_acc: 0.5286\n",
      "Epoch 107/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5019 - acc: 0.7576 - val_loss: 0.8142 - val_acc: 0.5253\n",
      "Epoch 108/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4807 - acc: 0.7914 - val_loss: 0.8072 - val_acc: 0.5219\n",
      "Epoch 109/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4874 - acc: 0.7838 - val_loss: 0.7572 - val_acc: 0.5286\n",
      "Epoch 110/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4999 - acc: 0.7627 - val_loss: 0.7555 - val_acc: 0.5051\n",
      "Epoch 111/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4764 - acc: 0.7931 - val_loss: 0.7559 - val_acc: 0.5320\n",
      "Epoch 112/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4698 - acc: 0.8100 - val_loss: 0.7859 - val_acc: 0.5219\n",
      "Epoch 113/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4975 - acc: 0.7534 - val_loss: 0.7750 - val_acc: 0.5623\n",
      "Epoch 114/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4729 - acc: 0.7998 - val_loss: 0.7823 - val_acc: 0.4949\n",
      "Epoch 115/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4727 - acc: 0.7889 - val_loss: 0.7875 - val_acc: 0.4916\n",
      "Epoch 116/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4837 - acc: 0.7753 - val_loss: 0.7912 - val_acc: 0.5589\n",
      "Epoch 117/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4603 - acc: 0.8108 - val_loss: 0.7874 - val_acc: 0.5253\n",
      "Epoch 118/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4771 - acc: 0.7863 - val_loss: 0.7988 - val_acc: 0.5455\n",
      "Epoch 119/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4698 - acc: 0.7863 - val_loss: 0.7846 - val_acc: 0.5152\n",
      "Epoch 120/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4728 - acc: 0.7956 - val_loss: 0.7725 - val_acc: 0.5286\n",
      "Epoch 121/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4607 - acc: 0.8024 - val_loss: 0.7741 - val_acc: 0.5051\n",
      "Epoch 122/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4772 - acc: 0.7787 - val_loss: 0.8179 - val_acc: 0.5185\n",
      "Epoch 123/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4619 - acc: 0.8074 - val_loss: 0.8207 - val_acc: 0.5185\n",
      "Epoch 124/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4668 - acc: 0.7931 - val_loss: 0.7714 - val_acc: 0.5084\n",
      "Epoch 125/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4669 - acc: 0.7990 - val_loss: 0.8046 - val_acc: 0.5051\n",
      "Epoch 126/1100\n",
      "1184/1184 [==============================] - 0s 28us/step - loss: 0.4530 - acc: 0.8083 - val_loss: 0.8045 - val_acc: 0.5387\n",
      "Epoch 127/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.4483 - acc: 0.8167 - val_loss: 0.8141 - val_acc: 0.5286\n",
      "Epoch 128/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4743 - acc: 0.7779 - val_loss: 0.7751 - val_acc: 0.5219\n",
      "Epoch 129/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4487 - acc: 0.8176 - val_loss: 0.7921 - val_acc: 0.5084\n",
      "Epoch 130/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4415 - acc: 0.8235 - val_loss: 0.7671 - val_acc: 0.5152\n",
      "Epoch 131/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4542 - acc: 0.8049 - val_loss: 0.7847 - val_acc: 0.5421\n",
      "Epoch 132/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4359 - acc: 0.8260 - val_loss: 0.7760 - val_acc: 0.5219\n",
      "Epoch 133/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4694 - acc: 0.7779 - val_loss: 0.7830 - val_acc: 0.5051\n",
      "Epoch 134/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4425 - acc: 0.8218 - val_loss: 0.7937 - val_acc: 0.5219\n",
      "Epoch 135/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4324 - acc: 0.8294 - val_loss: 0.8040 - val_acc: 0.5152\n",
      "Epoch 136/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4359 - acc: 0.8277 - val_loss: 0.8076 - val_acc: 0.5152\n",
      "Epoch 137/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4488 - acc: 0.8007 - val_loss: 0.8210 - val_acc: 0.5185\n",
      "Epoch 138/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4430 - acc: 0.8091 - val_loss: 0.8248 - val_acc: 0.5455\n",
      "Epoch 139/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4318 - acc: 0.8285 - val_loss: 0.7951 - val_acc: 0.5118\n",
      "Epoch 140/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4256 - acc: 0.8319 - val_loss: 0.8000 - val_acc: 0.5253\n",
      "Epoch 141/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4559 - acc: 0.7956 - val_loss: 0.7905 - val_acc: 0.5152\n",
      "Epoch 142/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4351 - acc: 0.8209 - val_loss: 0.8635 - val_acc: 0.5421\n",
      "Epoch 143/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4245 - acc: 0.8429 - val_loss: 0.7895 - val_acc: 0.5051\n",
      "Epoch 144/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4157 - acc: 0.8463 - val_loss: 0.7908 - val_acc: 0.5084\n",
      "Epoch 145/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4298 - acc: 0.8201 - val_loss: 0.7924 - val_acc: 0.5118\n",
      "Epoch 146/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.4130 - acc: 0.8615 - val_loss: 0.8486 - val_acc: 0.5051\n",
      "Epoch 147/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4473 - acc: 0.7897 - val_loss: 0.7996 - val_acc: 0.5084\n",
      "Epoch 148/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4186 - acc: 0.8302 - val_loss: 0.8853 - val_acc: 0.5152\n",
      "Epoch 149/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4418 - acc: 0.8015 - val_loss: 0.7942 - val_acc: 0.5219\n",
      "Epoch 150/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4178 - acc: 0.8454 - val_loss: 0.7987 - val_acc: 0.5084\n",
      "Epoch 151/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4043 - acc: 0.8514 - val_loss: 0.8483 - val_acc: 0.5488\n",
      "Epoch 152/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4328 - acc: 0.8091 - val_loss: 0.8423 - val_acc: 0.5455\n",
      "Epoch 153/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4162 - acc: 0.8378 - val_loss: 0.8460 - val_acc: 0.5219\n",
      "Epoch 154/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4289 - acc: 0.8193 - val_loss: 0.8063 - val_acc: 0.5354\n",
      "Epoch 155/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4049 - acc: 0.8539 - val_loss: 0.8097 - val_acc: 0.5185\n",
      "Epoch 156/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4133 - acc: 0.8412 - val_loss: 0.8348 - val_acc: 0.5488\n",
      "Epoch 157/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4111 - acc: 0.8454 - val_loss: 0.8131 - val_acc: 0.5286\n",
      "Epoch 158/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4176 - acc: 0.8319 - val_loss: 0.8420 - val_acc: 0.5354\n",
      "Epoch 159/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4036 - acc: 0.8454 - val_loss: 0.8449 - val_acc: 0.5152\n",
      "Epoch 160/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4180 - acc: 0.8184 - val_loss: 0.8099 - val_acc: 0.5051\n",
      "Epoch 161/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.3956 - acc: 0.8539 - val_loss: 0.8179 - val_acc: 0.5286\n",
      "Epoch 162/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4173 - acc: 0.8243 - val_loss: 0.8100 - val_acc: 0.5017\n",
      "Epoch 163/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4022 - acc: 0.8530 - val_loss: 0.8983 - val_acc: 0.5118\n",
      "Epoch 164/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4016 - acc: 0.8446 - val_loss: 0.8165 - val_acc: 0.5051\n",
      "Epoch 165/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4107 - acc: 0.8345 - val_loss: 0.8575 - val_acc: 0.5354\n",
      "Epoch 166/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3889 - acc: 0.8606 - val_loss: 0.8258 - val_acc: 0.4983\n",
      "Epoch 167/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3925 - acc: 0.8547 - val_loss: 0.8165 - val_acc: 0.5017\n",
      "Epoch 168/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4191 - acc: 0.8125 - val_loss: 0.8264 - val_acc: 0.5421\n",
      "Epoch 169/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3847 - acc: 0.8657 - val_loss: 0.8155 - val_acc: 0.5219\n",
      "Epoch 170/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3937 - acc: 0.8429 - val_loss: 0.9012 - val_acc: 0.5387\n",
      "Epoch 171/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3969 - acc: 0.8370 - val_loss: 0.8334 - val_acc: 0.5253\n",
      "Epoch 172/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3878 - acc: 0.8581 - val_loss: 0.8240 - val_acc: 0.5185\n",
      "Epoch 173/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3972 - acc: 0.8345 - val_loss: 0.8542 - val_acc: 0.5084\n",
      "Epoch 174/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3776 - acc: 0.8623 - val_loss: 0.8522 - val_acc: 0.5219\n",
      "Epoch 175/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3971 - acc: 0.8421 - val_loss: 0.8229 - val_acc: 0.5152\n",
      "Epoch 176/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3787 - acc: 0.8632 - val_loss: 0.8696 - val_acc: 0.5387\n",
      "Epoch 177/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3797 - acc: 0.8699 - val_loss: 0.8203 - val_acc: 0.5051\n",
      "Epoch 178/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3976 - acc: 0.8463 - val_loss: 0.8215 - val_acc: 0.5286\n",
      "Epoch 179/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3940 - acc: 0.8421 - val_loss: 0.8303 - val_acc: 0.5286\n",
      "Epoch 180/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3706 - acc: 0.8682 - val_loss: 0.8553 - val_acc: 0.5253\n",
      "Epoch 181/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3642 - acc: 0.8750 - val_loss: 0.8396 - val_acc: 0.5118\n",
      "Epoch 182/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3943 - acc: 0.8539 - val_loss: 0.8457 - val_acc: 0.5286\n",
      "Epoch 183/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3685 - acc: 0.8699 - val_loss: 0.8732 - val_acc: 0.5253\n",
      "Epoch 184/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3788 - acc: 0.8691 - val_loss: 0.8450 - val_acc: 0.5152\n",
      "Epoch 185/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.3719 - acc: 0.8606 - val_loss: 0.9416 - val_acc: 0.5354\n",
      "Epoch 186/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3747 - acc: 0.8564 - val_loss: 0.8328 - val_acc: 0.5185\n",
      "Epoch 187/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3837 - acc: 0.8514 - val_loss: 0.8496 - val_acc: 0.5320\n",
      "Epoch 188/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3833 - acc: 0.8446 - val_loss: 0.8895 - val_acc: 0.5387\n",
      "Epoch 189/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3571 - acc: 0.8843 - val_loss: 0.8287 - val_acc: 0.5253\n",
      "Epoch 190/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3481 - acc: 0.8868 - val_loss: 0.8957 - val_acc: 0.5455\n",
      "Epoch 191/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3821 - acc: 0.8454 - val_loss: 0.9387 - val_acc: 0.5387\n",
      "Epoch 192/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3651 - acc: 0.8657 - val_loss: 0.8553 - val_acc: 0.5589\n",
      "Epoch 193/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3698 - acc: 0.8623 - val_loss: 0.8441 - val_acc: 0.5320\n",
      "Epoch 194/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3611 - acc: 0.8767 - val_loss: 0.9218 - val_acc: 0.5219\n",
      "Epoch 195/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3768 - acc: 0.8438 - val_loss: 0.8349 - val_acc: 0.5152\n",
      "Epoch 196/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3460 - acc: 0.8851 - val_loss: 0.8480 - val_acc: 0.5185\n",
      "Epoch 197/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3686 - acc: 0.8623 - val_loss: 0.8879 - val_acc: 0.5185\n",
      "Epoch 198/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3458 - acc: 0.8767 - val_loss: 0.8879 - val_acc: 0.5320\n",
      "Epoch 199/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.3518 - acc: 0.8809 - val_loss: 0.8375 - val_acc: 0.5084\n",
      "Epoch 200/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.3717 - acc: 0.8581 - val_loss: 0.8603 - val_acc: 0.5051\n",
      "Epoch 201/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3569 - acc: 0.8699 - val_loss: 0.8866 - val_acc: 0.5387\n",
      "Epoch 202/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.3430 - acc: 0.8868 - val_loss: 0.8822 - val_acc: 0.5185\n",
      "Epoch 203/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3510 - acc: 0.8674 - val_loss: 0.8749 - val_acc: 0.5320\n",
      "Epoch 204/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3461 - acc: 0.8927 - val_loss: 0.8517 - val_acc: 0.5286\n",
      "Epoch 205/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3593 - acc: 0.8615 - val_loss: 0.8814 - val_acc: 0.5152\n",
      "Epoch 206/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3405 - acc: 0.8910 - val_loss: 0.9221 - val_acc: 0.5421\n",
      "Epoch 207/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3588 - acc: 0.8615 - val_loss: 0.8526 - val_acc: 0.5253\n",
      "Epoch 208/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3512 - acc: 0.8784 - val_loss: 0.8472 - val_acc: 0.5320\n",
      "Epoch 209/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3329 - acc: 0.8953 - val_loss: 0.9017 - val_acc: 0.5185\n",
      "Epoch 210/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3492 - acc: 0.8674 - val_loss: 0.8770 - val_acc: 0.5286\n",
      "Epoch 211/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3360 - acc: 0.8851 - val_loss: 0.8517 - val_acc: 0.5286\n",
      "Epoch 212/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3325 - acc: 0.8910 - val_loss: 0.9663 - val_acc: 0.5152\n",
      "Epoch 213/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3562 - acc: 0.8581 - val_loss: 0.9014 - val_acc: 0.5455\n",
      "Epoch 214/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.3254 - acc: 0.9003 - val_loss: 0.8699 - val_acc: 0.5253\n",
      "Epoch 215/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3531 - acc: 0.8598 - val_loss: 0.8609 - val_acc: 0.5219\n",
      "Epoch 216/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3272 - acc: 0.8944 - val_loss: 0.9262 - val_acc: 0.5387\n",
      "Epoch 217/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3315 - acc: 0.8936 - val_loss: 0.8828 - val_acc: 0.5320\n",
      "Epoch 218/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3503 - acc: 0.8606 - val_loss: 0.9326 - val_acc: 0.5185\n",
      "Epoch 219/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3322 - acc: 0.8818 - val_loss: 0.8591 - val_acc: 0.5253\n",
      "Epoch 220/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3449 - acc: 0.8767 - val_loss: 0.9234 - val_acc: 0.5421\n",
      "Epoch 221/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3233 - acc: 0.8877 - val_loss: 0.9266 - val_acc: 0.5320\n",
      "Epoch 222/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3239 - acc: 0.8885 - val_loss: 0.8748 - val_acc: 0.5152\n",
      "Epoch 223/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3119 - acc: 0.9113 - val_loss: 0.8851 - val_acc: 0.5522\n",
      "Epoch 224/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3279 - acc: 0.8834 - val_loss: 0.8621 - val_acc: 0.5320\n",
      "Epoch 225/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3549 - acc: 0.8480 - val_loss: 0.9361 - val_acc: 0.5354\n",
      "Epoch 226/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3192 - acc: 0.9037 - val_loss: 0.8901 - val_acc: 0.5455\n",
      "Epoch 227/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3091 - acc: 0.9130 - val_loss: 0.8928 - val_acc: 0.5421\n",
      "Epoch 228/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3339 - acc: 0.8699 - val_loss: 0.9313 - val_acc: 0.5185\n",
      "Epoch 229/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3103 - acc: 0.9062 - val_loss: 0.9337 - val_acc: 0.5354\n",
      "Epoch 230/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3350 - acc: 0.8826 - val_loss: 0.9035 - val_acc: 0.5354\n",
      "Epoch 231/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3076 - acc: 0.9029 - val_loss: 0.9925 - val_acc: 0.5455\n",
      "Epoch 232/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3266 - acc: 0.8843 - val_loss: 0.9302 - val_acc: 0.5421\n",
      "Epoch 233/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3216 - acc: 0.8860 - val_loss: 0.9506 - val_acc: 0.5354\n",
      "Epoch 234/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3213 - acc: 0.8818 - val_loss: 0.9037 - val_acc: 0.5421\n",
      "Epoch 235/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3174 - acc: 0.8894 - val_loss: 0.9028 - val_acc: 0.5253\n",
      "Epoch 236/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2995 - acc: 0.9147 - val_loss: 0.9044 - val_acc: 0.5253\n",
      "Epoch 237/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3040 - acc: 0.8986 - val_loss: 0.9156 - val_acc: 0.5421\n",
      "Epoch 238/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.3186 - acc: 0.8834 - val_loss: 0.9204 - val_acc: 0.5286\n",
      "Epoch 239/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3129 - acc: 0.8961 - val_loss: 0.8835 - val_acc: 0.5185\n",
      "Epoch 240/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3133 - acc: 0.8978 - val_loss: 0.8908 - val_acc: 0.5286\n",
      "Epoch 241/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2989 - acc: 0.9054 - val_loss: 0.9148 - val_acc: 0.5286\n",
      "Epoch 242/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3048 - acc: 0.9046 - val_loss: 0.9032 - val_acc: 0.5253\n",
      "Epoch 243/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.3022 - acc: 0.9012 - val_loss: 0.9088 - val_acc: 0.5387\n",
      "Epoch 244/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.3084 - acc: 0.8978 - val_loss: 0.9030 - val_acc: 0.5320\n",
      "Epoch 245/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2981 - acc: 0.9046 - val_loss: 1.0917 - val_acc: 0.5152\n",
      "Epoch 246/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3043 - acc: 0.8953 - val_loss: 0.9033 - val_acc: 0.5253\n",
      "Epoch 247/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2909 - acc: 0.9248 - val_loss: 0.9881 - val_acc: 0.5219\n",
      "Epoch 248/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3102 - acc: 0.8885 - val_loss: 0.9227 - val_acc: 0.5219\n",
      "Epoch 249/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3049 - acc: 0.8995 - val_loss: 0.9820 - val_acc: 0.5185\n",
      "Epoch 250/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2804 - acc: 0.9307 - val_loss: 0.9136 - val_acc: 0.5387\n",
      "Epoch 251/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3027 - acc: 0.8986 - val_loss: 0.9720 - val_acc: 0.5286\n",
      "Epoch 252/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2861 - acc: 0.9147 - val_loss: 0.9148 - val_acc: 0.5354\n",
      "Epoch 253/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3134 - acc: 0.8868 - val_loss: 0.9025 - val_acc: 0.5185\n",
      "Epoch 254/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.2841 - acc: 0.9215 - val_loss: 0.9477 - val_acc: 0.5421\n",
      "Epoch 255/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2881 - acc: 0.9062 - val_loss: 0.9458 - val_acc: 0.5320\n",
      "Epoch 256/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2828 - acc: 0.9130 - val_loss: 0.9523 - val_acc: 0.5253\n",
      "Epoch 257/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2983 - acc: 0.9062 - val_loss: 0.9378 - val_acc: 0.5421\n",
      "Epoch 258/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2846 - acc: 0.9189 - val_loss: 0.9392 - val_acc: 0.5084\n",
      "Epoch 259/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2767 - acc: 0.9316 - val_loss: 0.9171 - val_acc: 0.5354\n",
      "Epoch 260/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3047 - acc: 0.8843 - val_loss: 0.9092 - val_acc: 0.5152\n",
      "Epoch 261/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2910 - acc: 0.9139 - val_loss: 0.9612 - val_acc: 0.5286\n",
      "Epoch 262/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2789 - acc: 0.9155 - val_loss: 0.9179 - val_acc: 0.5320\n",
      "Epoch 263/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.2944 - acc: 0.9003 - val_loss: 0.9247 - val_acc: 0.5286\n",
      "Epoch 264/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2932 - acc: 0.9012 - val_loss: 0.9032 - val_acc: 0.5286\n",
      "Epoch 265/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2756 - acc: 0.9206 - val_loss: 0.9696 - val_acc: 0.5286\n",
      "Epoch 266/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2941 - acc: 0.9046 - val_loss: 0.9678 - val_acc: 0.5421\n",
      "Epoch 267/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2820 - acc: 0.9113 - val_loss: 0.9218 - val_acc: 0.5253\n",
      "Epoch 268/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2893 - acc: 0.8936 - val_loss: 0.9415 - val_acc: 0.5253\n",
      "Epoch 269/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2762 - acc: 0.9113 - val_loss: 0.9312 - val_acc: 0.5387\n",
      "Epoch 270/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2810 - acc: 0.9181 - val_loss: 0.9596 - val_acc: 0.5387\n",
      "Epoch 271/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2609 - acc: 0.9383 - val_loss: 0.9278 - val_acc: 0.5387\n",
      "Epoch 272/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2831 - acc: 0.9105 - val_loss: 0.9216 - val_acc: 0.5320\n",
      "Epoch 273/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2660 - acc: 0.9291 - val_loss: 0.9472 - val_acc: 0.5320\n",
      "Epoch 274/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2818 - acc: 0.9088 - val_loss: 0.9903 - val_acc: 0.5219\n",
      "Epoch 275/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2825 - acc: 0.8995 - val_loss: 0.9336 - val_acc: 0.5387\n",
      "Epoch 276/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2722 - acc: 0.9223 - val_loss: 0.9595 - val_acc: 0.5253\n",
      "Epoch 277/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2710 - acc: 0.9079 - val_loss: 1.0031 - val_acc: 0.5421\n",
      "Epoch 278/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2569 - acc: 0.9324 - val_loss: 0.9174 - val_acc: 0.5219\n",
      "Epoch 279/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2744 - acc: 0.9181 - val_loss: 0.9496 - val_acc: 0.5354\n",
      "Epoch 280/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2778 - acc: 0.9088 - val_loss: 1.0072 - val_acc: 0.5488\n",
      "Epoch 281/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2794 - acc: 0.9164 - val_loss: 0.9244 - val_acc: 0.5354\n",
      "Epoch 282/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2732 - acc: 0.9130 - val_loss: 0.9386 - val_acc: 0.5286\n",
      "Epoch 283/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2707 - acc: 0.9189 - val_loss: 0.9263 - val_acc: 0.5354\n",
      "Epoch 284/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2728 - acc: 0.9105 - val_loss: 0.9311 - val_acc: 0.5455\n",
      "Epoch 285/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2526 - acc: 0.9367 - val_loss: 0.9525 - val_acc: 0.5253\n",
      "Epoch 286/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2559 - acc: 0.9274 - val_loss: 1.1479 - val_acc: 0.5320\n",
      "Epoch 287/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2688 - acc: 0.9206 - val_loss: 0.9550 - val_acc: 0.5455\n",
      "Epoch 288/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2551 - acc: 0.9231 - val_loss: 1.0087 - val_acc: 0.5320\n",
      "Epoch 289/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2588 - acc: 0.9316 - val_loss: 0.9646 - val_acc: 0.5421\n",
      "Epoch 290/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2588 - acc: 0.9240 - val_loss: 0.9671 - val_acc: 0.5354\n",
      "Epoch 291/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2524 - acc: 0.9426 - val_loss: 0.9417 - val_acc: 0.5253\n",
      "Epoch 292/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2390 - acc: 0.9502 - val_loss: 1.0193 - val_acc: 0.5118\n",
      "Epoch 293/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2992 - acc: 0.8699 - val_loss: 0.9792 - val_acc: 0.5421\n",
      "Epoch 294/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2450 - acc: 0.9392 - val_loss: 1.0476 - val_acc: 0.5118\n",
      "Epoch 295/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2522 - acc: 0.9248 - val_loss: 1.0108 - val_acc: 0.5421\n",
      "Epoch 296/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2460 - acc: 0.9400 - val_loss: 0.9639 - val_acc: 0.5488\n",
      "Epoch 297/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2831 - acc: 0.8910 - val_loss: 1.0039 - val_acc: 0.5219\n",
      "Epoch 298/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2438 - acc: 0.9375 - val_loss: 0.9594 - val_acc: 0.5354\n",
      "Epoch 299/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2531 - acc: 0.9291 - val_loss: 0.9625 - val_acc: 0.5387\n",
      "Epoch 300/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2410 - acc: 0.9459 - val_loss: 1.0906 - val_acc: 0.5219\n",
      "Epoch 301/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2664 - acc: 0.9139 - val_loss: 0.9596 - val_acc: 0.5488\n",
      "Epoch 302/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2378 - acc: 0.9434 - val_loss: 0.9704 - val_acc: 0.5253\n",
      "Epoch 303/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2768 - acc: 0.8944 - val_loss: 0.9922 - val_acc: 0.5387\n",
      "Epoch 304/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2299 - acc: 0.9510 - val_loss: 0.9569 - val_acc: 0.5387\n",
      "Epoch 305/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2474 - acc: 0.9324 - val_loss: 1.0481 - val_acc: 0.5152\n",
      "Epoch 306/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2590 - acc: 0.9223 - val_loss: 0.9555 - val_acc: 0.5455\n",
      "Epoch 307/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2275 - acc: 0.9527 - val_loss: 1.0940 - val_acc: 0.5320\n",
      "Epoch 308/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2676 - acc: 0.9105 - val_loss: 1.0056 - val_acc: 0.5354\n",
      "Epoch 309/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2335 - acc: 0.9426 - val_loss: 0.9756 - val_acc: 0.5421\n",
      "Epoch 310/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2408 - acc: 0.9383 - val_loss: 0.9745 - val_acc: 0.5253\n",
      "Epoch 311/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2249 - acc: 0.9485 - val_loss: 0.9819 - val_acc: 0.5320\n",
      "Epoch 312/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2405 - acc: 0.9231 - val_loss: 0.9825 - val_acc: 0.5354\n",
      "Epoch 313/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2546 - acc: 0.9223 - val_loss: 1.0369 - val_acc: 0.5354\n",
      "Epoch 314/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2287 - acc: 0.9426 - val_loss: 0.9675 - val_acc: 0.5387\n",
      "Epoch 315/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2444 - acc: 0.9231 - val_loss: 1.0243 - val_acc: 0.5455\n",
      "Epoch 316/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2267 - acc: 0.9502 - val_loss: 0.9891 - val_acc: 0.5185\n",
      "Epoch 317/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2447 - acc: 0.9248 - val_loss: 0.9818 - val_acc: 0.5253\n",
      "Epoch 318/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2435 - acc: 0.9291 - val_loss: 0.9817 - val_acc: 0.5387\n",
      "Epoch 319/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2349 - acc: 0.9316 - val_loss: 0.9736 - val_acc: 0.5387\n",
      "Epoch 320/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2463 - acc: 0.9198 - val_loss: 1.0358 - val_acc: 0.5051\n",
      "Epoch 321/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2215 - acc: 0.9485 - val_loss: 1.1515 - val_acc: 0.5286\n",
      "Epoch 322/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2358 - acc: 0.9392 - val_loss: 1.0477 - val_acc: 0.5421\n",
      "Epoch 323/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2403 - acc: 0.9307 - val_loss: 1.1163 - val_acc: 0.5286\n",
      "Epoch 324/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2354 - acc: 0.9367 - val_loss: 0.9745 - val_acc: 0.5522\n",
      "Epoch 325/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.2104 - acc: 0.9569 - val_loss: 1.0518 - val_acc: 0.5556\n",
      "Epoch 326/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2385 - acc: 0.9248 - val_loss: 1.0695 - val_acc: 0.5421\n",
      "Epoch 327/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2251 - acc: 0.9400 - val_loss: 1.0507 - val_acc: 0.5286\n",
      "Epoch 328/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.2323 - acc: 0.9299 - val_loss: 1.0180 - val_acc: 0.5556\n",
      "Epoch 329/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2123 - acc: 0.9485 - val_loss: 0.9815 - val_acc: 0.5354\n",
      "Epoch 330/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2474 - acc: 0.9181 - val_loss: 1.0295 - val_acc: 0.5354\n",
      "Epoch 331/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2077 - acc: 0.9620 - val_loss: 1.1314 - val_acc: 0.5488\n",
      "Epoch 332/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2282 - acc: 0.9333 - val_loss: 1.0530 - val_acc: 0.5488\n",
      "Epoch 333/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2423 - acc: 0.9215 - val_loss: 0.9955 - val_acc: 0.5152\n",
      "Epoch 334/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2055 - acc: 0.9611 - val_loss: 1.0152 - val_acc: 0.5455\n",
      "Epoch 335/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2181 - acc: 0.9443 - val_loss: 1.1115 - val_acc: 0.5320\n",
      "Epoch 336/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2331 - acc: 0.9307 - val_loss: 1.1154 - val_acc: 0.5354\n",
      "Epoch 337/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2259 - acc: 0.9282 - val_loss: 1.0055 - val_acc: 0.5455\n",
      "Epoch 338/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2194 - acc: 0.9468 - val_loss: 1.0570 - val_acc: 0.5320\n",
      "Epoch 339/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2014 - acc: 0.9628 - val_loss: 1.0133 - val_acc: 0.5387\n",
      "Epoch 340/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2345 - acc: 0.9181 - val_loss: 1.0059 - val_acc: 0.5488\n",
      "Epoch 341/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.2116 - acc: 0.9510 - val_loss: 1.0792 - val_acc: 0.5320\n",
      "Epoch 342/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.2098 - acc: 0.9434 - val_loss: 1.0066 - val_acc: 0.5354\n",
      "Epoch 343/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1998 - acc: 0.9654 - val_loss: 1.0744 - val_acc: 0.5253\n",
      "Epoch 344/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.2140 - acc: 0.9400 - val_loss: 0.9991 - val_acc: 0.5522\n",
      "Epoch 345/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2017 - acc: 0.9544 - val_loss: 1.0920 - val_acc: 0.5556\n",
      "Epoch 346/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2348 - acc: 0.9248 - val_loss: 1.0298 - val_acc: 0.5286\n",
      "Epoch 347/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2060 - acc: 0.9519 - val_loss: 1.0890 - val_acc: 0.5219\n",
      "Epoch 348/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2209 - acc: 0.9459 - val_loss: 1.0590 - val_acc: 0.5253\n",
      "Epoch 349/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1957 - acc: 0.9611 - val_loss: 1.0513 - val_acc: 0.5253\n",
      "Epoch 350/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2262 - acc: 0.9257 - val_loss: 1.0397 - val_acc: 0.5320\n",
      "Epoch 351/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2014 - acc: 0.9519 - val_loss: 1.0154 - val_acc: 0.5286\n",
      "Epoch 352/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2297 - acc: 0.9215 - val_loss: 1.0148 - val_acc: 0.5522\n",
      "Epoch 353/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1877 - acc: 0.9679 - val_loss: 1.0075 - val_acc: 0.5455\n",
      "Epoch 354/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2233 - acc: 0.9333 - val_loss: 1.0622 - val_acc: 0.5253\n",
      "Epoch 355/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1957 - acc: 0.9654 - val_loss: 1.0407 - val_acc: 0.5387\n",
      "Epoch 356/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2327 - acc: 0.9181 - val_loss: 1.0249 - val_acc: 0.5320\n",
      "Epoch 357/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1862 - acc: 0.9738 - val_loss: 1.0812 - val_acc: 0.5387\n",
      "Epoch 358/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1885 - acc: 0.9628 - val_loss: 1.0729 - val_acc: 0.5354\n",
      "Epoch 359/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2256 - acc: 0.9307 - val_loss: 1.0255 - val_acc: 0.5556\n",
      "Epoch 360/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1902 - acc: 0.9578 - val_loss: 1.0325 - val_acc: 0.5320\n",
      "Epoch 361/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1889 - acc: 0.9620 - val_loss: 1.2509 - val_acc: 0.5152\n",
      "Epoch 362/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2189 - acc: 0.9291 - val_loss: 1.0198 - val_acc: 0.5320\n",
      "Epoch 363/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1877 - acc: 0.9620 - val_loss: 1.0412 - val_acc: 0.5421\n",
      "Epoch 364/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2035 - acc: 0.9400 - val_loss: 1.0380 - val_acc: 0.5455\n",
      "Epoch 365/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2005 - acc: 0.9493 - val_loss: 1.0896 - val_acc: 0.5354\n",
      "Epoch 366/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1842 - acc: 0.9662 - val_loss: 1.0464 - val_acc: 0.5253\n",
      "Epoch 367/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2195 - acc: 0.9324 - val_loss: 1.0259 - val_acc: 0.5253\n",
      "Epoch 368/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1904 - acc: 0.9578 - val_loss: 1.0624 - val_acc: 0.5387\n",
      "Epoch 369/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2075 - acc: 0.9417 - val_loss: 1.1361 - val_acc: 0.5320\n",
      "Epoch 370/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1950 - acc: 0.9535 - val_loss: 1.0776 - val_acc: 0.5488\n",
      "Epoch 371/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1880 - acc: 0.9611 - val_loss: 1.1009 - val_acc: 0.5286\n",
      "Epoch 372/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1883 - acc: 0.9519 - val_loss: 1.0505 - val_acc: 0.5286\n",
      "Epoch 373/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1844 - acc: 0.9645 - val_loss: 1.3043 - val_acc: 0.5320\n",
      "Epoch 374/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2215 - acc: 0.9333 - val_loss: 1.0452 - val_acc: 0.5354\n",
      "Epoch 375/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1722 - acc: 0.9738 - val_loss: 1.0510 - val_acc: 0.5556\n",
      "Epoch 376/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2143 - acc: 0.9333 - val_loss: 1.0523 - val_acc: 0.5320\n",
      "Epoch 377/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1716 - acc: 0.9738 - val_loss: 1.0513 - val_acc: 0.5522\n",
      "Epoch 378/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2034 - acc: 0.9451 - val_loss: 1.0334 - val_acc: 0.5253\n",
      "Epoch 379/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1840 - acc: 0.9611 - val_loss: 1.0475 - val_acc: 0.5421\n",
      "Epoch 380/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1737 - acc: 0.9679 - val_loss: 1.1082 - val_acc: 0.5488\n",
      "Epoch 381/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2088 - acc: 0.9375 - val_loss: 1.0471 - val_acc: 0.5455\n",
      "Epoch 382/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1807 - acc: 0.9595 - val_loss: 1.0957 - val_acc: 0.5387\n",
      "Epoch 383/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1743 - acc: 0.9654 - val_loss: 1.0716 - val_acc: 0.5488\n",
      "Epoch 384/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1987 - acc: 0.9468 - val_loss: 1.0554 - val_acc: 0.5522\n",
      "Epoch 385/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1924 - acc: 0.9544 - val_loss: 1.0775 - val_acc: 0.5387\n",
      "Epoch 386/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1941 - acc: 0.9493 - val_loss: 1.0681 - val_acc: 0.5354\n",
      "Epoch 387/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1768 - acc: 0.9645 - val_loss: 1.0775 - val_acc: 0.5421\n",
      "Epoch 388/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1750 - acc: 0.9662 - val_loss: 1.0771 - val_acc: 0.5320\n",
      "Epoch 389/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1863 - acc: 0.9519 - val_loss: 1.0705 - val_acc: 0.5320\n",
      "Epoch 390/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1924 - acc: 0.9426 - val_loss: 1.0726 - val_acc: 0.5421\n",
      "Epoch 391/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1837 - acc: 0.9569 - val_loss: 1.2138 - val_acc: 0.5421\n",
      "Epoch 392/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.1771 - acc: 0.9637 - val_loss: 1.0744 - val_acc: 0.5286\n",
      "Epoch 393/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1659 - acc: 0.9721 - val_loss: 1.0752 - val_acc: 0.5286\n",
      "Epoch 394/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1878 - acc: 0.9426 - val_loss: 1.0760 - val_acc: 0.5421\n",
      "Epoch 395/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.1572 - acc: 0.9806 - val_loss: 1.0635 - val_acc: 0.5455\n",
      "Epoch 396/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1943 - acc: 0.9434 - val_loss: 1.0795 - val_acc: 0.5387\n",
      "Epoch 397/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1622 - acc: 0.9704 - val_loss: 1.0927 - val_acc: 0.5387\n",
      "Epoch 398/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1760 - acc: 0.9603 - val_loss: 1.1532 - val_acc: 0.5286\n",
      "Epoch 399/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1625 - acc: 0.9713 - val_loss: 1.1029 - val_acc: 0.5219\n",
      "Epoch 400/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.2024 - acc: 0.9434 - val_loss: 1.1093 - val_acc: 0.5522\n",
      "Epoch 401/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.1604 - acc: 0.9730 - val_loss: 1.1371 - val_acc: 0.5387\n",
      "Epoch 402/1100\n",
      "1184/1184 [==============================] - 0s 27us/step - loss: 0.1894 - acc: 0.9367 - val_loss: 1.0715 - val_acc: 0.5320\n",
      "Epoch 403/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1578 - acc: 0.9755 - val_loss: 1.0978 - val_acc: 0.5253\n",
      "Epoch 404/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.1879 - acc: 0.9451 - val_loss: 1.1135 - val_acc: 0.5286\n",
      "Epoch 405/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.1558 - acc: 0.9797 - val_loss: 1.0862 - val_acc: 0.5320\n",
      "Epoch 406/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1834 - acc: 0.9502 - val_loss: 1.0955 - val_acc: 0.5522\n",
      "Epoch 407/1100\n",
      "1184/1184 [==============================] - 0s 30us/step - loss: 0.1520 - acc: 0.9755 - val_loss: 1.0783 - val_acc: 0.5488\n",
      "Epoch 408/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1871 - acc: 0.9502 - val_loss: 1.1280 - val_acc: 0.5354\n",
      "Epoch 409/1100\n",
      "1184/1184 [==============================] - 0s 27us/step - loss: 0.1615 - acc: 0.9637 - val_loss: 1.3596 - val_acc: 0.5152\n",
      "Epoch 410/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1742 - acc: 0.9603 - val_loss: 1.1360 - val_acc: 0.5488\n",
      "Epoch 411/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.1564 - acc: 0.9730 - val_loss: 1.2987 - val_acc: 0.5455\n",
      "Epoch 412/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1875 - acc: 0.9468 - val_loss: 1.2354 - val_acc: 0.5387\n",
      "Epoch 413/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1731 - acc: 0.9578 - val_loss: 1.1038 - val_acc: 0.5556\n",
      "Epoch 414/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1725 - acc: 0.9519 - val_loss: 1.1426 - val_acc: 0.5387\n",
      "Epoch 415/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.1753 - acc: 0.9645 - val_loss: 1.1150 - val_acc: 0.5219\n",
      "Epoch 416/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1439 - acc: 0.9840 - val_loss: 1.2819 - val_acc: 0.5354\n",
      "Epoch 417/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.1842 - acc: 0.9426 - val_loss: 1.2097 - val_acc: 0.5387\n",
      "Epoch 418/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1592 - acc: 0.9688 - val_loss: 1.2257 - val_acc: 0.5387\n",
      "Epoch 419/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1732 - acc: 0.9561 - val_loss: 1.1070 - val_acc: 0.5589\n",
      "Epoch 420/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1735 - acc: 0.9535 - val_loss: 1.1165 - val_acc: 0.5286\n",
      "Epoch 421/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1426 - acc: 0.9789 - val_loss: 1.1039 - val_acc: 0.5421\n",
      "Epoch 422/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.1410 - acc: 0.9797 - val_loss: 1.1397 - val_acc: 0.5589\n",
      "Epoch 423/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2097 - acc: 0.9257 - val_loss: 1.1130 - val_acc: 0.5623\n",
      "Epoch 424/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1424 - acc: 0.9814 - val_loss: 1.0922 - val_acc: 0.5387\n",
      "Epoch 425/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.1780 - acc: 0.9527 - val_loss: 1.1244 - val_acc: 0.5488\n",
      "Epoch 426/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1596 - acc: 0.9713 - val_loss: 1.1083 - val_acc: 0.5455\n",
      "Epoch 427/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1439 - acc: 0.9797 - val_loss: 1.3624 - val_acc: 0.5286\n",
      "Epoch 428/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1771 - acc: 0.9544 - val_loss: 1.1539 - val_acc: 0.5589\n",
      "Epoch 429/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1504 - acc: 0.9789 - val_loss: 1.3989 - val_acc: 0.5421\n",
      "Epoch 430/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1605 - acc: 0.9645 - val_loss: 1.1351 - val_acc: 0.5320\n",
      "Epoch 431/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1527 - acc: 0.9688 - val_loss: 1.1262 - val_acc: 0.5320\n",
      "Epoch 432/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1558 - acc: 0.9645 - val_loss: 1.1310 - val_acc: 0.5253\n",
      "Epoch 433/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1524 - acc: 0.9780 - val_loss: 1.1627 - val_acc: 0.5421\n",
      "Epoch 434/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1471 - acc: 0.9730 - val_loss: 1.1735 - val_acc: 0.5556\n",
      "Epoch 435/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1549 - acc: 0.9738 - val_loss: 1.1691 - val_acc: 0.5455\n",
      "Epoch 436/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1605 - acc: 0.9611 - val_loss: 1.1540 - val_acc: 0.5185\n",
      "Epoch 437/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1390 - acc: 0.9780 - val_loss: 1.1423 - val_acc: 0.5488\n",
      "Epoch 438/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1754 - acc: 0.9561 - val_loss: 1.1353 - val_acc: 0.5320\n",
      "Epoch 439/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1573 - acc: 0.9620 - val_loss: 1.1299 - val_acc: 0.5488\n",
      "Epoch 440/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1314 - acc: 0.9873 - val_loss: 1.1357 - val_acc: 0.5421\n",
      "Epoch 441/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1642 - acc: 0.9603 - val_loss: 1.1311 - val_acc: 0.5455\n",
      "Epoch 442/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1312 - acc: 0.9865 - val_loss: 1.1805 - val_acc: 0.5387\n",
      "Epoch 443/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1667 - acc: 0.9603 - val_loss: 1.1449 - val_acc: 0.5556\n",
      "Epoch 444/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1390 - acc: 0.9797 - val_loss: 1.2880 - val_acc: 0.5589\n",
      "Epoch 445/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1432 - acc: 0.9721 - val_loss: 1.2343 - val_acc: 0.5253\n",
      "Epoch 446/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1323 - acc: 0.9831 - val_loss: 1.3268 - val_acc: 0.5488\n",
      "Epoch 447/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1471 - acc: 0.9704 - val_loss: 1.2983 - val_acc: 0.5354\n",
      "Epoch 448/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1404 - acc: 0.9747 - val_loss: 1.1635 - val_acc: 0.5556\n",
      "Epoch 449/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1391 - acc: 0.9747 - val_loss: 1.1882 - val_acc: 0.5253\n",
      "Epoch 450/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1640 - acc: 0.9620 - val_loss: 1.1791 - val_acc: 0.5253\n",
      "Epoch 451/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1324 - acc: 0.9780 - val_loss: 1.3308 - val_acc: 0.5455\n",
      "Epoch 452/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1453 - acc: 0.9671 - val_loss: 1.1570 - val_acc: 0.5354\n",
      "Epoch 453/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1459 - acc: 0.9721 - val_loss: 1.1497 - val_acc: 0.5320\n",
      "Epoch 454/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1411 - acc: 0.9730 - val_loss: 1.2243 - val_acc: 0.5421\n",
      "Epoch 455/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1534 - acc: 0.9671 - val_loss: 1.1700 - val_acc: 0.5488\n",
      "Epoch 456/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1365 - acc: 0.9764 - val_loss: 1.1693 - val_acc: 0.5556\n",
      "Epoch 457/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1283 - acc: 0.9831 - val_loss: 1.4916 - val_acc: 0.5219\n",
      "Epoch 458/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1559 - acc: 0.9654 - val_loss: 1.1524 - val_acc: 0.5522\n",
      "Epoch 459/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1238 - acc: 0.9840 - val_loss: 1.1580 - val_acc: 0.5623\n",
      "Epoch 460/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1390 - acc: 0.9789 - val_loss: 1.2312 - val_acc: 0.5354\n",
      "Epoch 461/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1502 - acc: 0.9645 - val_loss: 1.1886 - val_acc: 0.5387\n",
      "Epoch 462/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1363 - acc: 0.9806 - val_loss: 1.3543 - val_acc: 0.5589\n",
      "Epoch 463/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1423 - acc: 0.9738 - val_loss: 1.2028 - val_acc: 0.5354\n",
      "Epoch 464/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1311 - acc: 0.9780 - val_loss: 1.1855 - val_acc: 0.5152\n",
      "Epoch 465/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1448 - acc: 0.9696 - val_loss: 1.1579 - val_acc: 0.5387\n",
      "Epoch 466/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1330 - acc: 0.9747 - val_loss: 1.1749 - val_acc: 0.5556\n",
      "Epoch 467/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1193 - acc: 0.9907 - val_loss: 1.3971 - val_acc: 0.5421\n",
      "Epoch 468/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1431 - acc: 0.9671 - val_loss: 1.3155 - val_acc: 0.5354\n",
      "Epoch 469/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1437 - acc: 0.9688 - val_loss: 1.2135 - val_acc: 0.5387\n",
      "Epoch 470/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1613 - acc: 0.9578 - val_loss: 1.2248 - val_acc: 0.5219\n",
      "Epoch 471/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1148 - acc: 0.9916 - val_loss: 1.1790 - val_acc: 0.5488\n",
      "Epoch 472/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1248 - acc: 0.9806 - val_loss: 1.1778 - val_acc: 0.5387\n",
      "Epoch 473/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1440 - acc: 0.9671 - val_loss: 1.2122 - val_acc: 0.5421\n",
      "Epoch 474/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1422 - acc: 0.9654 - val_loss: 1.1943 - val_acc: 0.5455\n",
      "Epoch 475/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1246 - acc: 0.9848 - val_loss: 1.2287 - val_acc: 0.5286\n",
      "Epoch 476/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1310 - acc: 0.9789 - val_loss: 1.2635 - val_acc: 0.5387\n",
      "Epoch 477/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1457 - acc: 0.9730 - val_loss: 1.1910 - val_acc: 0.5354\n",
      "Epoch 478/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1303 - acc: 0.9780 - val_loss: 1.2732 - val_acc: 0.5455\n",
      "Epoch 479/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1318 - acc: 0.9755 - val_loss: 1.2284 - val_acc: 0.5455\n",
      "Epoch 480/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1429 - acc: 0.9696 - val_loss: 1.2755 - val_acc: 0.5387\n",
      "Epoch 481/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1194 - acc: 0.9856 - val_loss: 1.2135 - val_acc: 0.5589\n",
      "Epoch 482/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1358 - acc: 0.9688 - val_loss: 1.1956 - val_acc: 0.5354\n",
      "Epoch 483/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1191 - acc: 0.9823 - val_loss: 1.2917 - val_acc: 0.5286\n",
      "Epoch 484/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1329 - acc: 0.9747 - val_loss: 1.2437 - val_acc: 0.5556\n",
      "Epoch 485/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1225 - acc: 0.9873 - val_loss: 1.2215 - val_acc: 0.5589\n",
      "Epoch 486/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1408 - acc: 0.9713 - val_loss: 1.3028 - val_acc: 0.5421\n",
      "Epoch 487/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1261 - acc: 0.9780 - val_loss: 1.3041 - val_acc: 0.5455\n",
      "Epoch 488/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1144 - acc: 0.9890 - val_loss: 1.2044 - val_acc: 0.5421\n",
      "Epoch 489/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1597 - acc: 0.9535 - val_loss: 1.2138 - val_acc: 0.5421\n",
      "Epoch 490/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1050 - acc: 0.9916 - val_loss: 1.2422 - val_acc: 0.5219\n",
      "Epoch 491/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1447 - acc: 0.9645 - val_loss: 1.2080 - val_acc: 0.5522\n",
      "Epoch 492/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.1085 - acc: 0.9907 - val_loss: 1.2760 - val_acc: 0.5185\n",
      "Epoch 493/1100\n",
      "1184/1184 [==============================] - 0s 29us/step - loss: 0.1299 - acc: 0.9721 - val_loss: 1.2076 - val_acc: 0.5455\n",
      "Epoch 494/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.1266 - acc: 0.9696 - val_loss: 1.2246 - val_acc: 0.5421\n",
      "Epoch 495/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1269 - acc: 0.9747 - val_loss: 1.3409 - val_acc: 0.5589\n",
      "Epoch 496/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1182 - acc: 0.9848 - val_loss: 1.2184 - val_acc: 0.5354\n",
      "Epoch 497/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1123 - acc: 0.9882 - val_loss: 1.2275 - val_acc: 0.5219\n",
      "Epoch 498/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1489 - acc: 0.9620 - val_loss: 1.1906 - val_acc: 0.5354\n",
      "Epoch 499/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1055 - acc: 0.9932 - val_loss: 1.2612 - val_acc: 0.5488\n",
      "Epoch 500/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1342 - acc: 0.9688 - val_loss: 1.2230 - val_acc: 0.5455\n",
      "Epoch 501/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1084 - acc: 0.9882 - val_loss: 1.4709 - val_acc: 0.5354\n",
      "Epoch 502/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1211 - acc: 0.9764 - val_loss: 1.2472 - val_acc: 0.5387\n",
      "Epoch 503/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1282 - acc: 0.9730 - val_loss: 1.2448 - val_acc: 0.5286\n",
      "Epoch 504/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1071 - acc: 0.9899 - val_loss: 1.2371 - val_acc: 0.5455\n",
      "Epoch 505/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1238 - acc: 0.9780 - val_loss: 1.2523 - val_acc: 0.5387\n",
      "Epoch 506/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1223 - acc: 0.9772 - val_loss: 1.2238 - val_acc: 0.5657\n",
      "Epoch 507/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1000 - acc: 0.9949 - val_loss: 1.3483 - val_acc: 0.5488\n",
      "Epoch 508/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1330 - acc: 0.9730 - val_loss: 1.2211 - val_acc: 0.5488\n",
      "Epoch 509/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1171 - acc: 0.9806 - val_loss: 1.2581 - val_acc: 0.5455\n",
      "Epoch 510/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1193 - acc: 0.9814 - val_loss: 1.2419 - val_acc: 0.5421\n",
      "Epoch 511/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0989 - acc: 0.9932 - val_loss: 1.2401 - val_acc: 0.5387\n",
      "Epoch 512/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1421 - acc: 0.9611 - val_loss: 1.2461 - val_acc: 0.5354\n",
      "Epoch 513/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1038 - acc: 0.9890 - val_loss: 1.3699 - val_acc: 0.5354\n",
      "Epoch 514/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1326 - acc: 0.9713 - val_loss: 1.3096 - val_acc: 0.5354\n",
      "Epoch 515/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1030 - acc: 0.9924 - val_loss: 1.4605 - val_acc: 0.5455\n",
      "Epoch 516/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1329 - acc: 0.9738 - val_loss: 1.2444 - val_acc: 0.5421\n",
      "Epoch 517/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0985 - acc: 0.9899 - val_loss: 1.3423 - val_acc: 0.5421\n",
      "Epoch 518/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1301 - acc: 0.9696 - val_loss: 1.2631 - val_acc: 0.5522\n",
      "Epoch 519/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.1316 - acc: 0.9713 - val_loss: 1.2443 - val_acc: 0.5354\n",
      "Epoch 520/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0911 - acc: 0.9932 - val_loss: 1.2590 - val_acc: 0.5354\n",
      "Epoch 521/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1228 - acc: 0.9721 - val_loss: 1.2589 - val_acc: 0.5253\n",
      "Epoch 522/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.1031 - acc: 0.9916 - val_loss: 1.3024 - val_acc: 0.5556\n",
      "Epoch 523/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.1092 - acc: 0.9865 - val_loss: 1.2836 - val_acc: 0.5320\n",
      "Epoch 524/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1385 - acc: 0.9645 - val_loss: 1.2377 - val_acc: 0.5421\n",
      "Epoch 525/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0906 - acc: 0.9949 - val_loss: 1.2570 - val_acc: 0.5488\n",
      "Epoch 526/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1081 - acc: 0.9831 - val_loss: 1.3033 - val_acc: 0.5488\n",
      "Epoch 527/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1166 - acc: 0.9814 - val_loss: 1.2639 - val_acc: 0.5522\n",
      "Epoch 528/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1198 - acc: 0.9755 - val_loss: 1.2508 - val_acc: 0.5522\n",
      "Epoch 529/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0954 - acc: 0.9966 - val_loss: 1.2767 - val_acc: 0.5556\n",
      "Epoch 530/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1380 - acc: 0.9679 - val_loss: 1.3106 - val_acc: 0.5488\n",
      "Epoch 531/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0928 - acc: 0.9916 - val_loss: 1.2547 - val_acc: 0.5421\n",
      "Epoch 532/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1137 - acc: 0.9797 - val_loss: 1.4037 - val_acc: 0.5522\n",
      "Epoch 533/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0972 - acc: 0.9899 - val_loss: 1.2806 - val_acc: 0.5455\n",
      "Epoch 534/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1147 - acc: 0.9831 - val_loss: 1.3006 - val_acc: 0.5320\n",
      "Epoch 535/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1028 - acc: 0.9865 - val_loss: 1.2939 - val_acc: 0.5320\n",
      "Epoch 536/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0939 - acc: 0.9941 - val_loss: 1.2858 - val_acc: 0.5488\n",
      "Epoch 537/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1236 - acc: 0.9704 - val_loss: 1.3168 - val_acc: 0.5589\n",
      "Epoch 538/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0963 - acc: 0.9924 - val_loss: 1.2861 - val_acc: 0.5455\n",
      "Epoch 539/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1197 - acc: 0.9679 - val_loss: 1.2792 - val_acc: 0.5320\n",
      "Epoch 540/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0853 - acc: 0.9992 - val_loss: 1.3168 - val_acc: 0.5118\n",
      "Epoch 541/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1217 - acc: 0.9704 - val_loss: 1.3358 - val_acc: 0.5286\n",
      "Epoch 542/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0884 - acc: 0.9958 - val_loss: 1.3217 - val_acc: 0.5488\n",
      "Epoch 543/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1263 - acc: 0.9662 - val_loss: 1.3017 - val_acc: 0.5522\n",
      "Epoch 544/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0957 - acc: 0.9899 - val_loss: 1.3011 - val_acc: 0.5421\n",
      "Epoch 545/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0843 - acc: 0.9958 - val_loss: 1.4840 - val_acc: 0.5354\n",
      "Epoch 546/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1365 - acc: 0.9535 - val_loss: 1.2854 - val_acc: 0.5556\n",
      "Epoch 547/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0899 - acc: 0.9924 - val_loss: 1.4284 - val_acc: 0.5421\n",
      "Epoch 548/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0992 - acc: 0.9823 - val_loss: 1.3517 - val_acc: 0.5387\n",
      "Epoch 549/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0943 - acc: 0.9916 - val_loss: 1.2995 - val_acc: 0.5556\n",
      "Epoch 550/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1036 - acc: 0.9797 - val_loss: 1.3080 - val_acc: 0.5253\n",
      "Epoch 551/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0952 - acc: 0.9907 - val_loss: 1.3881 - val_acc: 0.5522\n",
      "Epoch 552/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0991 - acc: 0.9848 - val_loss: 1.3847 - val_acc: 0.5488\n",
      "Epoch 553/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1052 - acc: 0.9814 - val_loss: 1.3222 - val_acc: 0.5556\n",
      "Epoch 554/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.1115 - acc: 0.9780 - val_loss: 1.3191 - val_acc: 0.5421\n",
      "Epoch 555/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1032 - acc: 0.9890 - val_loss: 1.3436 - val_acc: 0.5421\n",
      "Epoch 556/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0793 - acc: 0.9966 - val_loss: 1.3292 - val_acc: 0.5286\n",
      "Epoch 557/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1235 - acc: 0.9679 - val_loss: 1.2954 - val_acc: 0.5522\n",
      "Epoch 558/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0806 - acc: 0.9975 - val_loss: 1.3022 - val_acc: 0.5354\n",
      "Epoch 559/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1184 - acc: 0.9696 - val_loss: 1.3766 - val_acc: 0.5421\n",
      "Epoch 560/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0865 - acc: 0.9941 - val_loss: 1.3477 - val_acc: 0.5690\n",
      "Epoch 561/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0830 - acc: 0.9941 - val_loss: 1.3110 - val_acc: 0.5522\n",
      "Epoch 562/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1226 - acc: 0.9595 - val_loss: 1.3080 - val_acc: 0.5354\n",
      "Epoch 563/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0759 - acc: 0.9975 - val_loss: 1.3551 - val_acc: 0.5118\n",
      "Epoch 564/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1095 - acc: 0.9797 - val_loss: 1.3135 - val_acc: 0.5455\n",
      "Epoch 565/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0900 - acc: 0.9932 - val_loss: 1.4212 - val_acc: 0.5286\n",
      "Epoch 566/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0874 - acc: 0.9932 - val_loss: 1.3638 - val_acc: 0.5522\n",
      "Epoch 567/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1037 - acc: 0.9873 - val_loss: 1.3588 - val_acc: 0.5320\n",
      "Epoch 568/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0751 - acc: 0.9983 - val_loss: 1.3474 - val_acc: 0.5320\n",
      "Epoch 569/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1277 - acc: 0.9611 - val_loss: 1.3155 - val_acc: 0.5354\n",
      "Epoch 570/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0816 - acc: 0.9941 - val_loss: 1.3893 - val_acc: 0.5421\n",
      "Epoch 571/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0920 - acc: 0.9865 - val_loss: 1.3118 - val_acc: 0.5387\n",
      "Epoch 572/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1128 - acc: 0.9713 - val_loss: 1.3728 - val_acc: 0.5455\n",
      "Epoch 573/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0784 - acc: 0.9966 - val_loss: 1.3642 - val_acc: 0.5488\n",
      "Epoch 574/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0800 - acc: 0.9958 - val_loss: 1.3599 - val_acc: 0.5286\n",
      "Epoch 575/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1114 - acc: 0.9764 - val_loss: 1.3499 - val_acc: 0.5320\n",
      "Epoch 576/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.0743 - acc: 0.9975 - val_loss: 1.3738 - val_acc: 0.5286\n",
      "Epoch 577/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0914 - acc: 0.9882 - val_loss: 1.3514 - val_acc: 0.5286\n",
      "Epoch 578/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0850 - acc: 0.9899 - val_loss: 1.4888 - val_acc: 0.5488\n",
      "Epoch 579/1100\n",
      "1184/1184 [==============================] - 0s 28us/step - loss: 0.0968 - acc: 0.9848 - val_loss: 1.3484 - val_acc: 0.5455\n",
      "Epoch 580/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.1021 - acc: 0.9814 - val_loss: 1.3300 - val_acc: 0.5421\n",
      "Epoch 581/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0887 - acc: 0.9907 - val_loss: 1.3800 - val_acc: 0.5623\n",
      "Epoch 582/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0830 - acc: 0.9949 - val_loss: 1.4372 - val_acc: 0.5522\n",
      "Epoch 583/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1051 - acc: 0.9755 - val_loss: 1.3629 - val_acc: 0.5455\n",
      "Epoch 584/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0716 - acc: 0.9983 - val_loss: 1.4515 - val_acc: 0.5522\n",
      "Epoch 585/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1161 - acc: 0.9654 - val_loss: 1.3902 - val_acc: 0.5219\n",
      "Epoch 586/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0683 - acc: 1.0000 - val_loss: 1.3890 - val_acc: 0.5522\n",
      "Epoch 587/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1049 - acc: 0.9814 - val_loss: 1.3491 - val_acc: 0.5455\n",
      "Epoch 588/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0686 - acc: 0.9983 - val_loss: 1.4219 - val_acc: 0.5152\n",
      "Epoch 589/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1023 - acc: 0.9738 - val_loss: 1.3588 - val_acc: 0.5522\n",
      "Epoch 590/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0833 - acc: 0.9899 - val_loss: 1.5060 - val_acc: 0.5253\n",
      "Epoch 591/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0828 - acc: 0.9899 - val_loss: 1.3969 - val_acc: 0.5354\n",
      "Epoch 592/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0756 - acc: 0.9949 - val_loss: 1.6087 - val_acc: 0.5354\n",
      "Epoch 593/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1053 - acc: 0.9780 - val_loss: 1.3565 - val_acc: 0.5589\n",
      "Epoch 594/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0796 - acc: 0.9958 - val_loss: 1.3927 - val_acc: 0.5623\n",
      "Epoch 595/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0914 - acc: 0.9882 - val_loss: 1.3966 - val_acc: 0.5354\n",
      "Epoch 596/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0808 - acc: 0.9907 - val_loss: 1.4027 - val_acc: 0.5387\n",
      "Epoch 597/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0789 - acc: 0.9949 - val_loss: 1.3946 - val_acc: 0.5286\n",
      "Epoch 598/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.1082 - acc: 0.9696 - val_loss: 1.3576 - val_acc: 0.5286\n",
      "Epoch 599/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0673 - acc: 0.9983 - val_loss: 1.3930 - val_acc: 0.5387\n",
      "Epoch 600/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0975 - acc: 0.9840 - val_loss: 1.4853 - val_acc: 0.5589\n",
      "Epoch 601/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0777 - acc: 0.9924 - val_loss: 1.3778 - val_acc: 0.5253\n",
      "Epoch 602/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0711 - acc: 0.9958 - val_loss: 1.4302 - val_acc: 0.5455\n",
      "Epoch 603/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0919 - acc: 0.9873 - val_loss: 1.4220 - val_acc: 0.5455\n",
      "Epoch 604/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.1052 - acc: 0.9814 - val_loss: 1.3883 - val_acc: 0.5320\n",
      "Epoch 605/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0640 - acc: 0.9975 - val_loss: 1.3799 - val_acc: 0.5387\n",
      "Epoch 606/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.1009 - acc: 0.9730 - val_loss: 1.4273 - val_acc: 0.5387\n",
      "Epoch 607/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0683 - acc: 0.9983 - val_loss: 1.3956 - val_acc: 0.5286\n",
      "Epoch 608/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0662 - acc: 0.9958 - val_loss: 1.4929 - val_acc: 0.5253\n",
      "Epoch 609/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.1016 - acc: 0.9764 - val_loss: 1.4606 - val_acc: 0.5320\n",
      "Epoch 610/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0702 - acc: 0.9975 - val_loss: 1.4220 - val_acc: 0.5253\n",
      "Epoch 611/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0929 - acc: 0.9856 - val_loss: 1.4455 - val_acc: 0.5354\n",
      "Epoch 612/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0649 - acc: 0.9992 - val_loss: 1.4055 - val_acc: 0.5152\n",
      "Epoch 613/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0764 - acc: 0.9941 - val_loss: 1.4457 - val_acc: 0.5354\n",
      "Epoch 614/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0815 - acc: 0.9916 - val_loss: 1.6581 - val_acc: 0.5522\n",
      "Epoch 615/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0780 - acc: 0.9890 - val_loss: 1.4092 - val_acc: 0.5253\n",
      "Epoch 616/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0860 - acc: 0.9823 - val_loss: 1.6386 - val_acc: 0.5387\n",
      "Epoch 617/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.0748 - acc: 0.9899 - val_loss: 1.4035 - val_acc: 0.5152\n",
      "Epoch 618/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.0608 - acc: 0.9992 - val_loss: 1.4459 - val_acc: 0.5286\n",
      "Epoch 619/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0801 - acc: 0.9949 - val_loss: 1.4524 - val_acc: 0.5286\n",
      "Epoch 620/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0620 - acc: 0.9992 - val_loss: 1.4430 - val_acc: 0.5320\n",
      "Epoch 621/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0877 - acc: 0.9856 - val_loss: 1.4164 - val_acc: 0.5118\n",
      "Epoch 622/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0668 - acc: 0.9966 - val_loss: 1.4303 - val_acc: 0.5253\n",
      "Epoch 623/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0983 - acc: 0.9797 - val_loss: 1.4247 - val_acc: 0.5185\n",
      "Epoch 624/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0599 - acc: 0.9983 - val_loss: 1.4314 - val_acc: 0.5421\n",
      "Epoch 625/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0652 - acc: 0.9966 - val_loss: 1.4147 - val_acc: 0.5421\n",
      "Epoch 626/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0984 - acc: 0.9789 - val_loss: 1.4066 - val_acc: 0.5320\n",
      "Epoch 627/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0604 - acc: 0.9966 - val_loss: 1.4346 - val_acc: 0.5084\n",
      "Epoch 628/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0856 - acc: 0.9797 - val_loss: 1.5917 - val_acc: 0.5421\n",
      "Epoch 629/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0685 - acc: 0.9924 - val_loss: 1.4804 - val_acc: 0.5455\n",
      "Epoch 630/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0680 - acc: 0.9966 - val_loss: 1.4213 - val_acc: 0.5152\n",
      "Epoch 631/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.0843 - acc: 0.9806 - val_loss: 1.4458 - val_acc: 0.5387\n",
      "Epoch 632/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0602 - acc: 0.9983 - val_loss: 1.4887 - val_acc: 0.5522\n",
      "Epoch 633/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0860 - acc: 0.9865 - val_loss: 1.4301 - val_acc: 0.5488\n",
      "Epoch 634/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0627 - acc: 0.9975 - val_loss: 1.4723 - val_acc: 0.5421\n",
      "Epoch 635/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0772 - acc: 0.9873 - val_loss: 1.5006 - val_acc: 0.5387\n",
      "Epoch 636/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0633 - acc: 0.9941 - val_loss: 1.4294 - val_acc: 0.5320\n",
      "Epoch 637/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0698 - acc: 0.9932 - val_loss: 1.4240 - val_acc: 0.5219\n",
      "Epoch 638/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0794 - acc: 0.9899 - val_loss: 1.4425 - val_acc: 0.5320\n",
      "Epoch 639/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0600 - acc: 0.9975 - val_loss: 1.4664 - val_acc: 0.5219\n",
      "Epoch 640/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0741 - acc: 0.9916 - val_loss: 1.4942 - val_acc: 0.5354\n",
      "Epoch 641/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0701 - acc: 0.9941 - val_loss: 1.4530 - val_acc: 0.5253\n",
      "Epoch 642/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0630 - acc: 0.9966 - val_loss: 1.5223 - val_acc: 0.5354\n",
      "Epoch 643/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0697 - acc: 0.9958 - val_loss: 1.4795 - val_acc: 0.5320\n",
      "Epoch 644/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0876 - acc: 0.9856 - val_loss: 1.4820 - val_acc: 0.5690\n",
      "Epoch 645/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0583 - acc: 0.9966 - val_loss: 1.5804 - val_acc: 0.5354\n",
      "Epoch 646/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.0703 - acc: 0.9941 - val_loss: 1.4584 - val_acc: 0.5320\n",
      "Epoch 647/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0565 - acc: 0.9983 - val_loss: 1.6287 - val_acc: 0.5320\n",
      "Epoch 648/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.0943 - acc: 0.9738 - val_loss: 1.4515 - val_acc: 0.5455\n",
      "Epoch 649/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.0579 - acc: 0.9966 - val_loss: 1.4468 - val_acc: 0.5286\n",
      "Epoch 650/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.0807 - acc: 0.9831 - val_loss: 1.5234 - val_acc: 0.5253\n",
      "Epoch 651/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0553 - acc: 1.0000 - val_loss: 1.4599 - val_acc: 0.5152\n",
      "Epoch 652/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0730 - acc: 0.9890 - val_loss: 1.5934 - val_acc: 0.5286\n",
      "Epoch 653/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0626 - acc: 0.9958 - val_loss: 1.4791 - val_acc: 0.5354\n",
      "Epoch 654/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0549 - acc: 0.9983 - val_loss: 1.6403 - val_acc: 0.5387\n",
      "Epoch 655/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.0815 - acc: 0.9882 - val_loss: 1.5347 - val_acc: 0.5320\n",
      "Epoch 656/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0599 - acc: 0.9975 - val_loss: 1.5207 - val_acc: 0.5387\n",
      "Epoch 657/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0886 - acc: 0.9873 - val_loss: 1.4407 - val_acc: 0.5253\n",
      "Epoch 658/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.0511 - acc: 1.0000 - val_loss: 1.4939 - val_acc: 0.5522\n",
      "Epoch 659/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0791 - acc: 0.9856 - val_loss: 1.4348 - val_acc: 0.5421\n",
      "Epoch 660/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0501 - acc: 1.0000 - val_loss: 1.4575 - val_acc: 0.5017\n",
      "Epoch 661/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0865 - acc: 0.9806 - val_loss: 1.4419 - val_acc: 0.5286\n",
      "Epoch 662/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.0524 - acc: 0.9992 - val_loss: 1.4785 - val_acc: 0.5387\n",
      "Epoch 663/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0757 - acc: 0.9907 - val_loss: 1.4662 - val_acc: 0.5455\n",
      "Epoch 664/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0533 - acc: 0.9975 - val_loss: 1.4657 - val_acc: 0.5354\n",
      "Epoch 665/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0691 - acc: 0.9899 - val_loss: 1.4730 - val_acc: 0.5354\n",
      "Epoch 666/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0536 - acc: 0.9992 - val_loss: 1.5848 - val_acc: 0.5421\n",
      "Epoch 667/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0748 - acc: 0.9848 - val_loss: 1.4935 - val_acc: 0.5354\n",
      "Epoch 668/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0495 - acc: 0.9992 - val_loss: 1.5448 - val_acc: 0.5387\n",
      "Epoch 669/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0821 - acc: 0.9848 - val_loss: 1.4867 - val_acc: 0.5253\n",
      "Epoch 670/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0476 - acc: 1.0000 - val_loss: 1.5067 - val_acc: 0.5219\n",
      "Epoch 671/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0879 - acc: 0.9865 - val_loss: 1.4963 - val_acc: 0.5253\n",
      "Epoch 672/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0478 - acc: 1.0000 - val_loss: 1.4921 - val_acc: 0.5286\n",
      "Epoch 673/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0599 - acc: 0.9907 - val_loss: 1.5151 - val_acc: 0.5421\n",
      "Epoch 674/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0520 - acc: 0.9983 - val_loss: 1.5159 - val_acc: 0.5286\n",
      "Epoch 675/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0841 - acc: 0.9780 - val_loss: 1.5002 - val_acc: 0.5354\n",
      "Epoch 676/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0469 - acc: 0.9992 - val_loss: 1.5690 - val_acc: 0.5354\n",
      "Epoch 677/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0472 - acc: 1.0000 - val_loss: 1.5119 - val_acc: 0.5320\n",
      "Epoch 678/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0924 - acc: 0.9738 - val_loss: 1.5354 - val_acc: 0.5522\n",
      "Epoch 679/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0469 - acc: 1.0000 - val_loss: 1.4938 - val_acc: 0.5253\n",
      "Epoch 680/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0458 - acc: 1.0000 - val_loss: 1.5050 - val_acc: 0.5152\n",
      "Epoch 681/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0811 - acc: 0.9764 - val_loss: 1.5085 - val_acc: 0.5253\n",
      "Epoch 682/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0533 - acc: 0.9966 - val_loss: 1.7223 - val_acc: 0.5387\n",
      "Epoch 683/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0647 - acc: 0.9916 - val_loss: 1.5365 - val_acc: 0.5522\n",
      "Epoch 684/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0503 - acc: 0.9992 - val_loss: 1.5083 - val_acc: 0.5354\n",
      "Epoch 685/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0492 - acc: 0.9992 - val_loss: 1.6280 - val_acc: 0.5455\n",
      "Epoch 686/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0789 - acc: 0.9873 - val_loss: 1.5236 - val_acc: 0.5253\n",
      "Epoch 687/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0467 - acc: 1.0000 - val_loss: 1.5412 - val_acc: 0.5286\n",
      "Epoch 688/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0759 - acc: 0.9899 - val_loss: 1.5510 - val_acc: 0.5118\n",
      "Epoch 689/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0455 - acc: 1.0000 - val_loss: 1.5605 - val_acc: 0.5354\n",
      "Epoch 690/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0720 - acc: 0.9924 - val_loss: 1.5116 - val_acc: 0.5253\n",
      "Epoch 691/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.0602 - acc: 0.9932 - val_loss: 1.5278 - val_acc: 0.5253\n",
      "Epoch 692/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0499 - acc: 0.9992 - val_loss: 1.5065 - val_acc: 0.5421\n",
      "Epoch 693/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0597 - acc: 0.9916 - val_loss: 1.5035 - val_acc: 0.5286\n",
      "Epoch 694/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0446 - acc: 1.0000 - val_loss: 1.5361 - val_acc: 0.5219\n",
      "Epoch 695/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0822 - acc: 0.9814 - val_loss: 1.5350 - val_acc: 0.5253\n",
      "Epoch 696/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0434 - acc: 0.9992 - val_loss: 1.6021 - val_acc: 0.5320\n",
      "Epoch 697/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0540 - acc: 0.9966 - val_loss: 1.5847 - val_acc: 0.5354\n",
      "Epoch 698/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0691 - acc: 0.9932 - val_loss: 1.5425 - val_acc: 0.5320\n",
      "Epoch 699/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0481 - acc: 0.9992 - val_loss: 1.5642 - val_acc: 0.5152\n",
      "Epoch 700/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0804 - acc: 0.9806 - val_loss: 1.5174 - val_acc: 0.5219\n",
      "Epoch 701/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 1.5309 - val_acc: 0.5320\n",
      "Epoch 702/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0458 - acc: 0.9992 - val_loss: 1.6687 - val_acc: 0.5488\n",
      "Epoch 703/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0634 - acc: 0.9916 - val_loss: 1.5390 - val_acc: 0.5253\n",
      "Epoch 704/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0457 - acc: 0.9992 - val_loss: 1.6087 - val_acc: 0.5286\n",
      "Epoch 705/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0710 - acc: 0.9882 - val_loss: 1.5492 - val_acc: 0.5320\n",
      "Epoch 706/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 1.8620 - val_acc: 0.5455\n",
      "Epoch 707/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0740 - acc: 0.9856 - val_loss: 1.5381 - val_acc: 0.5219\n",
      "Epoch 708/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0466 - acc: 0.9983 - val_loss: 1.6895 - val_acc: 0.5522\n",
      "Epoch 709/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0580 - acc: 0.9949 - val_loss: 1.5530 - val_acc: 0.5421\n",
      "Epoch 710/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0468 - acc: 0.9992 - val_loss: 1.5911 - val_acc: 0.5354\n",
      "Epoch 711/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0659 - acc: 0.9924 - val_loss: 1.5449 - val_acc: 0.5253\n",
      "Epoch 712/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0481 - acc: 0.9983 - val_loss: 1.7355 - val_acc: 0.5387\n",
      "Epoch 713/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0507 - acc: 0.9958 - val_loss: 1.5700 - val_acc: 0.5219\n",
      "Epoch 714/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0671 - acc: 0.9865 - val_loss: 1.6710 - val_acc: 0.5488\n",
      "Epoch 715/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0461 - acc: 0.9983 - val_loss: 1.5486 - val_acc: 0.5286\n",
      "Epoch 716/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0388 - acc: 1.0000 - val_loss: 1.5821 - val_acc: 0.5354\n",
      "Epoch 717/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0798 - acc: 0.9831 - val_loss: 1.5548 - val_acc: 0.5387\n",
      "Epoch 718/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0389 - acc: 1.0000 - val_loss: 1.5622 - val_acc: 0.5421\n",
      "Epoch 719/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0610 - acc: 0.9966 - val_loss: 1.5495 - val_acc: 0.5320\n",
      "Epoch 720/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0390 - acc: 0.9992 - val_loss: 1.6300 - val_acc: 0.5421\n",
      "Epoch 721/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0683 - acc: 0.9890 - val_loss: 1.5951 - val_acc: 0.5253\n",
      "Epoch 722/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0424 - acc: 1.0000 - val_loss: 1.6873 - val_acc: 0.5354\n",
      "Epoch 723/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0532 - acc: 0.9958 - val_loss: 1.5853 - val_acc: 0.5286\n",
      "Epoch 724/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0432 - acc: 0.9975 - val_loss: 1.8556 - val_acc: 0.5421\n",
      "Epoch 725/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0552 - acc: 0.9949 - val_loss: 1.5973 - val_acc: 0.5387\n",
      "Epoch 726/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0438 - acc: 0.9992 - val_loss: 1.5934 - val_acc: 0.5354\n",
      "Epoch 727/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0657 - acc: 0.9924 - val_loss: 1.6486 - val_acc: 0.5455\n",
      "Epoch 728/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0420 - acc: 0.9992 - val_loss: 1.5699 - val_acc: 0.5320\n",
      "Epoch 729/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0463 - acc: 0.9966 - val_loss: 1.5904 - val_acc: 0.5387\n",
      "Epoch 730/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0427 - acc: 0.9992 - val_loss: 1.6516 - val_acc: 0.5320\n",
      "Epoch 731/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0484 - acc: 0.9983 - val_loss: 1.5824 - val_acc: 0.5219\n",
      "Epoch 732/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0429 - acc: 0.9983 - val_loss: 1.7475 - val_acc: 0.5354\n",
      "Epoch 733/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0594 - acc: 0.9907 - val_loss: 1.6047 - val_acc: 0.5354\n",
      "Epoch 734/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0377 - acc: 1.0000 - val_loss: 1.7221 - val_acc: 0.5320\n",
      "Epoch 735/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0482 - acc: 0.9958 - val_loss: 1.5780 - val_acc: 0.5354\n",
      "Epoch 736/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0534 - acc: 0.9958 - val_loss: 1.6996 - val_acc: 0.5320\n",
      "Epoch 737/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0468 - acc: 0.9983 - val_loss: 1.5837 - val_acc: 0.5185\n",
      "Epoch 738/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 1.6172 - val_acc: 0.5253\n",
      "Epoch 739/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0840 - acc: 0.9764 - val_loss: 1.5871 - val_acc: 0.5286\n",
      "Epoch 740/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0357 - acc: 1.0000 - val_loss: 1.5948 - val_acc: 0.5421\n",
      "Epoch 741/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0396 - acc: 0.9966 - val_loss: 1.6120 - val_acc: 0.5488\n",
      "Epoch 742/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0560 - acc: 0.9949 - val_loss: 1.5797 - val_acc: 0.5219\n",
      "Epoch 743/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0694 - acc: 0.9848 - val_loss: 1.5863 - val_acc: 0.5286\n",
      "Epoch 744/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0338 - acc: 1.0000 - val_loss: 1.6072 - val_acc: 0.5320\n",
      "Epoch 745/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0401 - acc: 0.9983 - val_loss: 1.9595 - val_acc: 0.5286\n",
      "Epoch 746/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0611 - acc: 0.9865 - val_loss: 1.5900 - val_acc: 0.5320\n",
      "Epoch 747/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0337 - acc: 1.0000 - val_loss: 1.5979 - val_acc: 0.5320\n",
      "Epoch 748/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 1.6117 - val_acc: 0.5354\n",
      "Epoch 749/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0827 - acc: 0.9755 - val_loss: 1.5880 - val_acc: 0.5387\n",
      "Epoch 750/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 1.6064 - val_acc: 0.5320\n",
      "Epoch 751/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 1.6330 - val_acc: 0.5488\n",
      "Epoch 752/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0578 - acc: 0.9932 - val_loss: 1.6093 - val_acc: 0.5253\n",
      "Epoch 753/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0379 - acc: 1.0000 - val_loss: 1.6448 - val_acc: 0.5556\n",
      "Epoch 754/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0561 - acc: 0.9975 - val_loss: 1.6024 - val_acc: 0.5354\n",
      "Epoch 755/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0327 - acc: 0.9992 - val_loss: 1.6638 - val_acc: 0.5421\n",
      "Epoch 756/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0709 - acc: 0.9831 - val_loss: 1.6009 - val_acc: 0.5286\n",
      "Epoch 757/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 1.6434 - val_acc: 0.5522\n",
      "Epoch 758/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 1.6876 - val_acc: 0.5320\n",
      "Epoch 759/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0730 - acc: 0.9848 - val_loss: 1.6295 - val_acc: 0.5320\n",
      "Epoch 760/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 1.6579 - val_acc: 0.5589\n",
      "Epoch 761/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0376 - acc: 1.0000 - val_loss: 1.6670 - val_acc: 0.5455\n",
      "Epoch 762/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0372 - acc: 1.0000 - val_loss: 1.7497 - val_acc: 0.5185\n",
      "Epoch 763/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0536 - acc: 0.9941 - val_loss: 1.6807 - val_acc: 0.5488\n",
      "Epoch 764/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 1.6418 - val_acc: 0.5219\n",
      "Epoch 765/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0400 - acc: 0.9966 - val_loss: 1.8015 - val_acc: 0.5455\n",
      "Epoch 766/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0443 - acc: 0.9975 - val_loss: 1.6178 - val_acc: 0.5421\n",
      "Epoch 767/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0558 - acc: 0.9924 - val_loss: 1.6921 - val_acc: 0.5455\n",
      "Epoch 768/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0339 - acc: 0.9992 - val_loss: 1.6349 - val_acc: 0.5354\n",
      "Epoch 769/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 1.6603 - val_acc: 0.5286\n",
      "Epoch 770/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0769 - acc: 0.9840 - val_loss: 1.6287 - val_acc: 0.5455\n",
      "Epoch 771/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 1.6395 - val_acc: 0.5320\n",
      "Epoch 772/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0438 - acc: 0.9958 - val_loss: 1.8259 - val_acc: 0.5455\n",
      "Epoch 773/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0372 - acc: 0.9983 - val_loss: 1.6681 - val_acc: 0.5219\n",
      "Epoch 774/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0394 - acc: 0.9992 - val_loss: 1.7701 - val_acc: 0.5320\n",
      "Epoch 775/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0398 - acc: 0.9992 - val_loss: 1.6711 - val_acc: 0.5320\n",
      "Epoch 776/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0486 - acc: 0.9949 - val_loss: 1.6414 - val_acc: 0.5118\n",
      "Epoch 777/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 1.7508 - val_acc: 0.5387\n",
      "Epoch 778/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0492 - acc: 0.9949 - val_loss: 1.6491 - val_acc: 0.5286\n",
      "Epoch 779/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0287 - acc: 1.0000 - val_loss: 1.6692 - val_acc: 0.5387\n",
      "Epoch 780/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0596 - acc: 0.9899 - val_loss: 1.6507 - val_acc: 0.5488\n",
      "Epoch 781/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 1.6370 - val_acc: 0.5421\n",
      "Epoch 782/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0625 - acc: 0.9882 - val_loss: 1.6753 - val_acc: 0.5253\n",
      "Epoch 783/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 1.6716 - val_acc: 0.5253\n",
      "Epoch 784/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 1.6961 - val_acc: 0.5354\n",
      "Epoch 785/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0357 - acc: 1.0000 - val_loss: 1.7042 - val_acc: 0.5421\n",
      "Epoch 786/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0666 - acc: 0.9840 - val_loss: 1.6612 - val_acc: 0.5354\n",
      "Epoch 787/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 1.6630 - val_acc: 0.5354\n",
      "Epoch 788/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 1.7024 - val_acc: 0.5152\n",
      "Epoch 789/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0578 - acc: 0.9916 - val_loss: 1.6780 - val_acc: 0.5455\n",
      "Epoch 790/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 1.6654 - val_acc: 0.5320\n",
      "Epoch 791/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0681 - acc: 0.9764 - val_loss: 1.7098 - val_acc: 0.5421\n",
      "Epoch 792/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 1.6684 - val_acc: 0.5286\n",
      "Epoch 793/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0275 - acc: 1.0000 - val_loss: 1.6481 - val_acc: 0.5387\n",
      "Epoch 794/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 1.8837 - val_acc: 0.5320\n",
      "Epoch 795/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0382 - acc: 0.9966 - val_loss: 1.6708 - val_acc: 0.5286\n",
      "Epoch 796/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0304 - acc: 0.9992 - val_loss: 1.6960 - val_acc: 0.5421\n",
      "Epoch 797/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0481 - acc: 0.9932 - val_loss: 1.7915 - val_acc: 0.5320\n",
      "Epoch 798/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0312 - acc: 0.9992 - val_loss: 1.6835 - val_acc: 0.5253\n",
      "Epoch 799/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 1.7192 - val_acc: 0.5286\n",
      "Epoch 800/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0326 - acc: 0.9992 - val_loss: 1.7028 - val_acc: 0.5387\n",
      "Epoch 801/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0685 - acc: 0.9806 - val_loss: 1.6650 - val_acc: 0.5387\n",
      "Epoch 802/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 1.6754 - val_acc: 0.5354\n",
      "Epoch 803/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 1.7840 - val_acc: 0.5488\n",
      "Epoch 804/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0470 - acc: 0.9958 - val_loss: 1.6951 - val_acc: 0.5354\n",
      "Epoch 805/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 1.7622 - val_acc: 0.5421\n",
      "Epoch 806/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0468 - acc: 0.9949 - val_loss: 1.6981 - val_acc: 0.5185\n",
      "Epoch 807/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 1.6942 - val_acc: 0.5185\n",
      "Epoch 808/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0595 - acc: 0.9899 - val_loss: 1.6937 - val_acc: 0.5354\n",
      "Epoch 809/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 1.7038 - val_acc: 0.5185\n",
      "Epoch 810/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0263 - acc: 0.9992 - val_loss: 1.7294 - val_acc: 0.5354\n",
      "Epoch 811/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0404 - acc: 0.9949 - val_loss: 1.7951 - val_acc: 0.5286\n",
      "Epoch 812/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0311 - acc: 0.9992 - val_loss: 1.7093 - val_acc: 0.5253\n",
      "Epoch 813/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0688 - acc: 0.9848 - val_loss: 1.6916 - val_acc: 0.5286\n",
      "Epoch 814/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 1.7566 - val_acc: 0.5253\n",
      "Epoch 815/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 1.7146 - val_acc: 0.5320\n",
      "Epoch 816/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 1.7488 - val_acc: 0.5354\n",
      "Epoch 817/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0565 - acc: 0.9865 - val_loss: 1.6929 - val_acc: 0.5253\n",
      "Epoch 818/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 1.7074 - val_acc: 0.5152\n",
      "Epoch 819/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 1.9504 - val_acc: 0.5286\n",
      "Epoch 820/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0436 - acc: 0.9941 - val_loss: 1.7373 - val_acc: 0.5320\n",
      "Epoch 821/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 1.6829 - val_acc: 0.5152\n",
      "Epoch 822/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0614 - acc: 0.9856 - val_loss: 1.7235 - val_acc: 0.5253\n",
      "Epoch 823/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 1.7070 - val_acc: 0.5286\n",
      "Epoch 824/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 1.8133 - val_acc: 0.5455\n",
      "Epoch 825/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0309 - acc: 0.9992 - val_loss: 1.8628 - val_acc: 0.5421\n",
      "Epoch 826/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0511 - acc: 0.9916 - val_loss: 1.7065 - val_acc: 0.5354\n",
      "Epoch 827/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 1.7607 - val_acc: 0.5320\n",
      "Epoch 828/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0369 - acc: 0.9992 - val_loss: 1.8007 - val_acc: 0.5253\n",
      "Epoch 829/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0324 - acc: 0.9983 - val_loss: 1.7426 - val_acc: 0.5185\n",
      "Epoch 830/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 2.0312 - val_acc: 0.5354\n",
      "Epoch 831/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0632 - acc: 0.9780 - val_loss: 1.7291 - val_acc: 0.5320\n",
      "Epoch 832/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 1.7346 - val_acc: 0.5421\n",
      "Epoch 833/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 1.7413 - val_acc: 0.5253\n",
      "Epoch 834/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0498 - acc: 0.9890 - val_loss: 1.7383 - val_acc: 0.5286\n",
      "Epoch 835/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 1.7603 - val_acc: 0.5185\n",
      "Epoch 836/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 1.7639 - val_acc: 0.5320\n",
      "Epoch 837/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0646 - acc: 0.9848 - val_loss: 1.7302 - val_acc: 0.5354\n",
      "Epoch 838/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 1.7360 - val_acc: 0.5354\n",
      "Epoch 839/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 1.8203 - val_acc: 0.5488\n",
      "Epoch 840/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0604 - acc: 0.9840 - val_loss: 1.7371 - val_acc: 0.5320\n",
      "Epoch 841/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 1.7519 - val_acc: 0.5421\n",
      "Epoch 842/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0317 - acc: 0.9992 - val_loss: 2.0400 - val_acc: 0.5488\n",
      "Epoch 843/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0297 - acc: 0.9975 - val_loss: 1.8198 - val_acc: 0.5320\n",
      "Epoch 844/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 1.7669 - val_acc: 0.5286\n",
      "Epoch 845/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0328 - acc: 0.9966 - val_loss: 1.9370 - val_acc: 0.5421\n",
      "Epoch 846/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0304 - acc: 0.9983 - val_loss: 1.7519 - val_acc: 0.5253\n",
      "Epoch 847/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 1.7493 - val_acc: 0.5320\n",
      "Epoch 848/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0513 - acc: 0.9899 - val_loss: 1.7453 - val_acc: 0.5253\n",
      "Epoch 849/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 1.7556 - val_acc: 0.5219\n",
      "Epoch 850/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0314 - acc: 0.9992 - val_loss: 1.7464 - val_acc: 0.5522\n",
      "Epoch 851/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 1.7562 - val_acc: 0.5320\n",
      "Epoch 852/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0450 - acc: 0.9916 - val_loss: 1.7383 - val_acc: 0.5219\n",
      "Epoch 853/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.7391 - val_acc: 0.5253\n",
      "Epoch 854/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 1.8149 - val_acc: 0.5387\n",
      "Epoch 855/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0447 - acc: 0.9975 - val_loss: 1.7556 - val_acc: 0.5286\n",
      "Epoch 856/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 1.7782 - val_acc: 0.5286\n",
      "Epoch 857/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0600 - acc: 0.9865 - val_loss: 1.7569 - val_acc: 0.5354\n",
      "Epoch 858/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.7698 - val_acc: 0.5286\n",
      "Epoch 859/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 1.7645 - val_acc: 0.5421\n",
      "Epoch 860/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0492 - acc: 0.9848 - val_loss: 1.8508 - val_acc: 0.5387\n",
      "Epoch 861/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 1.7729 - val_acc: 0.5286\n",
      "Epoch 862/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.7711 - val_acc: 0.5320\n",
      "Epoch 863/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.0259 - acc: 0.9966 - val_loss: 2.0480 - val_acc: 0.5455\n",
      "Epoch 864/1100\n",
      "1184/1184 [==============================] - 0s 31us/step - loss: 0.0342 - acc: 0.9975 - val_loss: 1.7823 - val_acc: 0.5320\n",
      "Epoch 865/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.7694 - val_acc: 0.5320\n",
      "Epoch 866/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0283 - acc: 0.9983 - val_loss: 2.1408 - val_acc: 0.5152\n",
      "Epoch 867/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0391 - acc: 0.9924 - val_loss: 1.7772 - val_acc: 0.5219\n",
      "Epoch 868/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 1.7681 - val_acc: 0.5354\n",
      "Epoch 869/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.0343 - acc: 0.9975 - val_loss: 1.9496 - val_acc: 0.5556\n",
      "Epoch 870/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0249 - acc: 0.9983 - val_loss: 1.8069 - val_acc: 0.5387\n",
      "Epoch 871/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 1.9037 - val_acc: 0.5522\n",
      "Epoch 872/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0313 - acc: 0.9992 - val_loss: 1.8237 - val_acc: 0.5219\n",
      "Epoch 873/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.0217 - acc: 0.9992 - val_loss: 1.8199 - val_acc: 0.5387\n",
      "Epoch 874/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.0453 - acc: 0.9958 - val_loss: 1.8102 - val_acc: 0.5286\n",
      "Epoch 875/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 1.7735 - val_acc: 0.5286\n",
      "Epoch 876/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 1.8361 - val_acc: 0.5354\n",
      "Epoch 877/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0421 - acc: 0.9941 - val_loss: 1.8134 - val_acc: 0.5253\n",
      "Epoch 878/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 1.8341 - val_acc: 0.5253\n",
      "Epoch 879/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0385 - acc: 0.9992 - val_loss: 1.8288 - val_acc: 0.5354\n",
      "Epoch 880/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 1.7915 - val_acc: 0.5253\n",
      "Epoch 881/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 1.8732 - val_acc: 0.5387\n",
      "Epoch 882/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.0371 - acc: 0.9966 - val_loss: 1.8251 - val_acc: 0.5387\n",
      "Epoch 883/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 1.8075 - val_acc: 0.5286\n",
      "Epoch 884/1100\n",
      "1184/1184 [==============================] - 0s 27us/step - loss: 0.0289 - acc: 0.9975 - val_loss: 2.2935 - val_acc: 0.5152\n",
      "Epoch 885/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.0401 - acc: 0.9890 - val_loss: 1.8154 - val_acc: 0.5488\n",
      "Epoch 886/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 1.7979 - val_acc: 0.5286\n",
      "Epoch 887/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 1.8028 - val_acc: 0.5320\n",
      "Epoch 888/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0423 - acc: 0.9916 - val_loss: 1.8804 - val_acc: 0.5286\n",
      "Epoch 889/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 1.8438 - val_acc: 0.5421\n",
      "Epoch 890/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 1.8205 - val_acc: 0.5354\n",
      "Epoch 891/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0285 - acc: 0.9983 - val_loss: 1.8160 - val_acc: 0.5455\n",
      "Epoch 892/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 1.8500 - val_acc: 0.5488\n",
      "Epoch 893/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0239 - acc: 1.0000 - val_loss: 1.9108 - val_acc: 0.5320\n",
      "Epoch 894/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0287 - acc: 1.0000 - val_loss: 1.8244 - val_acc: 0.5253\n",
      "Epoch 895/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 1.8514 - val_acc: 0.5387\n",
      "Epoch 896/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0461 - acc: 0.9941 - val_loss: 1.8285 - val_acc: 0.5185\n",
      "Epoch 897/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 1.8734 - val_acc: 0.5320\n",
      "Epoch 898/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 2.0226 - val_acc: 0.5320\n",
      "Epoch 899/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0358 - acc: 0.9958 - val_loss: 1.8276 - val_acc: 0.5253\n",
      "Epoch 900/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 1.8235 - val_acc: 0.5354\n",
      "Epoch 901/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0711 - acc: 0.9780 - val_loss: 1.8160 - val_acc: 0.5387\n",
      "Epoch 902/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 1.8073 - val_acc: 0.5219\n",
      "Epoch 903/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 1.8130 - val_acc: 0.5219\n",
      "Epoch 904/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 1.8159 - val_acc: 0.5320\n",
      "Epoch 905/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0296 - acc: 0.9992 - val_loss: 1.8659 - val_acc: 0.5354\n",
      "Epoch 906/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 1.8760 - val_acc: 0.5253\n",
      "Epoch 907/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0398 - acc: 0.9958 - val_loss: 1.8168 - val_acc: 0.5354\n",
      "Epoch 908/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 1.8485 - val_acc: 0.5354\n",
      "Epoch 909/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 2.1300 - val_acc: 0.5286\n",
      "Epoch 910/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0368 - acc: 0.9941 - val_loss: 1.8413 - val_acc: 0.5219\n",
      "Epoch 911/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 1.8622 - val_acc: 0.5488\n",
      "Epoch 912/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 1.8219 - val_acc: 0.5286\n",
      "Epoch 913/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 2.1076 - val_acc: 0.5354\n",
      "Epoch 914/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0641 - acc: 0.9780 - val_loss: 1.8348 - val_acc: 0.5286\n",
      "Epoch 915/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 1.8401 - val_acc: 0.5354\n",
      "Epoch 916/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.8454 - val_acc: 0.5185\n",
      "Epoch 917/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.9265 - val_acc: 0.5421\n",
      "Epoch 918/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0560 - acc: 0.9873 - val_loss: 1.8389 - val_acc: 0.5522\n",
      "Epoch 919/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.8357 - val_acc: 0.5421\n",
      "Epoch 920/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 1.8543 - val_acc: 0.5387\n",
      "Epoch 921/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 2.2804 - val_acc: 0.5556\n",
      "Epoch 922/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0413 - acc: 0.9865 - val_loss: 1.8475 - val_acc: 0.5219\n",
      "Epoch 923/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.8532 - val_acc: 0.5421\n",
      "Epoch 924/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0310 - acc: 0.9992 - val_loss: 1.8897 - val_acc: 0.5488\n",
      "Epoch 925/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 1.8692 - val_acc: 0.5488\n",
      "Epoch 926/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 1.9145 - val_acc: 0.5286\n",
      "Epoch 927/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0207 - acc: 0.9992 - val_loss: 1.9747 - val_acc: 0.5421\n",
      "Epoch 928/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0320 - acc: 0.9992 - val_loss: 1.8757 - val_acc: 0.5387\n",
      "Epoch 929/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.9070 - val_acc: 0.5219\n",
      "Epoch 930/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0323 - acc: 0.9924 - val_loss: 1.9874 - val_acc: 0.5387\n",
      "Epoch 931/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 1.8573 - val_acc: 0.5354\n",
      "Epoch 932/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 1.8742 - val_acc: 0.5286\n",
      "Epoch 933/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 1.8831 - val_acc: 0.5455\n",
      "Epoch 934/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 2.0039 - val_acc: 0.5488\n",
      "Epoch 935/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9890 - val_loss: 1.8730 - val_acc: 0.5354\n",
      "Epoch 936/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.8762 - val_acc: 0.5387\n",
      "Epoch 937/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.8662 - val_acc: 0.5455\n",
      "Epoch 938/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0185 - acc: 0.9992 - val_loss: 2.0533 - val_acc: 0.5421\n",
      "Epoch 939/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0253 - acc: 0.9975 - val_loss: 1.9820 - val_acc: 0.5488\n",
      "Epoch 940/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 1.9158 - val_acc: 0.5421\n",
      "Epoch 941/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0167 - acc: 0.9992 - val_loss: 1.9664 - val_acc: 0.5387\n",
      "Epoch 942/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0386 - acc: 0.9975 - val_loss: 1.8839 - val_acc: 0.5320\n",
      "Epoch 943/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 1.9025 - val_acc: 0.5286\n",
      "Epoch 944/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 1.9434 - val_acc: 0.5657\n",
      "Epoch 945/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0425 - acc: 0.9966 - val_loss: 1.8582 - val_acc: 0.5488\n",
      "Epoch 946/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.8827 - val_acc: 0.5387\n",
      "Epoch 947/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.8510 - val_acc: 0.5387\n",
      "Epoch 948/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0383 - acc: 0.9932 - val_loss: 1.9138 - val_acc: 0.5320\n",
      "Epoch 949/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 1.8848 - val_acc: 0.5354\n",
      "Epoch 950/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 1.9722 - val_acc: 0.5253\n",
      "Epoch 951/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0304 - acc: 0.9992 - val_loss: 1.8590 - val_acc: 0.5286\n",
      "Epoch 952/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.8994 - val_acc: 0.5286\n",
      "Epoch 953/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0389 - acc: 0.9932 - val_loss: 1.8866 - val_acc: 0.5421\n",
      "Epoch 954/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.8773 - val_acc: 0.5387\n",
      "Epoch 955/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 1.8802 - val_acc: 0.5320\n",
      "Epoch 956/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0190 - acc: 0.9983 - val_loss: 2.4217 - val_acc: 0.5051\n",
      "Epoch 957/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0366 - acc: 0.9916 - val_loss: 1.9035 - val_acc: 0.5320\n",
      "Epoch 958/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.9002 - val_acc: 0.5387\n",
      "Epoch 959/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.8861 - val_acc: 0.5219\n",
      "Epoch 960/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0316 - acc: 0.9958 - val_loss: 1.9083 - val_acc: 0.5387\n",
      "Epoch 961/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.9065 - val_acc: 0.5286\n",
      "Epoch 962/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.9304 - val_acc: 0.5253\n",
      "Epoch 963/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0435 - acc: 0.9882 - val_loss: 1.9058 - val_acc: 0.5320\n",
      "Epoch 964/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.9027 - val_acc: 0.5421\n",
      "Epoch 965/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 1.9191 - val_acc: 0.5320\n",
      "Epoch 966/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.9243 - val_acc: 0.5387\n",
      "Epoch 967/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0483 - acc: 0.9848 - val_loss: 1.9170 - val_acc: 0.5387\n",
      "Epoch 968/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.9217 - val_acc: 0.5421\n",
      "Epoch 969/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.9093 - val_acc: 0.5253\n",
      "Epoch 970/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.9099 - val_acc: 0.5354\n",
      "Epoch 971/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0581 - acc: 0.9823 - val_loss: 1.8974 - val_acc: 0.5320\n",
      "Epoch 972/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.9063 - val_acc: 0.5286\n",
      "Epoch 973/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.9146 - val_acc: 0.5253\n",
      "Epoch 974/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.9414 - val_acc: 0.5387\n",
      "Epoch 975/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9890 - val_loss: 1.9158 - val_acc: 0.5522\n",
      "Epoch 976/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.9119 - val_acc: 0.5387\n",
      "Epoch 977/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.9197 - val_acc: 0.5421\n",
      "Epoch 978/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 2.2817 - val_acc: 0.5387\n",
      "Epoch 979/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0304 - acc: 0.9916 - val_loss: 1.9221 - val_acc: 0.5387\n",
      "Epoch 980/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.9128 - val_acc: 0.5387\n",
      "Epoch 981/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.9436 - val_acc: 0.5253\n",
      "Epoch 982/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0523 - acc: 0.9814 - val_loss: 1.9486 - val_acc: 0.5253\n",
      "Epoch 983/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.9365 - val_acc: 0.5253\n",
      "Epoch 984/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.9286 - val_acc: 0.5185\n",
      "Epoch 985/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.9424 - val_acc: 0.5185\n",
      "Epoch 986/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0305 - acc: 0.9958 - val_loss: 1.9532 - val_acc: 0.5354\n",
      "Epoch 987/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 1.9385 - val_acc: 0.5421\n",
      "Epoch 988/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.9606 - val_acc: 0.5421\n",
      "Epoch 989/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0401 - acc: 0.9958 - val_loss: 1.9681 - val_acc: 0.5387\n",
      "Epoch 990/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.9331 - val_acc: 0.5320\n",
      "Epoch 991/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.9441 - val_acc: 0.5219\n",
      "Epoch 992/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0286 - acc: 0.9958 - val_loss: 1.9801 - val_acc: 0.5152\n",
      "Epoch 993/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.9506 - val_acc: 0.5253\n",
      "Epoch 994/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.9645 - val_acc: 0.5185\n",
      "Epoch 995/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0245 - acc: 0.9949 - val_loss: 2.1400 - val_acc: 0.5522\n",
      "Epoch 996/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 1.9434 - val_acc: 0.5286\n",
      "Epoch 997/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.9479 - val_acc: 0.5253\n",
      "Epoch 998/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.9574 - val_acc: 0.5253\n",
      "Epoch 999/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0332 - acc: 0.9932 - val_loss: 1.9424 - val_acc: 0.5556\n",
      "Epoch 1000/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.9416 - val_acc: 0.5320\n",
      "Epoch 1001/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.9381 - val_acc: 0.5286\n",
      "Epoch 1002/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.9613 - val_acc: 0.5354\n",
      "Epoch 1003/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0309 - acc: 0.9966 - val_loss: 1.9780 - val_acc: 0.5354\n",
      "Epoch 1004/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.9757 - val_acc: 0.5320\n",
      "Epoch 1005/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.9569 - val_acc: 0.5253\n",
      "Epoch 1006/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 2.0042 - val_acc: 0.5421\n",
      "Epoch 1007/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0525 - acc: 0.9789 - val_loss: 1.9601 - val_acc: 0.5488\n",
      "Epoch 1008/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.9541 - val_acc: 0.5387\n",
      "Epoch 1009/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.9704 - val_acc: 0.5421\n",
      "Epoch 1010/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.9710 - val_acc: 0.5421\n",
      "Epoch 1011/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0248 - acc: 0.9958 - val_loss: 2.1302 - val_acc: 0.5354\n",
      "Epoch 1012/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.9616 - val_acc: 0.5455\n",
      "Epoch 1013/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.9795 - val_acc: 0.5387\n",
      "Epoch 1014/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 2.0441 - val_acc: 0.5488\n",
      "Epoch 1015/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0316 - acc: 0.9966 - val_loss: 1.9666 - val_acc: 0.5354\n",
      "Epoch 1016/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.9821 - val_acc: 0.5354\n",
      "Epoch 1017/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 2.0845 - val_acc: 0.5556\n",
      "Epoch 1018/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 2.0010 - val_acc: 0.5455\n",
      "Epoch 1019/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 2.2092 - val_acc: 0.5488\n",
      "Epoch 1020/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0234 - acc: 0.9958 - val_loss: 1.9699 - val_acc: 0.5354\n",
      "Epoch 1021/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.0051 - val_acc: 0.5556\n",
      "Epoch 1022/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0128 - acc: 0.9992 - val_loss: 1.9932 - val_acc: 0.5421\n",
      "Epoch 1023/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0403 - acc: 0.9890 - val_loss: 1.9897 - val_acc: 0.5387\n",
      "Epoch 1024/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 1.9808 - val_acc: 0.5421\n",
      "Epoch 1025/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.9955 - val_acc: 0.5320\n",
      "Epoch 1026/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 2.0122 - val_acc: 0.5286\n",
      "Epoch 1027/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 1.9751 - val_acc: 0.5253\n",
      "Epoch 1028/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0396 - acc: 0.9932 - val_loss: 2.0045 - val_acc: 0.5421\n",
      "Epoch 1029/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.9955 - val_acc: 0.5354\n",
      "Epoch 1030/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 1.9888 - val_acc: 0.5320\n",
      "Epoch 1031/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.2189 - val_acc: 0.5421\n",
      "Epoch 1032/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0493 - acc: 0.9831 - val_loss: 2.0090 - val_acc: 0.5354\n",
      "Epoch 1033/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.0102 - val_acc: 0.5354\n",
      "Epoch 1034/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.9962 - val_acc: 0.5387\n",
      "Epoch 1035/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.9924 - val_acc: 0.5354\n",
      "Epoch 1036/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0444 - acc: 0.9865 - val_loss: 1.9824 - val_acc: 0.5421\n",
      "Epoch 1037/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 1.9812 - val_acc: 0.5354\n",
      "Epoch 1038/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 1.9939 - val_acc: 0.5387\n",
      "Epoch 1039/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.0061 - val_acc: 0.5253\n",
      "Epoch 1040/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.0502 - val_acc: 0.5387\n",
      "Epoch 1041/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9848 - val_loss: 2.0041 - val_acc: 0.5253\n",
      "Epoch 1042/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.9954 - val_acc: 0.5387\n",
      "Epoch 1043/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 1.9886 - val_acc: 0.5421\n",
      "Epoch 1044/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.1912 - val_acc: 0.5455\n",
      "Epoch 1045/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0223 - acc: 0.9992 - val_loss: 2.0451 - val_acc: 0.5320\n",
      "Epoch 1046/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.0032 - val_acc: 0.5421\n",
      "Epoch 1047/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 2.1762 - val_acc: 0.5455\n",
      "Epoch 1048/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 2.0176 - val_acc: 0.5387\n",
      "Epoch 1049/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 2.0900 - val_acc: 0.5152\n",
      "Epoch 1050/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0367 - acc: 0.9924 - val_loss: 2.0197 - val_acc: 0.5455\n",
      "Epoch 1051/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.0222 - val_acc: 0.5354\n",
      "Epoch 1052/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.0436 - val_acc: 0.5421\n",
      "Epoch 1053/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 2.0241 - val_acc: 0.5421\n",
      "Epoch 1054/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.0426 - val_acc: 0.5488\n",
      "Epoch 1055/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0423 - acc: 0.9899 - val_loss: 2.0341 - val_acc: 0.5320\n",
      "Epoch 1056/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.0193 - val_acc: 0.5286\n",
      "Epoch 1057/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.0494 - val_acc: 0.5286\n",
      "Epoch 1058/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 2.0540 - val_acc: 0.5320\n",
      "Epoch 1059/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.0337 - val_acc: 0.5320\n",
      "Epoch 1060/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0389 - acc: 0.9882 - val_loss: 2.0283 - val_acc: 0.5320\n",
      "Epoch 1061/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.0183 - val_acc: 0.5387\n",
      "Epoch 1062/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.0429 - val_acc: 0.5320\n",
      "Epoch 1063/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.0820 - val_acc: 0.5253\n",
      "Epoch 1064/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 2.0325 - val_acc: 0.5488\n",
      "Epoch 1065/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.0335 - val_acc: 0.5354\n",
      "Epoch 1066/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0168 - acc: 0.9983 - val_loss: 2.4896 - val_acc: 0.5286\n",
      "Epoch 1067/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0251 - acc: 0.9941 - val_loss: 2.0415 - val_acc: 0.5253\n",
      "Epoch 1068/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.0429 - val_acc: 0.5286\n",
      "Epoch 1069/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.0531 - val_acc: 0.5354\n",
      "Epoch 1070/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.0999 - val_acc: 0.5455\n",
      "Epoch 1071/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0346 - acc: 0.9941 - val_loss: 2.0391 - val_acc: 0.5286\n",
      "Epoch 1072/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.0387 - val_acc: 0.5286\n",
      "Epoch 1073/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.0402 - val_acc: 0.5387\n",
      "Epoch 1074/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 2.3944 - val_acc: 0.5589\n",
      "Epoch 1075/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0202 - acc: 0.9992 - val_loss: 2.0248 - val_acc: 0.5354\n",
      "Epoch 1076/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.0324 - val_acc: 0.5320\n",
      "Epoch 1077/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.1069 - val_acc: 0.5421\n",
      "Epoch 1078/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0335 - acc: 0.9932 - val_loss: 2.0255 - val_acc: 0.5286\n",
      "Epoch 1079/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.0464 - val_acc: 0.5219\n",
      "Epoch 1080/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.0414 - val_acc: 0.5455\n",
      "Epoch 1081/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 2.1287 - val_acc: 0.5354\n",
      "Epoch 1082/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.0528 - val_acc: 0.5320\n",
      "Epoch 1083/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0227 - acc: 0.9949 - val_loss: 2.1929 - val_acc: 0.5387\n",
      "Epoch 1084/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 2.0427 - val_acc: 0.5354\n",
      "Epoch 1085/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.0546 - val_acc: 0.5421\n",
      "Epoch 1086/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.0486 - val_acc: 0.5354\n",
      "Epoch 1087/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0354 - acc: 0.9899 - val_loss: 2.0868 - val_acc: 0.5320\n",
      "Epoch 1088/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.0579 - val_acc: 0.5354\n",
      "Epoch 1089/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.0870 - val_acc: 0.5286\n",
      "Epoch 1090/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.0700 - val_acc: 0.5421\n",
      "Epoch 1091/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 2.3061 - val_acc: 0.5286\n",
      "Epoch 1092/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0130 - acc: 0.9992 - val_loss: 2.0824 - val_acc: 0.5286\n",
      "Epoch 1093/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.0734 - val_acc: 0.5455\n",
      "Epoch 1094/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.0791 - val_acc: 0.5354\n",
      "Epoch 1095/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0370 - acc: 0.9941 - val_loss: 2.0840 - val_acc: 0.5387\n",
      "Epoch 1096/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.0821 - val_acc: 0.5421\n",
      "Epoch 1097/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.0607 - val_acc: 0.5354\n",
      "Epoch 1098/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.0879 - val_acc: 0.5421\n",
      "Epoch 1099/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 2.2135 - val_acc: 0.5421\n",
      "Epoch 1100/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.0781 - val_acc: 0.5286\n"
     ]
    }
   ],
   "source": [
    "validation_data_split = 0.2\n",
    "num_epochs = 1100\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 20\n",
    "early_patience = 100\n",
    "#tensorboard is used for visualization\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "#earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "#Early stopping happens when the quantity monitored stops increasing or decreasing\n",
    "# Read Dataset\n",
    "dataset = pd.read_csv('final1600.csv')\n",
    "\n",
    "# Process Dataset\n",
    "processedData, processedLabel = processData(dataset)\n",
    "history = model.fit(processedData\n",
    "                    , processedLabel\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb]\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest = pd.read_csv('final1600.csv')\n",
    "datatest1,datalabel = testData(datatest)\n",
    "#np.set_printoptions(precision=4, suppress=True)\n",
    "k,l = datatest1.shape\n",
    "\n",
    "eval_results = model.predict(datatest1)\n",
    "#print(\"\\nLoss, accuracy on test data: \")\n",
    "#print(\"%0.4f %0.2f%%\" % (eval_results[0], \\\n",
    " #eval_results[1]*100))\n",
    "\n",
    "for i in range(100):\n",
    "    if(eval_results[i]>0.5):\n",
    "        eval_results[i] = 1\n",
    "    else:\n",
    "        eval_results[i] = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(k):\n",
    "    if (eval_results[i] == datalabel[1482+i]):\n",
    "        correct = correct +1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "        \n",
    "print (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1c36eb52b0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c36fb7b70>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c37027860>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c3705c400>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c36eb57f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Implementation with Human Observed Dataset on subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(dataset):\n",
    "    \n",
    "    # Why do we have to process?  We do not needvindexes, we only need values.\n",
    "    #We are converting the dataset back to array \n",
    "    #for further processing them to binary form\n",
    "    data   = dataset.iloc[:1481,0:9]\n",
    "    labels = dataset.iloc[:1481,9]\n",
    "    #to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "    #processedData  = encodeData(data)\n",
    "    #processedLabel = encodeLabel(labels)\n",
    "    print (data)\n",
    "    print(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testData(dataset):\n",
    "    data   = dataset.iloc[1482:,0:9]\n",
    "    labels = dataset.iloc[1482:,9]\n",
    "    #to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "    #processedData  = encodeData(data)\n",
    "    #processedLabel = encodeLabel(labels)\n",
    "    #print (data)\n",
    "    #print(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "input_size = 9\n",
    "drop_out = 0.1\n",
    "first_dense_layer_nodes  = 512\n",
    "second_dense_layer = 512\n",
    "second_dense_layer_nodes = 1\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    # Why do we need a model? A model is a core data  srtucture in keras and used to organize layers.\n",
    "    # Why use Dense layer and then activation? We need to tell the system how the model is by specifying input and dense layer size,\n",
    "    #after specifying we apply activation.\n",
    "    # Why use sequential model with layers? sequential model is a linear way of stacking layers, \n",
    "    #where a layer connects just to the next layer. Here we have a fixed souce of input and output.\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    #relu always gives value such that if x<0 it will give 0 otherwise it will give the number itself\n",
    "    #activation function are used to map input to output\n",
    "    \n",
    "    # Why dropout? WE used dropout to avoid overfitting of model\n",
    "    #model.add(Dropout(drop_out))\n",
    "    #model.add(Dense(second_dense_layer))\n",
    "    #model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    # Why Softmax?\n",
    "    # softmax is an activation function used when we are doing classification \n",
    "    #and softmax will give probabilities of various classes involved\n",
    "    model.summary()\n",
    "    \n",
    "    # Why use categorical_crossentropy? We use categorial cross entropy when the target is in categorical format\n",
    "    # Here we are distribuiting the number in 4 categories, thus using categorical crossentropy\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # optimizer allows the internal learnable parameter (weights)to get adjusted.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               5120      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,633\n",
      "Trainable params: 5,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  3  0.1  0.2  0.3  0.4  1  2  0.5\n",
      "0     1  0    1    1    0    1  1  0    0\n",
      "1     0  1    0    2    1    2  2  3    0\n",
      "2     0  2    1    3    3    1  2  3    1\n",
      "3     0  2    0    3    0    0  1  0    1\n",
      "4     1  0    0    1    2    0  1  2    0\n",
      "5     1  1    1    3    1    1  1  1    1\n",
      "6     1  0    1    0    0    0  2  1    0\n",
      "7     0  2    0    0    2    0  2  0    0\n",
      "8     2  1    1    2    0    0  1  0    0\n",
      "9     1  2    0    2    0    0  0  2    0\n",
      "10    1  4    0    2    0    0  0  4    0\n",
      "11    1  3    0    1    0    2  3  1    0\n",
      "12    0  0    0    0    0    1  1  2    1\n",
      "13    2  1    0    1    0    1  2  4    0\n",
      "14    1  3    1    3    0    2  0  3    1\n",
      "15    1  0    1    0    1    0  2  2    0\n",
      "16    0  2    0    2    0    1  0  2    0\n",
      "17    2  3    0    1    2    2  1  2    1\n",
      "18    0  0    1    0    0    1  1  2    0\n",
      "19    2  1    0    2    2    2  0  0    0\n",
      "20    0  2    0    3    0    1  1  0    0\n",
      "21    1  3    0    0    0    0  0  1    1\n",
      "22    1  0    2    1    0    1  1  2    0\n",
      "23    1  1    1    1    0    0  3  2    1\n",
      "24    1  1    1    2    2    1  0  2    0\n",
      "25    1  0    0    3    0    0  0  0    1\n",
      "26    0  1    0    2    0    1  1  2    0\n",
      "27    2  0    0    1    1    0  1  0    1\n",
      "28    0  0    0    2    0    0  1  3    0\n",
      "29    3  1    1    2    1    1  0  1    0\n",
      "...  .. ..  ...  ...  ...  ... .. ..  ...\n",
      "1451  1  0    0    1    0    1  0  3    0\n",
      "1452  1  0    0    3    2    0  2  0    1\n",
      "1453  0  1    0    0    0    0  2  1    0\n",
      "1454  2  1    0    3    2    1  1  0    1\n",
      "1455  2  2    0    0    0    1  1  1    0\n",
      "1456  0  1    0    3    0    0  1  1    0\n",
      "1457  1  4    0    0    0    1  1  3    0\n",
      "1458  0  3    0    3    0    0  1  2    1\n",
      "1459  1  1    0    3    0    0  3  1    1\n",
      "1460  0  0    0    3    0    2  1  2    1\n",
      "1461  3  0    1    1    2    1  1  1    0\n",
      "1462  1  0    1    0    0    1  1  1    1\n",
      "1463  1  0    0    0    0    1  1  0    0\n",
      "1464  0  0    1    0    1    1  0  0    0\n",
      "1465  0  3    0    1    0    0  1  1    1\n",
      "1466  1  1    0    2    0    0  1  1    1\n",
      "1467  1  1    0    3    0    2  0  2    0\n",
      "1468  0  1    0    0    2    0  0  0    1\n",
      "1469  2  3    0    3    0    1  0  1    0\n",
      "1470  1  4    0    1    0    0  1  0    0\n",
      "1471  2  0    1    1    0    0  1  1    0\n",
      "1472  2  0    1    1    0    2  2  2    1\n",
      "1473  3  0    0    3    1    0  0  2    0\n",
      "1474  1  1    1    2    2    0  0  0    1\n",
      "1475  1  0    0    2    0    0  0  0    0\n",
      "1476  1  3    1    0    2    1  1  2    1\n",
      "1477  0  3    0    1    0    0  2  2    0\n",
      "1478  1  1    0    1    0    1  1  3    0\n",
      "1479  1  1    0    3    0    1  3  1    0\n",
      "1480  0  0    1    1    2    0  0  2    1\n",
      "\n",
      "[1481 rows x 9 columns]\n",
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       1\n",
      "5       0\n",
      "6       0\n",
      "7       0\n",
      "8       0\n",
      "9       0\n",
      "10      1\n",
      "11      1\n",
      "12      0\n",
      "13      0\n",
      "14      1\n",
      "15      0\n",
      "16      0\n",
      "17      1\n",
      "18      1\n",
      "19      0\n",
      "20      0\n",
      "21      0\n",
      "22      1\n",
      "23      0\n",
      "24      0\n",
      "25      1\n",
      "26      1\n",
      "27      0\n",
      "28      0\n",
      "29      0\n",
      "       ..\n",
      "1451    0\n",
      "1452    1\n",
      "1453    0\n",
      "1454    0\n",
      "1455    0\n",
      "1456    1\n",
      "1457    0\n",
      "1458    1\n",
      "1459    0\n",
      "1460    0\n",
      "1461    0\n",
      "1462    1\n",
      "1463    0\n",
      "1464    1\n",
      "1465    1\n",
      "1466    1\n",
      "1467    1\n",
      "1468    0\n",
      "1469    0\n",
      "1470    0\n",
      "1471    0\n",
      "1472    1\n",
      "1473    0\n",
      "1474    1\n",
      "1475    0\n",
      "1476    1\n",
      "1477    0\n",
      "1478    1\n",
      "1479    0\n",
      "1480    1\n",
      "Name: 1.1, Length: 1481, dtype: int64\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/1100\n",
      "1184/1184 [==============================] - 0s 250us/step - loss: 0.6999 - acc: 0.4924 - val_loss: 0.6838 - val_acc: 0.5690\n",
      "Epoch 2/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.6921 - acc: 0.5321 - val_loss: 0.6938 - val_acc: 0.5185\n",
      "Epoch 3/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.6855 - acc: 0.5439 - val_loss: 0.6840 - val_acc: 0.5522\n",
      "Epoch 4/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.6860 - acc: 0.5481 - val_loss: 0.6813 - val_acc: 0.5892\n",
      "Epoch 5/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.6879 - acc: 0.5422 - val_loss: 0.6817 - val_acc: 0.5589\n",
      "Epoch 6/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.6833 - acc: 0.5591 - val_loss: 0.6802 - val_acc: 0.5825\n",
      "Epoch 7/1100\n",
      "1184/1184 [==============================] - 0s 28us/step - loss: 0.6813 - acc: 0.5642 - val_loss: 0.6817 - val_acc: 0.5960\n",
      "Epoch 8/1100\n",
      "1184/1184 [==============================] - 0s 29us/step - loss: 0.6823 - acc: 0.5633 - val_loss: 0.6809 - val_acc: 0.5859\n",
      "Epoch 9/1100\n",
      "1184/1184 [==============================] - 0s 28us/step - loss: 0.6800 - acc: 0.5659 - val_loss: 0.6946 - val_acc: 0.5051\n",
      "Epoch 10/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6772 - acc: 0.5997 - val_loss: 0.6808 - val_acc: 0.5825\n",
      "Epoch 11/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.6773 - acc: 0.5760 - val_loss: 0.6830 - val_acc: 0.5690\n",
      "Epoch 12/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.6758 - acc: 0.5853 - val_loss: 0.6842 - val_acc: 0.5286\n",
      "Epoch 13/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.6772 - acc: 0.5921 - val_loss: 0.6836 - val_acc: 0.5758\n",
      "Epoch 14/1100\n",
      "1184/1184 [==============================] - 0s 28us/step - loss: 0.6744 - acc: 0.5988 - val_loss: 0.6866 - val_acc: 0.5623\n",
      "Epoch 15/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.6713 - acc: 0.5988 - val_loss: 0.6853 - val_acc: 0.5690\n",
      "Epoch 16/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.6740 - acc: 0.5802 - val_loss: 0.6795 - val_acc: 0.5791\n",
      "Epoch 17/1100\n",
      "1184/1184 [==============================] - 0s 35us/step - loss: 0.6706 - acc: 0.5895 - val_loss: 0.6848 - val_acc: 0.5522\n",
      "Epoch 18/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.6690 - acc: 0.6014 - val_loss: 0.6794 - val_acc: 0.5623\n",
      "Epoch 19/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.6695 - acc: 0.5938 - val_loss: 0.6866 - val_acc: 0.5421\n",
      "Epoch 20/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.6665 - acc: 0.6199 - val_loss: 0.6819 - val_acc: 0.5488\n",
      "Epoch 21/1100\n",
      "1184/1184 [==============================] - 0s 34us/step - loss: 0.6672 - acc: 0.6140 - val_loss: 0.6820 - val_acc: 0.5387\n",
      "Epoch 22/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.6672 - acc: 0.6098 - val_loss: 0.6768 - val_acc: 0.5724\n",
      "Epoch 23/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.6659 - acc: 0.6039 - val_loss: 0.6925 - val_acc: 0.5421\n",
      "Epoch 24/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.6657 - acc: 0.6106 - val_loss: 0.6794 - val_acc: 0.5657\n",
      "Epoch 25/1100\n",
      "1184/1184 [==============================] - 0s 32us/step - loss: 0.6644 - acc: 0.6039 - val_loss: 0.6943 - val_acc: 0.5354\n",
      "Epoch 26/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.6619 - acc: 0.6225 - val_loss: 0.6772 - val_acc: 0.5657\n",
      "Epoch 27/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.6590 - acc: 0.6250 - val_loss: 0.6808 - val_acc: 0.5488\n",
      "Epoch 28/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.6598 - acc: 0.6267 - val_loss: 0.6792 - val_acc: 0.5724\n",
      "Epoch 29/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6578 - acc: 0.6334 - val_loss: 0.7082 - val_acc: 0.5387\n",
      "Epoch 30/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.6580 - acc: 0.6182 - val_loss: 0.6786 - val_acc: 0.5623\n",
      "Epoch 31/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.6565 - acc: 0.6292 - val_loss: 0.6822 - val_acc: 0.5421\n",
      "Epoch 32/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6573 - acc: 0.6267 - val_loss: 0.6803 - val_acc: 0.5387\n",
      "Epoch 33/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6582 - acc: 0.6233 - val_loss: 0.6820 - val_acc: 0.5690\n",
      "Epoch 34/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.6534 - acc: 0.6410 - val_loss: 0.6772 - val_acc: 0.5657\n",
      "Epoch 35/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6516 - acc: 0.6309 - val_loss: 0.6897 - val_acc: 0.5253\n",
      "Epoch 36/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6545 - acc: 0.6132 - val_loss: 0.6906 - val_acc: 0.5623\n",
      "Epoch 37/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.6517 - acc: 0.6275 - val_loss: 0.6847 - val_acc: 0.5825\n",
      "Epoch 38/1100\n",
      "1184/1184 [==============================] - 0s 26us/step - loss: 0.6515 - acc: 0.6470 - val_loss: 0.6875 - val_acc: 0.5859\n",
      "Epoch 39/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6518 - acc: 0.6385 - val_loss: 0.6835 - val_acc: 0.5556\n",
      "Epoch 40/1100\n",
      "1184/1184 [==============================] - 0s 25us/step - loss: 0.6491 - acc: 0.6334 - val_loss: 0.6982 - val_acc: 0.5421\n",
      "Epoch 41/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6500 - acc: 0.6503 - val_loss: 0.6847 - val_acc: 0.5859\n",
      "Epoch 42/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6438 - acc: 0.6301 - val_loss: 0.6870 - val_acc: 0.5724\n",
      "Epoch 43/1100\n",
      "1184/1184 [==============================] - 0s 29us/step - loss: 0.6464 - acc: 0.6427 - val_loss: 0.6795 - val_acc: 0.5623\n",
      "Epoch 44/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6456 - acc: 0.6436 - val_loss: 0.6815 - val_acc: 0.5859\n",
      "Epoch 45/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6432 - acc: 0.6571 - val_loss: 0.6839 - val_acc: 0.5354\n",
      "Epoch 46/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.6479 - acc: 0.6208 - val_loss: 0.6809 - val_acc: 0.5926\n",
      "Epoch 47/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6428 - acc: 0.6402 - val_loss: 0.6820 - val_acc: 0.5758\n",
      "Epoch 48/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6398 - acc: 0.6664 - val_loss: 0.6841 - val_acc: 0.5488\n",
      "Epoch 49/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6399 - acc: 0.6554 - val_loss: 0.6809 - val_acc: 0.5589\n",
      "Epoch 50/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.6404 - acc: 0.6495 - val_loss: 0.6863 - val_acc: 0.5791\n",
      "Epoch 51/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6392 - acc: 0.6292 - val_loss: 0.6981 - val_acc: 0.5657\n",
      "Epoch 52/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6389 - acc: 0.6537 - val_loss: 0.6820 - val_acc: 0.5623\n",
      "Epoch 53/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6384 - acc: 0.6394 - val_loss: 0.6825 - val_acc: 0.5926\n",
      "Epoch 54/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.6348 - acc: 0.6655 - val_loss: 0.7222 - val_acc: 0.5421\n",
      "Epoch 55/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6371 - acc: 0.6495 - val_loss: 0.6917 - val_acc: 0.5791\n",
      "Epoch 56/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6352 - acc: 0.6495 - val_loss: 0.6952 - val_acc: 0.5320\n",
      "Epoch 57/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6357 - acc: 0.6402 - val_loss: 0.6864 - val_acc: 0.5488\n",
      "Epoch 58/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.6331 - acc: 0.6537 - val_loss: 0.7022 - val_acc: 0.5589\n",
      "Epoch 59/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6309 - acc: 0.6529 - val_loss: 0.6811 - val_acc: 0.5825\n",
      "Epoch 60/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6287 - acc: 0.6706 - val_loss: 0.6923 - val_acc: 0.5051\n",
      "Epoch 61/1100\n",
      "1184/1184 [==============================] - 0s 13us/step - loss: 0.6310 - acc: 0.6546 - val_loss: 0.7182 - val_acc: 0.5488\n",
      "Epoch 62/1100\n",
      "1184/1184 [==============================] - 0s 14us/step - loss: 0.6303 - acc: 0.6546 - val_loss: 0.6979 - val_acc: 0.5589\n",
      "Epoch 63/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.6299 - acc: 0.6579 - val_loss: 0.6879 - val_acc: 0.5488\n",
      "Epoch 64/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6248 - acc: 0.6698 - val_loss: 0.7390 - val_acc: 0.5320\n",
      "Epoch 65/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6270 - acc: 0.6571 - val_loss: 0.6862 - val_acc: 0.5825\n",
      "Epoch 66/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.6254 - acc: 0.6579 - val_loss: 0.6843 - val_acc: 0.5589\n",
      "Epoch 67/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.6246 - acc: 0.6596 - val_loss: 0.6840 - val_acc: 0.5791\n",
      "Epoch 68/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.6232 - acc: 0.6731 - val_loss: 0.6841 - val_acc: 0.5488\n",
      "Epoch 69/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6255 - acc: 0.6655 - val_loss: 0.6874 - val_acc: 0.5791\n",
      "Epoch 70/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6215 - acc: 0.6630 - val_loss: 0.6829 - val_acc: 0.5791\n",
      "Epoch 71/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6227 - acc: 0.6596 - val_loss: 0.6911 - val_acc: 0.5892\n",
      "Epoch 72/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6203 - acc: 0.6630 - val_loss: 0.6853 - val_acc: 0.5825\n",
      "Epoch 73/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6186 - acc: 0.6782 - val_loss: 0.6961 - val_acc: 0.5825\n",
      "Epoch 74/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6178 - acc: 0.6698 - val_loss: 0.6822 - val_acc: 0.5791\n",
      "Epoch 75/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6203 - acc: 0.6588 - val_loss: 0.6862 - val_acc: 0.5488\n",
      "Epoch 76/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6159 - acc: 0.6723 - val_loss: 0.6862 - val_acc: 0.5758\n",
      "Epoch 77/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6155 - acc: 0.6824 - val_loss: 0.6875 - val_acc: 0.5488\n",
      "Epoch 78/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6175 - acc: 0.6706 - val_loss: 0.7002 - val_acc: 0.5152\n",
      "Epoch 79/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6182 - acc: 0.6723 - val_loss: 0.6875 - val_acc: 0.5960\n",
      "Epoch 80/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6116 - acc: 0.6664 - val_loss: 0.6915 - val_acc: 0.5825\n",
      "Epoch 81/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6131 - acc: 0.6833 - val_loss: 0.6902 - val_acc: 0.5892\n",
      "Epoch 82/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6127 - acc: 0.6757 - val_loss: 0.6881 - val_acc: 0.5690\n",
      "Epoch 83/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6092 - acc: 0.6833 - val_loss: 0.6949 - val_acc: 0.5219\n",
      "Epoch 84/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.6111 - acc: 0.6917 - val_loss: 0.6875 - val_acc: 0.5960\n",
      "Epoch 85/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6073 - acc: 0.6900 - val_loss: 0.6898 - val_acc: 0.5825\n",
      "Epoch 86/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6125 - acc: 0.6715 - val_loss: 0.6927 - val_acc: 0.5892\n",
      "Epoch 87/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6073 - acc: 0.6850 - val_loss: 0.6968 - val_acc: 0.5320\n",
      "Epoch 88/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6097 - acc: 0.6791 - val_loss: 0.6978 - val_acc: 0.5926\n",
      "Epoch 89/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6047 - acc: 0.6909 - val_loss: 0.7059 - val_acc: 0.5185\n",
      "Epoch 90/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.6091 - acc: 0.6748 - val_loss: 0.6968 - val_acc: 0.5421\n",
      "Epoch 91/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6053 - acc: 0.6858 - val_loss: 0.7012 - val_acc: 0.5152\n",
      "Epoch 92/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6049 - acc: 0.6833 - val_loss: 0.6966 - val_acc: 0.5657\n",
      "Epoch 93/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6035 - acc: 0.6791 - val_loss: 0.7014 - val_acc: 0.5724\n",
      "Epoch 94/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.6013 - acc: 0.6985 - val_loss: 0.6910 - val_acc: 0.5758\n",
      "Epoch 95/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6003 - acc: 0.6909 - val_loss: 0.7145 - val_acc: 0.5758\n",
      "Epoch 96/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.6007 - acc: 0.6765 - val_loss: 0.6995 - val_acc: 0.5320\n",
      "Epoch 97/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5985 - acc: 0.6900 - val_loss: 0.7006 - val_acc: 0.5589\n",
      "Epoch 98/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5988 - acc: 0.6892 - val_loss: 0.6963 - val_acc: 0.5758\n",
      "Epoch 99/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5984 - acc: 0.6976 - val_loss: 0.6951 - val_acc: 0.5791\n",
      "Epoch 100/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5957 - acc: 0.6943 - val_loss: 0.7149 - val_acc: 0.5758\n",
      "Epoch 101/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5985 - acc: 0.6892 - val_loss: 0.7187 - val_acc: 0.5589\n",
      "Epoch 102/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5962 - acc: 0.6791 - val_loss: 0.7025 - val_acc: 0.5152\n",
      "Epoch 103/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5985 - acc: 0.6740 - val_loss: 0.7343 - val_acc: 0.5522\n",
      "Epoch 104/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5984 - acc: 0.6959 - val_loss: 0.6936 - val_acc: 0.5690\n",
      "Epoch 105/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5904 - acc: 0.7137 - val_loss: 0.7013 - val_acc: 0.5758\n",
      "Epoch 106/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5953 - acc: 0.6867 - val_loss: 0.6968 - val_acc: 0.5455\n",
      "Epoch 107/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5919 - acc: 0.6959 - val_loss: 0.6959 - val_acc: 0.5522\n",
      "Epoch 108/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5922 - acc: 0.6943 - val_loss: 0.6982 - val_acc: 0.5488\n",
      "Epoch 109/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5922 - acc: 0.7002 - val_loss: 0.6968 - val_acc: 0.5657\n",
      "Epoch 110/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5880 - acc: 0.7035 - val_loss: 0.7032 - val_acc: 0.5354\n",
      "Epoch 111/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5873 - acc: 0.7019 - val_loss: 0.7014 - val_acc: 0.5320\n",
      "Epoch 112/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5907 - acc: 0.6968 - val_loss: 0.7006 - val_acc: 0.5488\n",
      "Epoch 113/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5873 - acc: 0.7103 - val_loss: 0.7103 - val_acc: 0.5690\n",
      "Epoch 114/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5860 - acc: 0.7052 - val_loss: 0.7041 - val_acc: 0.5354\n",
      "Epoch 115/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5847 - acc: 0.6993 - val_loss: 0.7033 - val_acc: 0.5724\n",
      "Epoch 116/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5854 - acc: 0.6934 - val_loss: 0.7182 - val_acc: 0.5589\n",
      "Epoch 117/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5823 - acc: 0.7111 - val_loss: 0.6999 - val_acc: 0.5825\n",
      "Epoch 118/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5804 - acc: 0.7069 - val_loss: 0.7218 - val_acc: 0.5690\n",
      "Epoch 119/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5824 - acc: 0.7027 - val_loss: 0.7115 - val_acc: 0.5522\n",
      "Epoch 120/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5805 - acc: 0.7120 - val_loss: 0.7302 - val_acc: 0.5724\n",
      "Epoch 121/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5807 - acc: 0.7010 - val_loss: 0.7113 - val_acc: 0.5960\n",
      "Epoch 122/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5777 - acc: 0.7145 - val_loss: 0.7048 - val_acc: 0.5488\n",
      "Epoch 123/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5787 - acc: 0.6976 - val_loss: 0.7069 - val_acc: 0.5387\n",
      "Epoch 124/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5752 - acc: 0.7120 - val_loss: 0.7074 - val_acc: 0.5286\n",
      "Epoch 125/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5781 - acc: 0.7171 - val_loss: 0.7133 - val_acc: 0.5118\n",
      "Epoch 126/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5769 - acc: 0.7086 - val_loss: 0.7093 - val_acc: 0.5253\n",
      "Epoch 127/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5755 - acc: 0.7171 - val_loss: 0.7356 - val_acc: 0.5589\n",
      "Epoch 128/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5744 - acc: 0.7196 - val_loss: 0.7129 - val_acc: 0.5354\n",
      "Epoch 129/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.5733 - acc: 0.7154 - val_loss: 0.7169 - val_acc: 0.5758\n",
      "Epoch 130/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5737 - acc: 0.7188 - val_loss: 0.7121 - val_acc: 0.5354\n",
      "Epoch 131/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5758 - acc: 0.7069 - val_loss: 0.7114 - val_acc: 0.5253\n",
      "Epoch 132/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5724 - acc: 0.7179 - val_loss: 0.7137 - val_acc: 0.5623\n",
      "Epoch 133/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5690 - acc: 0.7154 - val_loss: 0.7678 - val_acc: 0.5455\n",
      "Epoch 134/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5748 - acc: 0.7120 - val_loss: 0.7016 - val_acc: 0.5623\n",
      "Epoch 135/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5689 - acc: 0.7196 - val_loss: 0.7191 - val_acc: 0.5791\n",
      "Epoch 136/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5662 - acc: 0.7306 - val_loss: 0.7511 - val_acc: 0.5556\n",
      "Epoch 137/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5703 - acc: 0.7137 - val_loss: 0.7192 - val_acc: 0.5623\n",
      "Epoch 138/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5642 - acc: 0.7306 - val_loss: 0.7093 - val_acc: 0.5320\n",
      "Epoch 139/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5682 - acc: 0.7188 - val_loss: 0.7101 - val_acc: 0.5623\n",
      "Epoch 140/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5650 - acc: 0.7289 - val_loss: 0.7164 - val_acc: 0.5589\n",
      "Epoch 141/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5644 - acc: 0.7221 - val_loss: 0.7227 - val_acc: 0.5690\n",
      "Epoch 142/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5649 - acc: 0.7221 - val_loss: 0.7124 - val_acc: 0.5859\n",
      "Epoch 143/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5617 - acc: 0.7264 - val_loss: 0.7117 - val_acc: 0.5421\n",
      "Epoch 144/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5632 - acc: 0.7272 - val_loss: 0.7152 - val_acc: 0.5421\n",
      "Epoch 145/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5604 - acc: 0.7204 - val_loss: 0.7274 - val_acc: 0.5758\n",
      "Epoch 146/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5629 - acc: 0.7128 - val_loss: 0.7123 - val_acc: 0.5320\n",
      "Epoch 147/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5592 - acc: 0.7314 - val_loss: 0.7386 - val_acc: 0.5623\n",
      "Epoch 148/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5584 - acc: 0.7171 - val_loss: 0.7212 - val_acc: 0.5219\n",
      "Epoch 149/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5572 - acc: 0.7196 - val_loss: 0.7185 - val_acc: 0.5657\n",
      "Epoch 150/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.5547 - acc: 0.7373 - val_loss: 0.7104 - val_acc: 0.5421\n",
      "Epoch 151/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.5574 - acc: 0.7382 - val_loss: 0.7159 - val_acc: 0.5488\n",
      "Epoch 152/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5588 - acc: 0.7314 - val_loss: 0.7193 - val_acc: 0.5219\n",
      "Epoch 153/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5540 - acc: 0.7280 - val_loss: 0.7323 - val_acc: 0.5589\n",
      "Epoch 154/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5513 - acc: 0.7390 - val_loss: 0.7175 - val_acc: 0.5421\n",
      "Epoch 155/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5577 - acc: 0.7323 - val_loss: 0.7128 - val_acc: 0.5320\n",
      "Epoch 156/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5506 - acc: 0.7390 - val_loss: 0.7197 - val_acc: 0.5825\n",
      "Epoch 157/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5522 - acc: 0.7348 - val_loss: 0.7170 - val_acc: 0.5623\n",
      "Epoch 158/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5501 - acc: 0.7204 - val_loss: 0.7130 - val_acc: 0.5320\n",
      "Epoch 159/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5512 - acc: 0.7272 - val_loss: 0.7361 - val_acc: 0.5354\n",
      "Epoch 160/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5494 - acc: 0.7306 - val_loss: 0.7216 - val_acc: 0.5421\n",
      "Epoch 161/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5487 - acc: 0.7466 - val_loss: 0.7220 - val_acc: 0.5387\n",
      "Epoch 162/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5467 - acc: 0.7534 - val_loss: 0.7268 - val_acc: 0.5286\n",
      "Epoch 163/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5468 - acc: 0.7525 - val_loss: 0.7254 - val_acc: 0.5286\n",
      "Epoch 164/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5464 - acc: 0.7399 - val_loss: 0.7220 - val_acc: 0.5690\n",
      "Epoch 165/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5520 - acc: 0.7213 - val_loss: 0.7182 - val_acc: 0.5589\n",
      "Epoch 166/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5454 - acc: 0.7492 - val_loss: 0.7580 - val_acc: 0.5690\n",
      "Epoch 167/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5437 - acc: 0.7441 - val_loss: 0.7291 - val_acc: 0.5556\n",
      "Epoch 168/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5421 - acc: 0.7390 - val_loss: 0.7300 - val_acc: 0.5488\n",
      "Epoch 169/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5428 - acc: 0.7458 - val_loss: 0.7264 - val_acc: 0.5421\n",
      "Epoch 170/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5478 - acc: 0.7399 - val_loss: 0.7184 - val_acc: 0.5421\n",
      "Epoch 171/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5393 - acc: 0.7576 - val_loss: 0.7254 - val_acc: 0.5219\n",
      "Epoch 172/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5404 - acc: 0.7432 - val_loss: 0.7284 - val_acc: 0.5623\n",
      "Epoch 173/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5392 - acc: 0.7356 - val_loss: 0.7211 - val_acc: 0.5219\n",
      "Epoch 174/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5371 - acc: 0.7542 - val_loss: 0.7589 - val_acc: 0.5589\n",
      "Epoch 175/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5393 - acc: 0.7424 - val_loss: 0.7242 - val_acc: 0.5387\n",
      "Epoch 176/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5376 - acc: 0.7416 - val_loss: 0.7349 - val_acc: 0.5926\n",
      "Epoch 177/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5320 - acc: 0.7432 - val_loss: 0.7376 - val_acc: 0.5657\n",
      "Epoch 178/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5375 - acc: 0.7500 - val_loss: 0.7620 - val_acc: 0.5623\n",
      "Epoch 179/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5387 - acc: 0.7483 - val_loss: 0.7389 - val_acc: 0.5758\n",
      "Epoch 180/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5341 - acc: 0.7466 - val_loss: 0.7532 - val_acc: 0.5354\n",
      "Epoch 181/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5372 - acc: 0.7432 - val_loss: 0.7376 - val_acc: 0.5724\n",
      "Epoch 182/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5320 - acc: 0.7492 - val_loss: 0.7245 - val_acc: 0.5354\n",
      "Epoch 183/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5335 - acc: 0.7534 - val_loss: 0.7229 - val_acc: 0.5387\n",
      "Epoch 184/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5319 - acc: 0.7568 - val_loss: 0.7606 - val_acc: 0.5387\n",
      "Epoch 185/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5354 - acc: 0.7492 - val_loss: 0.7351 - val_acc: 0.5825\n",
      "Epoch 186/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5307 - acc: 0.7390 - val_loss: 0.7375 - val_acc: 0.5286\n",
      "Epoch 187/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.5287 - acc: 0.7593 - val_loss: 0.7312 - val_acc: 0.5320\n",
      "Epoch 188/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5309 - acc: 0.7601 - val_loss: 0.7312 - val_acc: 0.5589\n",
      "Epoch 189/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5269 - acc: 0.7584 - val_loss: 0.7415 - val_acc: 0.5758\n",
      "Epoch 190/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5280 - acc: 0.7517 - val_loss: 0.7398 - val_acc: 0.5421\n",
      "Epoch 191/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5251 - acc: 0.7618 - val_loss: 0.7388 - val_acc: 0.5724\n",
      "Epoch 192/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5274 - acc: 0.7584 - val_loss: 0.7392 - val_acc: 0.5286\n",
      "Epoch 193/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5251 - acc: 0.7593 - val_loss: 0.7312 - val_acc: 0.5657\n",
      "Epoch 194/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5240 - acc: 0.7618 - val_loss: 0.7352 - val_acc: 0.5455\n",
      "Epoch 195/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5229 - acc: 0.7703 - val_loss: 0.7410 - val_acc: 0.5758\n",
      "Epoch 196/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5212 - acc: 0.7627 - val_loss: 0.7464 - val_acc: 0.5623\n",
      "Epoch 197/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5227 - acc: 0.7551 - val_loss: 0.7477 - val_acc: 0.5892\n",
      "Epoch 198/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5260 - acc: 0.7593 - val_loss: 0.7461 - val_acc: 0.5825\n",
      "Epoch 199/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5202 - acc: 0.7508 - val_loss: 0.7404 - val_acc: 0.5219\n",
      "Epoch 200/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5204 - acc: 0.7542 - val_loss: 0.7443 - val_acc: 0.5690\n",
      "Epoch 201/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5192 - acc: 0.7584 - val_loss: 0.7403 - val_acc: 0.5589\n",
      "Epoch 202/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5206 - acc: 0.7551 - val_loss: 0.7444 - val_acc: 0.5354\n",
      "Epoch 203/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.5225 - acc: 0.7525 - val_loss: 0.7665 - val_acc: 0.5488\n",
      "Epoch 204/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5207 - acc: 0.7644 - val_loss: 0.7370 - val_acc: 0.5253\n",
      "Epoch 205/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5177 - acc: 0.7677 - val_loss: 0.7277 - val_acc: 0.5522\n",
      "Epoch 206/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5148 - acc: 0.7829 - val_loss: 0.7328 - val_acc: 0.5320\n",
      "Epoch 207/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5200 - acc: 0.7686 - val_loss: 0.7713 - val_acc: 0.5657\n",
      "Epoch 208/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5167 - acc: 0.7711 - val_loss: 0.7457 - val_acc: 0.5724\n",
      "Epoch 209/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5125 - acc: 0.7736 - val_loss: 0.7364 - val_acc: 0.5185\n",
      "Epoch 210/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5113 - acc: 0.7736 - val_loss: 0.7467 - val_acc: 0.5286\n",
      "Epoch 211/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5146 - acc: 0.7677 - val_loss: 0.7357 - val_acc: 0.5421\n",
      "Epoch 212/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5136 - acc: 0.7753 - val_loss: 0.7540 - val_acc: 0.5488\n",
      "Epoch 213/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5114 - acc: 0.7610 - val_loss: 0.7825 - val_acc: 0.5421\n",
      "Epoch 214/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.5138 - acc: 0.7627 - val_loss: 0.7497 - val_acc: 0.5892\n",
      "Epoch 215/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5131 - acc: 0.7627 - val_loss: 0.7371 - val_acc: 0.5488\n",
      "Epoch 216/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5113 - acc: 0.7745 - val_loss: 0.7387 - val_acc: 0.5387\n",
      "Epoch 217/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5049 - acc: 0.7779 - val_loss: 0.7411 - val_acc: 0.5253\n",
      "Epoch 218/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5136 - acc: 0.7576 - val_loss: 0.7419 - val_acc: 0.5421\n",
      "Epoch 219/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5077 - acc: 0.7745 - val_loss: 0.8182 - val_acc: 0.5387\n",
      "Epoch 220/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5105 - acc: 0.7677 - val_loss: 0.7418 - val_acc: 0.5522\n",
      "Epoch 221/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.5072 - acc: 0.7736 - val_loss: 0.7538 - val_acc: 0.5825\n",
      "Epoch 222/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.5062 - acc: 0.7720 - val_loss: 0.7634 - val_acc: 0.5690\n",
      "Epoch 223/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5135 - acc: 0.7576 - val_loss: 0.7586 - val_acc: 0.5320\n",
      "Epoch 224/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5063 - acc: 0.7559 - val_loss: 0.7677 - val_acc: 0.5556\n",
      "Epoch 225/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5065 - acc: 0.7779 - val_loss: 0.7489 - val_acc: 0.5859\n",
      "Epoch 226/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5042 - acc: 0.7720 - val_loss: 0.7497 - val_acc: 0.5758\n",
      "Epoch 227/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4998 - acc: 0.7753 - val_loss: 0.7477 - val_acc: 0.5421\n",
      "Epoch 228/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4999 - acc: 0.7897 - val_loss: 0.7483 - val_acc: 0.5354\n",
      "Epoch 229/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5044 - acc: 0.7703 - val_loss: 0.7486 - val_acc: 0.5320\n",
      "Epoch 230/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4998 - acc: 0.7787 - val_loss: 0.7566 - val_acc: 0.5589\n",
      "Epoch 231/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4971 - acc: 0.7762 - val_loss: 0.7585 - val_acc: 0.5084\n",
      "Epoch 232/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5031 - acc: 0.7846 - val_loss: 0.7547 - val_acc: 0.5286\n",
      "Epoch 233/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.5017 - acc: 0.7770 - val_loss: 0.7872 - val_acc: 0.5488\n",
      "Epoch 234/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.5002 - acc: 0.7686 - val_loss: 0.7512 - val_acc: 0.5286\n",
      "Epoch 235/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4952 - acc: 0.7838 - val_loss: 0.7595 - val_acc: 0.5825\n",
      "Epoch 236/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4990 - acc: 0.7812 - val_loss: 0.7706 - val_acc: 0.5758\n",
      "Epoch 237/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.5003 - acc: 0.7838 - val_loss: 0.7529 - val_acc: 0.5488\n",
      "Epoch 238/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4938 - acc: 0.7905 - val_loss: 0.7486 - val_acc: 0.5354\n",
      "Epoch 239/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4963 - acc: 0.7796 - val_loss: 0.7827 - val_acc: 0.5589\n",
      "Epoch 240/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4953 - acc: 0.7821 - val_loss: 0.7501 - val_acc: 0.5657\n",
      "Epoch 241/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.4936 - acc: 0.7812 - val_loss: 0.7600 - val_acc: 0.5589\n",
      "Epoch 242/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4881 - acc: 0.7981 - val_loss: 0.7980 - val_acc: 0.5825\n",
      "Epoch 243/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4964 - acc: 0.7770 - val_loss: 0.7586 - val_acc: 0.5387\n",
      "Epoch 244/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4936 - acc: 0.7821 - val_loss: 0.7570 - val_acc: 0.5522\n",
      "Epoch 245/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4887 - acc: 0.7905 - val_loss: 0.7773 - val_acc: 0.5455\n",
      "Epoch 246/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4898 - acc: 0.7812 - val_loss: 0.7549 - val_acc: 0.5421\n",
      "Epoch 247/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4961 - acc: 0.7779 - val_loss: 0.7658 - val_acc: 0.5320\n",
      "Epoch 248/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4912 - acc: 0.7762 - val_loss: 0.7583 - val_acc: 0.5623\n",
      "Epoch 249/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4870 - acc: 0.7922 - val_loss: 0.7600 - val_acc: 0.5455\n",
      "Epoch 250/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4934 - acc: 0.7948 - val_loss: 0.7636 - val_acc: 0.5690\n",
      "Epoch 251/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4868 - acc: 0.7812 - val_loss: 0.7817 - val_acc: 0.5488\n",
      "Epoch 252/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.4908 - acc: 0.7838 - val_loss: 0.8004 - val_acc: 0.5589\n",
      "Epoch 253/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4931 - acc: 0.7762 - val_loss: 0.8001 - val_acc: 0.5623\n",
      "Epoch 254/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4841 - acc: 0.7880 - val_loss: 0.7506 - val_acc: 0.5488\n",
      "Epoch 255/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4862 - acc: 0.7897 - val_loss: 0.7696 - val_acc: 0.5421\n",
      "Epoch 256/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4823 - acc: 0.8032 - val_loss: 0.7754 - val_acc: 0.5623\n",
      "Epoch 257/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4818 - acc: 0.7914 - val_loss: 0.7513 - val_acc: 0.5421\n",
      "Epoch 258/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4832 - acc: 0.7889 - val_loss: 0.8049 - val_acc: 0.5488\n",
      "Epoch 259/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4834 - acc: 0.7897 - val_loss: 0.7595 - val_acc: 0.5556\n",
      "Epoch 260/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4844 - acc: 0.7965 - val_loss: 0.7763 - val_acc: 0.5657\n",
      "Epoch 261/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4799 - acc: 0.7948 - val_loss: 0.7689 - val_acc: 0.5286\n",
      "Epoch 262/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4805 - acc: 0.7855 - val_loss: 0.7666 - val_acc: 0.5387\n",
      "Epoch 263/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4844 - acc: 0.7905 - val_loss: 0.7683 - val_acc: 0.5286\n",
      "Epoch 264/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4789 - acc: 0.7914 - val_loss: 0.7615 - val_acc: 0.5421\n",
      "Epoch 265/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4766 - acc: 0.7990 - val_loss: 0.7731 - val_acc: 0.5724\n",
      "Epoch 266/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4777 - acc: 0.7897 - val_loss: 0.7804 - val_acc: 0.5354\n",
      "Epoch 267/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4790 - acc: 0.7855 - val_loss: 0.7762 - val_acc: 0.5387\n",
      "Epoch 268/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4779 - acc: 0.8007 - val_loss: 0.7693 - val_acc: 0.5488\n",
      "Epoch 269/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4768 - acc: 0.7931 - val_loss: 0.7674 - val_acc: 0.5657\n",
      "Epoch 270/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4724 - acc: 0.7981 - val_loss: 0.7752 - val_acc: 0.5556\n",
      "Epoch 271/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4831 - acc: 0.7855 - val_loss: 0.7691 - val_acc: 0.5455\n",
      "Epoch 272/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4743 - acc: 0.7939 - val_loss: 0.7715 - val_acc: 0.5387\n",
      "Epoch 273/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4755 - acc: 0.8007 - val_loss: 0.7797 - val_acc: 0.5623\n",
      "Epoch 274/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4709 - acc: 0.7914 - val_loss: 0.7883 - val_acc: 0.5387\n",
      "Epoch 275/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4756 - acc: 0.7956 - val_loss: 0.7799 - val_acc: 0.5455\n",
      "Epoch 276/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4723 - acc: 0.7889 - val_loss: 0.7781 - val_acc: 0.5253\n",
      "Epoch 277/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4731 - acc: 0.8049 - val_loss: 0.7806 - val_acc: 0.5421\n",
      "Epoch 278/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4752 - acc: 0.7990 - val_loss: 0.7686 - val_acc: 0.5589\n",
      "Epoch 279/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4675 - acc: 0.8057 - val_loss: 0.7802 - val_acc: 0.5690\n",
      "Epoch 280/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4727 - acc: 0.7922 - val_loss: 0.8021 - val_acc: 0.5657\n",
      "Epoch 281/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4665 - acc: 0.8015 - val_loss: 0.8054 - val_acc: 0.5657\n",
      "Epoch 282/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.4786 - acc: 0.7905 - val_loss: 0.7679 - val_acc: 0.5556\n",
      "Epoch 283/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4632 - acc: 0.8108 - val_loss: 0.7875 - val_acc: 0.5623\n",
      "Epoch 284/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4657 - acc: 0.8108 - val_loss: 0.7780 - val_acc: 0.5387\n",
      "Epoch 285/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4674 - acc: 0.8066 - val_loss: 0.7710 - val_acc: 0.5488\n",
      "Epoch 286/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4670 - acc: 0.8083 - val_loss: 0.7730 - val_acc: 0.5421\n",
      "Epoch 287/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4698 - acc: 0.7897 - val_loss: 0.7779 - val_acc: 0.5387\n",
      "Epoch 288/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4669 - acc: 0.7965 - val_loss: 0.7787 - val_acc: 0.5354\n",
      "Epoch 289/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4654 - acc: 0.8083 - val_loss: 0.7962 - val_acc: 0.5455\n",
      "Epoch 290/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4630 - acc: 0.8117 - val_loss: 0.7826 - val_acc: 0.5354\n",
      "Epoch 291/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4651 - acc: 0.8015 - val_loss: 0.7884 - val_acc: 0.5657\n",
      "Epoch 292/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4628 - acc: 0.8015 - val_loss: 0.7729 - val_acc: 0.5387\n",
      "Epoch 293/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4645 - acc: 0.8057 - val_loss: 0.7740 - val_acc: 0.5354\n",
      "Epoch 294/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4618 - acc: 0.8100 - val_loss: 0.7882 - val_acc: 0.5589\n",
      "Epoch 295/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4612 - acc: 0.8100 - val_loss: 0.8241 - val_acc: 0.5522\n",
      "Epoch 296/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4655 - acc: 0.8041 - val_loss: 0.7756 - val_acc: 0.5488\n",
      "Epoch 297/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4599 - acc: 0.8066 - val_loss: 0.7778 - val_acc: 0.5556\n",
      "Epoch 298/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4556 - acc: 0.8074 - val_loss: 0.8050 - val_acc: 0.5556\n",
      "Epoch 299/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4605 - acc: 0.8066 - val_loss: 0.7784 - val_acc: 0.5455\n",
      "Epoch 300/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4583 - acc: 0.8041 - val_loss: 0.7784 - val_acc: 0.5623\n",
      "Epoch 301/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4601 - acc: 0.7973 - val_loss: 0.7818 - val_acc: 0.5387\n",
      "Epoch 302/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4556 - acc: 0.8159 - val_loss: 0.7944 - val_acc: 0.5387\n",
      "Epoch 303/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4569 - acc: 0.8176 - val_loss: 0.7752 - val_acc: 0.5657\n",
      "Epoch 304/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4524 - acc: 0.8159 - val_loss: 0.8274 - val_acc: 0.5623\n",
      "Epoch 305/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4544 - acc: 0.8083 - val_loss: 0.7783 - val_acc: 0.5623\n",
      "Epoch 306/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4525 - acc: 0.7981 - val_loss: 0.8060 - val_acc: 0.5690\n",
      "Epoch 307/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4605 - acc: 0.7981 - val_loss: 0.7871 - val_acc: 0.5556\n",
      "Epoch 308/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4553 - acc: 0.8100 - val_loss: 0.7877 - val_acc: 0.5455\n",
      "Epoch 309/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4506 - acc: 0.8057 - val_loss: 0.7946 - val_acc: 0.5320\n",
      "Epoch 310/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4582 - acc: 0.7965 - val_loss: 0.7800 - val_acc: 0.5286\n",
      "Epoch 311/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4495 - acc: 0.8201 - val_loss: 0.8280 - val_acc: 0.5657\n",
      "Epoch 312/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4504 - acc: 0.8091 - val_loss: 0.8233 - val_acc: 0.5522\n",
      "Epoch 313/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4514 - acc: 0.7990 - val_loss: 0.8420 - val_acc: 0.5320\n",
      "Epoch 314/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4504 - acc: 0.8226 - val_loss: 0.7768 - val_acc: 0.5657\n",
      "Epoch 315/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4462 - acc: 0.8260 - val_loss: 0.7813 - val_acc: 0.5556\n",
      "Epoch 316/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4430 - acc: 0.8260 - val_loss: 0.7916 - val_acc: 0.5488\n",
      "Epoch 317/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4522 - acc: 0.8125 - val_loss: 0.7845 - val_acc: 0.5354\n",
      "Epoch 318/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4510 - acc: 0.8100 - val_loss: 0.7855 - val_acc: 0.5623\n",
      "Epoch 319/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4526 - acc: 0.8159 - val_loss: 0.7972 - val_acc: 0.5387\n",
      "Epoch 320/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4473 - acc: 0.8133 - val_loss: 0.8253 - val_acc: 0.5690\n",
      "Epoch 321/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4542 - acc: 0.7973 - val_loss: 0.7984 - val_acc: 0.5488\n",
      "Epoch 322/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4431 - acc: 0.8285 - val_loss: 0.7898 - val_acc: 0.5589\n",
      "Epoch 323/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4441 - acc: 0.8184 - val_loss: 0.7913 - val_acc: 0.5455\n",
      "Epoch 324/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4471 - acc: 0.8176 - val_loss: 0.8201 - val_acc: 0.5286\n",
      "Epoch 325/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4432 - acc: 0.8125 - val_loss: 0.7925 - val_acc: 0.5421\n",
      "Epoch 326/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4435 - acc: 0.8218 - val_loss: 0.7954 - val_acc: 0.5589\n",
      "Epoch 327/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4425 - acc: 0.8193 - val_loss: 0.7930 - val_acc: 0.5387\n",
      "Epoch 328/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4391 - acc: 0.8269 - val_loss: 0.7956 - val_acc: 0.5690\n",
      "Epoch 329/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4407 - acc: 0.8201 - val_loss: 0.7968 - val_acc: 0.5253\n",
      "Epoch 330/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4409 - acc: 0.8193 - val_loss: 0.7954 - val_acc: 0.5219\n",
      "Epoch 331/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4389 - acc: 0.8302 - val_loss: 0.8113 - val_acc: 0.5589\n",
      "Epoch 332/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4381 - acc: 0.8269 - val_loss: 0.7879 - val_acc: 0.5455\n",
      "Epoch 333/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4335 - acc: 0.8277 - val_loss: 0.7950 - val_acc: 0.5421\n",
      "Epoch 334/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4390 - acc: 0.8252 - val_loss: 0.8059 - val_acc: 0.5455\n",
      "Epoch 335/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4431 - acc: 0.8193 - val_loss: 0.7926 - val_acc: 0.5253\n",
      "Epoch 336/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4389 - acc: 0.8133 - val_loss: 0.8057 - val_acc: 0.5354\n",
      "Epoch 337/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4337 - acc: 0.8361 - val_loss: 0.8010 - val_acc: 0.5556\n",
      "Epoch 338/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4371 - acc: 0.8218 - val_loss: 0.7924 - val_acc: 0.5421\n",
      "Epoch 339/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4385 - acc: 0.8277 - val_loss: 0.7996 - val_acc: 0.5657\n",
      "Epoch 340/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4386 - acc: 0.8201 - val_loss: 0.7981 - val_acc: 0.5320\n",
      "Epoch 341/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4337 - acc: 0.8269 - val_loss: 0.7957 - val_acc: 0.5488\n",
      "Epoch 342/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4300 - acc: 0.8277 - val_loss: 0.8015 - val_acc: 0.5589\n",
      "Epoch 343/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4306 - acc: 0.8311 - val_loss: 0.8102 - val_acc: 0.5522\n",
      "Epoch 344/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4315 - acc: 0.8252 - val_loss: 0.8065 - val_acc: 0.5455\n",
      "Epoch 345/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4318 - acc: 0.8277 - val_loss: 0.8046 - val_acc: 0.5522\n",
      "Epoch 346/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4310 - acc: 0.8294 - val_loss: 0.7993 - val_acc: 0.5556\n",
      "Epoch 347/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4333 - acc: 0.8201 - val_loss: 0.8080 - val_acc: 0.5556\n",
      "Epoch 348/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4265 - acc: 0.8294 - val_loss: 0.8573 - val_acc: 0.5455\n",
      "Epoch 349/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4315 - acc: 0.8252 - val_loss: 0.8000 - val_acc: 0.5589\n",
      "Epoch 350/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4259 - acc: 0.8311 - val_loss: 0.8153 - val_acc: 0.5455\n",
      "Epoch 351/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4322 - acc: 0.8176 - val_loss: 0.7980 - val_acc: 0.5690\n",
      "Epoch 352/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4259 - acc: 0.8387 - val_loss: 0.8306 - val_acc: 0.5387\n",
      "Epoch 353/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4226 - acc: 0.8429 - val_loss: 0.8149 - val_acc: 0.5421\n",
      "Epoch 354/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4244 - acc: 0.8285 - val_loss: 0.8369 - val_acc: 0.5387\n",
      "Epoch 355/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4204 - acc: 0.8429 - val_loss: 0.8094 - val_acc: 0.5791\n",
      "Epoch 356/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4358 - acc: 0.8100 - val_loss: 0.8193 - val_acc: 0.5387\n",
      "Epoch 357/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4283 - acc: 0.8277 - val_loss: 0.8079 - val_acc: 0.5556\n",
      "Epoch 358/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.4259 - acc: 0.8260 - val_loss: 0.8029 - val_acc: 0.5488\n",
      "Epoch 359/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4235 - acc: 0.8294 - val_loss: 0.8194 - val_acc: 0.5522\n",
      "Epoch 360/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4279 - acc: 0.8269 - val_loss: 0.8082 - val_acc: 0.5488\n",
      "Epoch 361/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4219 - acc: 0.8395 - val_loss: 0.8573 - val_acc: 0.5522\n",
      "Epoch 362/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4223 - acc: 0.8353 - val_loss: 0.8183 - val_acc: 0.5657\n",
      "Epoch 363/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4220 - acc: 0.8302 - val_loss: 0.8216 - val_acc: 0.5387\n",
      "Epoch 364/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4201 - acc: 0.8370 - val_loss: 0.8138 - val_acc: 0.5522\n",
      "Epoch 365/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4248 - acc: 0.8277 - val_loss: 0.8340 - val_acc: 0.5556\n",
      "Epoch 366/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4222 - acc: 0.8209 - val_loss: 0.8161 - val_acc: 0.5488\n",
      "Epoch 367/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4185 - acc: 0.8370 - val_loss: 0.8159 - val_acc: 0.5387\n",
      "Epoch 368/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4228 - acc: 0.8277 - val_loss: 0.8137 - val_acc: 0.5421\n",
      "Epoch 369/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4170 - acc: 0.8387 - val_loss: 0.8261 - val_acc: 0.5657\n",
      "Epoch 370/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4175 - acc: 0.8353 - val_loss: 0.8110 - val_acc: 0.5589\n",
      "Epoch 371/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4262 - acc: 0.8252 - val_loss: 0.8213 - val_acc: 0.5455\n",
      "Epoch 372/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4148 - acc: 0.8336 - val_loss: 0.8085 - val_acc: 0.5690\n",
      "Epoch 373/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4134 - acc: 0.8370 - val_loss: 0.8177 - val_acc: 0.5354\n",
      "Epoch 374/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4135 - acc: 0.8404 - val_loss: 0.8286 - val_acc: 0.5253\n",
      "Epoch 375/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4181 - acc: 0.8260 - val_loss: 0.8238 - val_acc: 0.5421\n",
      "Epoch 376/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4166 - acc: 0.8269 - val_loss: 0.8515 - val_acc: 0.5286\n",
      "Epoch 377/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4151 - acc: 0.8353 - val_loss: 0.8300 - val_acc: 0.5488\n",
      "Epoch 378/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4143 - acc: 0.8328 - val_loss: 0.8284 - val_acc: 0.5690\n",
      "Epoch 379/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4161 - acc: 0.8395 - val_loss: 0.8186 - val_acc: 0.5522\n",
      "Epoch 380/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.4113 - acc: 0.8387 - val_loss: 0.8382 - val_acc: 0.5286\n",
      "Epoch 381/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4131 - acc: 0.8319 - val_loss: 0.8174 - val_acc: 0.5522\n",
      "Epoch 382/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4129 - acc: 0.8412 - val_loss: 0.8487 - val_acc: 0.5455\n",
      "Epoch 383/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4114 - acc: 0.8454 - val_loss: 0.8329 - val_acc: 0.5219\n",
      "Epoch 384/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4105 - acc: 0.8421 - val_loss: 0.8325 - val_acc: 0.5556\n",
      "Epoch 385/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4179 - acc: 0.8387 - val_loss: 0.8346 - val_acc: 0.5488\n",
      "Epoch 386/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4089 - acc: 0.8345 - val_loss: 0.8341 - val_acc: 0.5286\n",
      "Epoch 387/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4067 - acc: 0.8404 - val_loss: 0.8807 - val_acc: 0.5522\n",
      "Epoch 388/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4088 - acc: 0.8429 - val_loss: 0.8217 - val_acc: 0.5657\n",
      "Epoch 389/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4066 - acc: 0.8421 - val_loss: 0.8314 - val_acc: 0.5455\n",
      "Epoch 390/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4102 - acc: 0.8404 - val_loss: 0.8345 - val_acc: 0.5657\n",
      "Epoch 391/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4040 - acc: 0.8395 - val_loss: 0.8388 - val_acc: 0.5455\n",
      "Epoch 392/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4134 - acc: 0.8387 - val_loss: 0.8374 - val_acc: 0.5354\n",
      "Epoch 393/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4074 - acc: 0.8370 - val_loss: 0.8346 - val_acc: 0.5522\n",
      "Epoch 394/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.4022 - acc: 0.8505 - val_loss: 0.8500 - val_acc: 0.5522\n",
      "Epoch 395/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4051 - acc: 0.8336 - val_loss: 0.8415 - val_acc: 0.5421\n",
      "Epoch 396/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4002 - acc: 0.8497 - val_loss: 0.8485 - val_acc: 0.5421\n",
      "Epoch 397/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.4048 - acc: 0.8463 - val_loss: 0.8506 - val_acc: 0.5387\n",
      "Epoch 398/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.4005 - acc: 0.8353 - val_loss: 0.8713 - val_acc: 0.5152\n",
      "Epoch 399/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4091 - acc: 0.8302 - val_loss: 0.8322 - val_acc: 0.5421\n",
      "Epoch 400/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3986 - acc: 0.8480 - val_loss: 0.8577 - val_acc: 0.5421\n",
      "Epoch 401/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3994 - acc: 0.8454 - val_loss: 0.8499 - val_acc: 0.5724\n",
      "Epoch 402/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4011 - acc: 0.8387 - val_loss: 0.8845 - val_acc: 0.5320\n",
      "Epoch 403/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4038 - acc: 0.8370 - val_loss: 0.8999 - val_acc: 0.5320\n",
      "Epoch 404/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3992 - acc: 0.8488 - val_loss: 0.8581 - val_acc: 0.5455\n",
      "Epoch 405/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4018 - acc: 0.8446 - val_loss: 0.8676 - val_acc: 0.5152\n",
      "Epoch 406/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.4000 - acc: 0.8438 - val_loss: 0.8305 - val_acc: 0.5387\n",
      "Epoch 407/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3976 - acc: 0.8514 - val_loss: 0.8783 - val_acc: 0.4949\n",
      "Epoch 408/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4056 - acc: 0.8412 - val_loss: 0.8430 - val_acc: 0.5286\n",
      "Epoch 409/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3956 - acc: 0.8438 - val_loss: 0.8372 - val_acc: 0.5354\n",
      "Epoch 410/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3962 - acc: 0.8438 - val_loss: 0.8339 - val_acc: 0.5488\n",
      "Epoch 411/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3952 - acc: 0.8412 - val_loss: 0.8434 - val_acc: 0.5387\n",
      "Epoch 412/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.4000 - acc: 0.8488 - val_loss: 0.8823 - val_acc: 0.5320\n",
      "Epoch 413/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.4023 - acc: 0.8454 - val_loss: 0.8865 - val_acc: 0.5320\n",
      "Epoch 414/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3911 - acc: 0.8446 - val_loss: 0.9303 - val_acc: 0.5286\n",
      "Epoch 415/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3965 - acc: 0.8505 - val_loss: 0.8328 - val_acc: 0.5421\n",
      "Epoch 416/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3993 - acc: 0.8454 - val_loss: 0.8365 - val_acc: 0.5522\n",
      "Epoch 417/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3932 - acc: 0.8438 - val_loss: 0.8389 - val_acc: 0.5623\n",
      "Epoch 418/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3924 - acc: 0.8395 - val_loss: 0.8492 - val_acc: 0.5589\n",
      "Epoch 419/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3906 - acc: 0.8556 - val_loss: 0.8760 - val_acc: 0.5522\n",
      "Epoch 420/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3989 - acc: 0.8285 - val_loss: 0.8294 - val_acc: 0.5690\n",
      "Epoch 421/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3880 - acc: 0.8497 - val_loss: 0.8431 - val_acc: 0.5556\n",
      "Epoch 422/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.3897 - acc: 0.8429 - val_loss: 0.8362 - val_acc: 0.5657\n",
      "Epoch 423/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3891 - acc: 0.8454 - val_loss: 0.8532 - val_acc: 0.5488\n",
      "Epoch 424/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3880 - acc: 0.8505 - val_loss: 0.8679 - val_acc: 0.5488\n",
      "Epoch 425/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3906 - acc: 0.8556 - val_loss: 0.8982 - val_acc: 0.5488\n",
      "Epoch 426/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3867 - acc: 0.8530 - val_loss: 0.8645 - val_acc: 0.5522\n",
      "Epoch 427/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3868 - acc: 0.8505 - val_loss: 0.8603 - val_acc: 0.5387\n",
      "Epoch 428/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3902 - acc: 0.8488 - val_loss: 0.8617 - val_acc: 0.5286\n",
      "Epoch 429/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3900 - acc: 0.8505 - val_loss: 0.8566 - val_acc: 0.5488\n",
      "Epoch 430/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3893 - acc: 0.8480 - val_loss: 0.8722 - val_acc: 0.5354\n",
      "Epoch 431/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3890 - acc: 0.8480 - val_loss: 0.8470 - val_acc: 0.5556\n",
      "Epoch 432/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3835 - acc: 0.8463 - val_loss: 0.8745 - val_acc: 0.5118\n",
      "Epoch 433/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3899 - acc: 0.8539 - val_loss: 0.8635 - val_acc: 0.5488\n",
      "Epoch 434/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3903 - acc: 0.8497 - val_loss: 0.8537 - val_acc: 0.5657\n",
      "Epoch 435/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3890 - acc: 0.8454 - val_loss: 0.8665 - val_acc: 0.5320\n",
      "Epoch 436/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3855 - acc: 0.8446 - val_loss: 0.9081 - val_acc: 0.5354\n",
      "Epoch 437/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3849 - acc: 0.8463 - val_loss: 0.8784 - val_acc: 0.5421\n",
      "Epoch 438/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3823 - acc: 0.8480 - val_loss: 0.8905 - val_acc: 0.5455\n",
      "Epoch 439/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3872 - acc: 0.8539 - val_loss: 0.8901 - val_acc: 0.5185\n",
      "Epoch 440/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3886 - acc: 0.8488 - val_loss: 0.8664 - val_acc: 0.5320\n",
      "Epoch 441/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3849 - acc: 0.8530 - val_loss: 0.8537 - val_acc: 0.5488\n",
      "Epoch 442/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3810 - acc: 0.8547 - val_loss: 0.8496 - val_acc: 0.5690\n",
      "Epoch 443/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3789 - acc: 0.8522 - val_loss: 0.8600 - val_acc: 0.5522\n",
      "Epoch 444/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3887 - acc: 0.8463 - val_loss: 0.9016 - val_acc: 0.5219\n",
      "Epoch 445/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3845 - acc: 0.8471 - val_loss: 0.8638 - val_acc: 0.5522\n",
      "Epoch 446/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3826 - acc: 0.8454 - val_loss: 0.8601 - val_acc: 0.5354\n",
      "Epoch 447/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3782 - acc: 0.8573 - val_loss: 0.8668 - val_acc: 0.5522\n",
      "Epoch 448/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3775 - acc: 0.8615 - val_loss: 0.8693 - val_acc: 0.5185\n",
      "Epoch 449/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3791 - acc: 0.8547 - val_loss: 0.8942 - val_acc: 0.5185\n",
      "Epoch 450/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3780 - acc: 0.8573 - val_loss: 0.8916 - val_acc: 0.5320\n",
      "Epoch 451/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3775 - acc: 0.8556 - val_loss: 0.8641 - val_acc: 0.5488\n",
      "Epoch 452/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3825 - acc: 0.8471 - val_loss: 0.8675 - val_acc: 0.5455\n",
      "Epoch 453/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3769 - acc: 0.8606 - val_loss: 0.8651 - val_acc: 0.5556\n",
      "Epoch 454/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3843 - acc: 0.8547 - val_loss: 0.8814 - val_acc: 0.5354\n",
      "Epoch 455/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3751 - acc: 0.8632 - val_loss: 0.8739 - val_acc: 0.5522\n",
      "Epoch 456/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3734 - acc: 0.8547 - val_loss: 0.8661 - val_acc: 0.5791\n",
      "Epoch 457/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3741 - acc: 0.8598 - val_loss: 0.9164 - val_acc: 0.5286\n",
      "Epoch 458/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3775 - acc: 0.8522 - val_loss: 0.8809 - val_acc: 0.5253\n",
      "Epoch 459/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3785 - acc: 0.8480 - val_loss: 0.8929 - val_acc: 0.5455\n",
      "Epoch 460/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3721 - acc: 0.8590 - val_loss: 0.8993 - val_acc: 0.5320\n",
      "Epoch 461/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3737 - acc: 0.8674 - val_loss: 0.8629 - val_acc: 0.5522\n",
      "Epoch 462/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3744 - acc: 0.8632 - val_loss: 0.8691 - val_acc: 0.5690\n",
      "Epoch 463/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3721 - acc: 0.8573 - val_loss: 0.8793 - val_acc: 0.5690\n",
      "Epoch 464/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.3711 - acc: 0.8556 - val_loss: 0.8936 - val_acc: 0.5354\n",
      "Epoch 465/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3700 - acc: 0.8640 - val_loss: 0.8756 - val_acc: 0.5354\n",
      "Epoch 466/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3754 - acc: 0.8505 - val_loss: 0.8767 - val_acc: 0.5556\n",
      "Epoch 467/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3681 - acc: 0.8590 - val_loss: 0.8779 - val_acc: 0.5488\n",
      "Epoch 468/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3710 - acc: 0.8547 - val_loss: 0.9216 - val_acc: 0.5421\n",
      "Epoch 469/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3696 - acc: 0.8598 - val_loss: 0.8718 - val_acc: 0.5589\n",
      "Epoch 470/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3677 - acc: 0.8674 - val_loss: 0.8801 - val_acc: 0.5488\n",
      "Epoch 471/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3703 - acc: 0.8556 - val_loss: 0.8808 - val_acc: 0.5354\n",
      "Epoch 472/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3668 - acc: 0.8666 - val_loss: 0.8663 - val_acc: 0.5556\n",
      "Epoch 473/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3650 - acc: 0.8606 - val_loss: 0.9127 - val_acc: 0.5219\n",
      "Epoch 474/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3704 - acc: 0.8581 - val_loss: 0.8857 - val_acc: 0.5320\n",
      "Epoch 475/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3622 - acc: 0.8725 - val_loss: 0.8724 - val_acc: 0.5455\n",
      "Epoch 476/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3677 - acc: 0.8590 - val_loss: 0.8784 - val_acc: 0.5488\n",
      "Epoch 477/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3719 - acc: 0.8547 - val_loss: 0.9421 - val_acc: 0.5286\n",
      "Epoch 478/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3665 - acc: 0.8539 - val_loss: 0.8789 - val_acc: 0.5320\n",
      "Epoch 479/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3605 - acc: 0.8691 - val_loss: 0.9000 - val_acc: 0.5219\n",
      "Epoch 480/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3594 - acc: 0.8708 - val_loss: 0.8876 - val_acc: 0.5488\n",
      "Epoch 481/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3642 - acc: 0.8657 - val_loss: 0.9289 - val_acc: 0.5455\n",
      "Epoch 482/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3650 - acc: 0.8598 - val_loss: 0.9030 - val_acc: 0.5320\n",
      "Epoch 483/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3683 - acc: 0.8598 - val_loss: 0.8874 - val_acc: 0.5556\n",
      "Epoch 484/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3655 - acc: 0.8640 - val_loss: 0.9528 - val_acc: 0.5219\n",
      "Epoch 485/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3653 - acc: 0.8606 - val_loss: 0.8868 - val_acc: 0.5556\n",
      "Epoch 486/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3600 - acc: 0.8649 - val_loss: 0.8985 - val_acc: 0.5421\n",
      "Epoch 487/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3616 - acc: 0.8691 - val_loss: 0.8857 - val_acc: 0.5522\n",
      "Epoch 488/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3586 - acc: 0.8657 - val_loss: 0.9181 - val_acc: 0.5320\n",
      "Epoch 489/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3641 - acc: 0.8657 - val_loss: 0.8969 - val_acc: 0.5488\n",
      "Epoch 490/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3579 - acc: 0.8784 - val_loss: 0.8857 - val_acc: 0.5320\n",
      "Epoch 491/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3592 - acc: 0.8674 - val_loss: 0.8918 - val_acc: 0.5522\n",
      "Epoch 492/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3559 - acc: 0.8674 - val_loss: 0.8978 - val_acc: 0.5320\n",
      "Epoch 493/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3661 - acc: 0.8632 - val_loss: 1.0067 - val_acc: 0.5320\n",
      "Epoch 494/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3597 - acc: 0.8682 - val_loss: 0.9392 - val_acc: 0.5320\n",
      "Epoch 495/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.3516 - acc: 0.8708 - val_loss: 0.9181 - val_acc: 0.5084\n",
      "Epoch 496/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3616 - acc: 0.8556 - val_loss: 0.9201 - val_acc: 0.5354\n",
      "Epoch 497/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3583 - acc: 0.8598 - val_loss: 0.9229 - val_acc: 0.5320\n",
      "Epoch 498/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3604 - acc: 0.8649 - val_loss: 0.9081 - val_acc: 0.5354\n",
      "Epoch 499/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3554 - acc: 0.8674 - val_loss: 0.9351 - val_acc: 0.5286\n",
      "Epoch 500/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3547 - acc: 0.8775 - val_loss: 0.9200 - val_acc: 0.5118\n",
      "Epoch 501/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3577 - acc: 0.8649 - val_loss: 0.9097 - val_acc: 0.5354\n",
      "Epoch 502/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3495 - acc: 0.8834 - val_loss: 0.9153 - val_acc: 0.5320\n",
      "Epoch 503/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3512 - acc: 0.8708 - val_loss: 0.9047 - val_acc: 0.5286\n",
      "Epoch 504/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3551 - acc: 0.8716 - val_loss: 0.9312 - val_acc: 0.5387\n",
      "Epoch 505/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3521 - acc: 0.8691 - val_loss: 0.9052 - val_acc: 0.5488\n",
      "Epoch 506/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3482 - acc: 0.8708 - val_loss: 0.9001 - val_acc: 0.5522\n",
      "Epoch 507/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3579 - acc: 0.8674 - val_loss: 0.9098 - val_acc: 0.5253\n",
      "Epoch 508/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3528 - acc: 0.8733 - val_loss: 0.9051 - val_acc: 0.5286\n",
      "Epoch 509/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3517 - acc: 0.8725 - val_loss: 0.9559 - val_acc: 0.5253\n",
      "Epoch 510/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3570 - acc: 0.8674 - val_loss: 0.9192 - val_acc: 0.5556\n",
      "Epoch 511/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3478 - acc: 0.8674 - val_loss: 0.9226 - val_acc: 0.5152\n",
      "Epoch 512/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3474 - acc: 0.8674 - val_loss: 1.0107 - val_acc: 0.5286\n",
      "Epoch 513/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3569 - acc: 0.8674 - val_loss: 0.9058 - val_acc: 0.5421\n",
      "Epoch 514/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3504 - acc: 0.8784 - val_loss: 0.9661 - val_acc: 0.5286\n",
      "Epoch 515/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3529 - acc: 0.8674 - val_loss: 0.9184 - val_acc: 0.5320\n",
      "Epoch 516/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3503 - acc: 0.8691 - val_loss: 0.9405 - val_acc: 0.5320\n",
      "Epoch 517/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3489 - acc: 0.8708 - val_loss: 0.9457 - val_acc: 0.5219\n",
      "Epoch 518/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3554 - acc: 0.8632 - val_loss: 0.9068 - val_acc: 0.5421\n",
      "Epoch 519/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3472 - acc: 0.8750 - val_loss: 0.9051 - val_acc: 0.5320\n",
      "Epoch 520/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3484 - acc: 0.8598 - val_loss: 0.9331 - val_acc: 0.5455\n",
      "Epoch 521/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3543 - acc: 0.8573 - val_loss: 0.9009 - val_acc: 0.5522\n",
      "Epoch 522/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3435 - acc: 0.8801 - val_loss: 0.9562 - val_acc: 0.5354\n",
      "Epoch 523/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3501 - acc: 0.8750 - val_loss: 0.9153 - val_acc: 0.5387\n",
      "Epoch 524/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3436 - acc: 0.8691 - val_loss: 0.9509 - val_acc: 0.5354\n",
      "Epoch 525/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3453 - acc: 0.8784 - val_loss: 0.9202 - val_acc: 0.5455\n",
      "Epoch 526/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3445 - acc: 0.8818 - val_loss: 0.9247 - val_acc: 0.5455\n",
      "Epoch 527/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3401 - acc: 0.8750 - val_loss: 0.9381 - val_acc: 0.5354\n",
      "Epoch 528/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3446 - acc: 0.8750 - val_loss: 1.0088 - val_acc: 0.5320\n",
      "Epoch 529/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3523 - acc: 0.8598 - val_loss: 0.9132 - val_acc: 0.5354\n",
      "Epoch 530/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3371 - acc: 0.8767 - val_loss: 0.9276 - val_acc: 0.5152\n",
      "Epoch 531/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3392 - acc: 0.8818 - val_loss: 0.9735 - val_acc: 0.4882\n",
      "Epoch 532/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3500 - acc: 0.8606 - val_loss: 0.9270 - val_acc: 0.5354\n",
      "Epoch 533/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3415 - acc: 0.8699 - val_loss: 0.9234 - val_acc: 0.5488\n",
      "Epoch 534/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3364 - acc: 0.8818 - val_loss: 0.9613 - val_acc: 0.5354\n",
      "Epoch 535/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3418 - acc: 0.8758 - val_loss: 0.9303 - val_acc: 0.5421\n",
      "Epoch 536/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3485 - acc: 0.8733 - val_loss: 0.9345 - val_acc: 0.5084\n",
      "Epoch 537/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3395 - acc: 0.8775 - val_loss: 0.9190 - val_acc: 0.5354\n",
      "Epoch 538/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3377 - acc: 0.8750 - val_loss: 0.9269 - val_acc: 0.5556\n",
      "Epoch 539/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3376 - acc: 0.8767 - val_loss: 0.9260 - val_acc: 0.5354\n",
      "Epoch 540/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3400 - acc: 0.8750 - val_loss: 0.9243 - val_acc: 0.5455\n",
      "Epoch 541/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3338 - acc: 0.8733 - val_loss: 0.9265 - val_acc: 0.5286\n",
      "Epoch 542/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3364 - acc: 0.8792 - val_loss: 0.9373 - val_acc: 0.5320\n",
      "Epoch 543/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3331 - acc: 0.8784 - val_loss: 1.0637 - val_acc: 0.5387\n",
      "Epoch 544/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3410 - acc: 0.8725 - val_loss: 0.9457 - val_acc: 0.5253\n",
      "Epoch 545/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3372 - acc: 0.8682 - val_loss: 0.9277 - val_acc: 0.5320\n",
      "Epoch 546/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3322 - acc: 0.8801 - val_loss: 0.9338 - val_acc: 0.5185\n",
      "Epoch 547/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3352 - acc: 0.8801 - val_loss: 0.9435 - val_acc: 0.5387\n",
      "Epoch 548/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3368 - acc: 0.8767 - val_loss: 0.9579 - val_acc: 0.5219\n",
      "Epoch 549/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3352 - acc: 0.8784 - val_loss: 0.9549 - val_acc: 0.5219\n",
      "Epoch 550/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3434 - acc: 0.8699 - val_loss: 0.9368 - val_acc: 0.5522\n",
      "Epoch 551/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3310 - acc: 0.8868 - val_loss: 0.9463 - val_acc: 0.5253\n",
      "Epoch 552/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3375 - acc: 0.8767 - val_loss: 0.9426 - val_acc: 0.5522\n",
      "Epoch 553/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3361 - acc: 0.8843 - val_loss: 0.9410 - val_acc: 0.5455\n",
      "Epoch 554/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3281 - acc: 0.8834 - val_loss: 0.9352 - val_acc: 0.5455\n",
      "Epoch 555/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3333 - acc: 0.8868 - val_loss: 1.0486 - val_acc: 0.5219\n",
      "Epoch 556/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3384 - acc: 0.8775 - val_loss: 0.9483 - val_acc: 0.5556\n",
      "Epoch 557/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3317 - acc: 0.8742 - val_loss: 0.9418 - val_acc: 0.5455\n",
      "Epoch 558/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3416 - acc: 0.8742 - val_loss: 0.9534 - val_acc: 0.5219\n",
      "Epoch 559/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3284 - acc: 0.8826 - val_loss: 0.9396 - val_acc: 0.5387\n",
      "Epoch 560/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3294 - acc: 0.8784 - val_loss: 1.0111 - val_acc: 0.5152\n",
      "Epoch 561/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3422 - acc: 0.8649 - val_loss: 0.9413 - val_acc: 0.5522\n",
      "Epoch 562/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3318 - acc: 0.8775 - val_loss: 0.9529 - val_acc: 0.5253\n",
      "Epoch 563/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3279 - acc: 0.8826 - val_loss: 0.9545 - val_acc: 0.5556\n",
      "Epoch 564/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3250 - acc: 0.8860 - val_loss: 0.9424 - val_acc: 0.5522\n",
      "Epoch 565/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3321 - acc: 0.8775 - val_loss: 0.9546 - val_acc: 0.5354\n",
      "Epoch 566/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3272 - acc: 0.8927 - val_loss: 1.0249 - val_acc: 0.5320\n",
      "Epoch 567/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3316 - acc: 0.8775 - val_loss: 0.9516 - val_acc: 0.5354\n",
      "Epoch 568/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3284 - acc: 0.8809 - val_loss: 0.9703 - val_acc: 0.5084\n",
      "Epoch 569/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3344 - acc: 0.8750 - val_loss: 0.9379 - val_acc: 0.5522\n",
      "Epoch 570/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3247 - acc: 0.8868 - val_loss: 1.0584 - val_acc: 0.5253\n",
      "Epoch 571/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3341 - acc: 0.8750 - val_loss: 0.9493 - val_acc: 0.5522\n",
      "Epoch 572/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3230 - acc: 0.8834 - val_loss: 0.9731 - val_acc: 0.5354\n",
      "Epoch 573/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3236 - acc: 0.8885 - val_loss: 0.9613 - val_acc: 0.5354\n",
      "Epoch 574/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3297 - acc: 0.8767 - val_loss: 0.9624 - val_acc: 0.5219\n",
      "Epoch 575/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3226 - acc: 0.8894 - val_loss: 1.0409 - val_acc: 0.5219\n",
      "Epoch 576/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3295 - acc: 0.8826 - val_loss: 1.0181 - val_acc: 0.5219\n",
      "Epoch 577/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3207 - acc: 0.8818 - val_loss: 0.9929 - val_acc: 0.5320\n",
      "Epoch 578/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3247 - acc: 0.8885 - val_loss: 0.9658 - val_acc: 0.5185\n",
      "Epoch 579/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3265 - acc: 0.8843 - val_loss: 0.9785 - val_acc: 0.5152\n",
      "Epoch 580/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3219 - acc: 0.8818 - val_loss: 1.0222 - val_acc: 0.5286\n",
      "Epoch 581/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3252 - acc: 0.8834 - val_loss: 0.9483 - val_acc: 0.5589\n",
      "Epoch 582/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3202 - acc: 0.8809 - val_loss: 0.9651 - val_acc: 0.5488\n",
      "Epoch 583/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3240 - acc: 0.8818 - val_loss: 0.9501 - val_acc: 0.5455\n",
      "Epoch 584/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.3269 - acc: 0.8801 - val_loss: 0.9550 - val_acc: 0.5320\n",
      "Epoch 585/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3201 - acc: 0.8868 - val_loss: 0.9914 - val_acc: 0.5354\n",
      "Epoch 586/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3206 - acc: 0.8801 - val_loss: 0.9815 - val_acc: 0.5421\n",
      "Epoch 587/1100\n",
      "1184/1184 [==============================] - 0s 24us/step - loss: 0.3192 - acc: 0.8944 - val_loss: 0.9676 - val_acc: 0.5253\n",
      "Epoch 588/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3252 - acc: 0.8750 - val_loss: 0.9623 - val_acc: 0.5556\n",
      "Epoch 589/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3205 - acc: 0.8784 - val_loss: 0.9745 - val_acc: 0.5387\n",
      "Epoch 590/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3279 - acc: 0.8708 - val_loss: 1.0292 - val_acc: 0.5286\n",
      "Epoch 591/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3181 - acc: 0.8877 - val_loss: 0.9694 - val_acc: 0.5455\n",
      "Epoch 592/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3145 - acc: 0.8961 - val_loss: 0.9599 - val_acc: 0.5320\n",
      "Epoch 593/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3296 - acc: 0.8699 - val_loss: 1.0079 - val_acc: 0.5185\n",
      "Epoch 594/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3178 - acc: 0.8868 - val_loss: 0.9566 - val_acc: 0.5455\n",
      "Epoch 595/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3137 - acc: 0.8894 - val_loss: 0.9625 - val_acc: 0.5387\n",
      "Epoch 596/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3303 - acc: 0.8640 - val_loss: 0.9711 - val_acc: 0.5488\n",
      "Epoch 597/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3127 - acc: 0.8919 - val_loss: 1.0115 - val_acc: 0.5118\n",
      "Epoch 598/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3174 - acc: 0.8784 - val_loss: 0.9650 - val_acc: 0.5320\n",
      "Epoch 599/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3149 - acc: 0.8868 - val_loss: 1.0758 - val_acc: 0.5253\n",
      "Epoch 600/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3245 - acc: 0.8818 - val_loss: 0.9546 - val_acc: 0.5556\n",
      "Epoch 601/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3117 - acc: 0.8910 - val_loss: 0.9792 - val_acc: 0.5421\n",
      "Epoch 602/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3129 - acc: 0.8927 - val_loss: 1.0062 - val_acc: 0.5185\n",
      "Epoch 603/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3246 - acc: 0.8767 - val_loss: 0.9773 - val_acc: 0.5354\n",
      "Epoch 604/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3095 - acc: 0.8927 - val_loss: 0.9860 - val_acc: 0.5387\n",
      "Epoch 605/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3114 - acc: 0.8944 - val_loss: 1.0236 - val_acc: 0.5253\n",
      "Epoch 606/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3245 - acc: 0.8725 - val_loss: 0.9633 - val_acc: 0.5455\n",
      "Epoch 607/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3117 - acc: 0.8970 - val_loss: 0.9691 - val_acc: 0.5522\n",
      "Epoch 608/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3113 - acc: 0.8902 - val_loss: 0.9904 - val_acc: 0.5253\n",
      "Epoch 609/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3164 - acc: 0.8851 - val_loss: 0.9666 - val_acc: 0.5455\n",
      "Epoch 610/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3081 - acc: 0.8953 - val_loss: 0.9929 - val_acc: 0.5253\n",
      "Epoch 611/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3136 - acc: 0.8860 - val_loss: 0.9903 - val_acc: 0.5253\n",
      "Epoch 612/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3140 - acc: 0.8902 - val_loss: 0.9793 - val_acc: 0.5421\n",
      "Epoch 613/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3059 - acc: 0.8970 - val_loss: 0.9834 - val_acc: 0.5488\n",
      "Epoch 614/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3137 - acc: 0.8894 - val_loss: 0.9901 - val_acc: 0.5421\n",
      "Epoch 615/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3076 - acc: 0.8936 - val_loss: 0.9791 - val_acc: 0.5387\n",
      "Epoch 616/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3124 - acc: 0.8826 - val_loss: 0.9792 - val_acc: 0.5421\n",
      "Epoch 617/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3087 - acc: 0.8944 - val_loss: 0.9943 - val_acc: 0.5253\n",
      "Epoch 618/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3042 - acc: 0.8961 - val_loss: 0.9776 - val_acc: 0.5589\n",
      "Epoch 619/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3092 - acc: 0.8919 - val_loss: 0.9785 - val_acc: 0.5354\n",
      "Epoch 620/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3121 - acc: 0.8834 - val_loss: 0.9784 - val_acc: 0.5488\n",
      "Epoch 621/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3112 - acc: 0.8834 - val_loss: 1.0001 - val_acc: 0.5253\n",
      "Epoch 622/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3114 - acc: 0.8894 - val_loss: 0.9902 - val_acc: 0.5286\n",
      "Epoch 623/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3070 - acc: 0.8877 - val_loss: 0.9862 - val_acc: 0.5387\n",
      "Epoch 624/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3090 - acc: 0.8961 - val_loss: 0.9787 - val_acc: 0.5320\n",
      "Epoch 625/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3036 - acc: 0.8919 - val_loss: 0.9962 - val_acc: 0.5320\n",
      "Epoch 626/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.3091 - acc: 0.8910 - val_loss: 0.9695 - val_acc: 0.5522\n",
      "Epoch 627/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3070 - acc: 0.8936 - val_loss: 1.0161 - val_acc: 0.5253\n",
      "Epoch 628/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3021 - acc: 0.8902 - val_loss: 0.9889 - val_acc: 0.5522\n",
      "Epoch 629/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3032 - acc: 0.8885 - val_loss: 0.9929 - val_acc: 0.5185\n",
      "Epoch 630/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3062 - acc: 0.8986 - val_loss: 1.0598 - val_acc: 0.5354\n",
      "Epoch 631/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3059 - acc: 0.8944 - val_loss: 1.0024 - val_acc: 0.5320\n",
      "Epoch 632/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3080 - acc: 0.8910 - val_loss: 1.0060 - val_acc: 0.5320\n",
      "Epoch 633/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3055 - acc: 0.8970 - val_loss: 1.0896 - val_acc: 0.5185\n",
      "Epoch 634/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3100 - acc: 0.8809 - val_loss: 1.0839 - val_acc: 0.5152\n",
      "Epoch 635/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3032 - acc: 0.8961 - val_loss: 1.0173 - val_acc: 0.5253\n",
      "Epoch 636/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3008 - acc: 0.8995 - val_loss: 1.0136 - val_acc: 0.5152\n",
      "Epoch 637/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2990 - acc: 0.9012 - val_loss: 0.9988 - val_acc: 0.5286\n",
      "Epoch 638/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3011 - acc: 0.8936 - val_loss: 1.0526 - val_acc: 0.5219\n",
      "Epoch 639/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.3124 - acc: 0.8775 - val_loss: 1.0079 - val_acc: 0.5421\n",
      "Epoch 640/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2983 - acc: 0.8986 - val_loss: 0.9915 - val_acc: 0.5522\n",
      "Epoch 641/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2981 - acc: 0.8970 - val_loss: 1.0531 - val_acc: 0.5387\n",
      "Epoch 642/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.3055 - acc: 0.8944 - val_loss: 1.0375 - val_acc: 0.5286\n",
      "Epoch 643/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3039 - acc: 0.8919 - val_loss: 1.0121 - val_acc: 0.5286\n",
      "Epoch 644/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2934 - acc: 0.9012 - val_loss: 1.0191 - val_acc: 0.5488\n",
      "Epoch 645/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3061 - acc: 0.8944 - val_loss: 1.0118 - val_acc: 0.5387\n",
      "Epoch 646/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3030 - acc: 0.8936 - val_loss: 0.9987 - val_acc: 0.5556\n",
      "Epoch 647/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2984 - acc: 0.8919 - val_loss: 1.0025 - val_acc: 0.5253\n",
      "Epoch 648/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2985 - acc: 0.8944 - val_loss: 1.0280 - val_acc: 0.5522\n",
      "Epoch 649/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2971 - acc: 0.9071 - val_loss: 1.0240 - val_acc: 0.5185\n",
      "Epoch 650/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2950 - acc: 0.9012 - val_loss: 1.0115 - val_acc: 0.5286\n",
      "Epoch 651/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2981 - acc: 0.8970 - val_loss: 1.0133 - val_acc: 0.5286\n",
      "Epoch 652/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.3005 - acc: 0.8894 - val_loss: 1.0368 - val_acc: 0.5387\n",
      "Epoch 653/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2938 - acc: 0.9003 - val_loss: 0.9991 - val_acc: 0.5354\n",
      "Epoch 654/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2977 - acc: 0.8953 - val_loss: 1.0185 - val_acc: 0.5286\n",
      "Epoch 655/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.3014 - acc: 0.8902 - val_loss: 1.0003 - val_acc: 0.5556\n",
      "Epoch 656/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2947 - acc: 0.9020 - val_loss: 1.0103 - val_acc: 0.5286\n",
      "Epoch 657/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2989 - acc: 0.8910 - val_loss: 1.0214 - val_acc: 0.5354\n",
      "Epoch 658/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.3045 - acc: 0.8927 - val_loss: 1.0536 - val_acc: 0.5253\n",
      "Epoch 659/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2936 - acc: 0.9046 - val_loss: 1.0127 - val_acc: 0.5488\n",
      "Epoch 660/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2998 - acc: 0.8961 - val_loss: 1.0247 - val_acc: 0.5286\n",
      "Epoch 661/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2901 - acc: 0.8953 - val_loss: 1.0558 - val_acc: 0.5017\n",
      "Epoch 662/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2935 - acc: 0.8970 - val_loss: 1.0147 - val_acc: 0.5421\n",
      "Epoch 663/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.2996 - acc: 0.8910 - val_loss: 1.0283 - val_acc: 0.5185\n",
      "Epoch 664/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2977 - acc: 0.9003 - val_loss: 1.0383 - val_acc: 0.5185\n",
      "Epoch 665/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2921 - acc: 0.8961 - val_loss: 1.0180 - val_acc: 0.5387\n",
      "Epoch 666/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2918 - acc: 0.8978 - val_loss: 1.0181 - val_acc: 0.5455\n",
      "Epoch 667/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2892 - acc: 0.9046 - val_loss: 1.0356 - val_acc: 0.5118\n",
      "Epoch 668/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2909 - acc: 0.8986 - val_loss: 1.0101 - val_acc: 0.5286\n",
      "Epoch 669/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2914 - acc: 0.9003 - val_loss: 1.0273 - val_acc: 0.5320\n",
      "Epoch 670/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2942 - acc: 0.8970 - val_loss: 1.0308 - val_acc: 0.5286\n",
      "Epoch 671/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2863 - acc: 0.9037 - val_loss: 1.0251 - val_acc: 0.5556\n",
      "Epoch 672/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2859 - acc: 0.8961 - val_loss: 1.0214 - val_acc: 0.5286\n",
      "Epoch 673/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2892 - acc: 0.9046 - val_loss: 1.0335 - val_acc: 0.5253\n",
      "Epoch 674/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2886 - acc: 0.9020 - val_loss: 1.0353 - val_acc: 0.5219\n",
      "Epoch 675/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2873 - acc: 0.9079 - val_loss: 1.0325 - val_acc: 0.5354\n",
      "Epoch 676/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2914 - acc: 0.9105 - val_loss: 1.0316 - val_acc: 0.5253\n",
      "Epoch 677/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2838 - acc: 0.9062 - val_loss: 1.0255 - val_acc: 0.5253\n",
      "Epoch 678/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2886 - acc: 0.9029 - val_loss: 1.0972 - val_acc: 0.5051\n",
      "Epoch 679/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2936 - acc: 0.9020 - val_loss: 1.0340 - val_acc: 0.5387\n",
      "Epoch 680/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2851 - acc: 0.9122 - val_loss: 1.0991 - val_acc: 0.5219\n",
      "Epoch 681/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2899 - acc: 0.8986 - val_loss: 1.0288 - val_acc: 0.5320\n",
      "Epoch 682/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2868 - acc: 0.9037 - val_loss: 1.0443 - val_acc: 0.5253\n",
      "Epoch 683/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2892 - acc: 0.8961 - val_loss: 1.0853 - val_acc: 0.5118\n",
      "Epoch 684/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.2909 - acc: 0.8978 - val_loss: 1.0579 - val_acc: 0.5118\n",
      "Epoch 685/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2989 - acc: 0.8944 - val_loss: 1.0253 - val_acc: 0.5354\n",
      "Epoch 686/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2806 - acc: 0.9105 - val_loss: 1.0477 - val_acc: 0.5354\n",
      "Epoch 687/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2831 - acc: 0.9088 - val_loss: 1.1315 - val_acc: 0.5051\n",
      "Epoch 688/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2847 - acc: 0.9071 - val_loss: 1.0432 - val_acc: 0.5320\n",
      "Epoch 689/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2865 - acc: 0.9071 - val_loss: 1.0333 - val_acc: 0.5354\n",
      "Epoch 690/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2877 - acc: 0.8944 - val_loss: 1.0525 - val_acc: 0.5219\n",
      "Epoch 691/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2822 - acc: 0.9020 - val_loss: 1.1144 - val_acc: 0.5084\n",
      "Epoch 692/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2844 - acc: 0.8953 - val_loss: 1.0330 - val_acc: 0.5455\n",
      "Epoch 693/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2824 - acc: 0.9046 - val_loss: 1.0361 - val_acc: 0.5421\n",
      "Epoch 694/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2856 - acc: 0.9012 - val_loss: 1.0310 - val_acc: 0.5354\n",
      "Epoch 695/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2849 - acc: 0.8986 - val_loss: 1.0374 - val_acc: 0.5286\n",
      "Epoch 696/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2802 - acc: 0.9088 - val_loss: 1.1485 - val_acc: 0.5017\n",
      "Epoch 697/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2800 - acc: 0.9054 - val_loss: 1.0395 - val_acc: 0.5354\n",
      "Epoch 698/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2842 - acc: 0.9003 - val_loss: 1.0564 - val_acc: 0.5017\n",
      "Epoch 699/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2866 - acc: 0.9113 - val_loss: 1.0312 - val_acc: 0.5488\n",
      "Epoch 700/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2814 - acc: 0.9037 - val_loss: 1.0566 - val_acc: 0.5354\n",
      "Epoch 701/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2822 - acc: 0.9155 - val_loss: 1.0341 - val_acc: 0.5320\n",
      "Epoch 702/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2739 - acc: 0.9105 - val_loss: 1.0637 - val_acc: 0.5421\n",
      "Epoch 703/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2899 - acc: 0.8927 - val_loss: 1.0546 - val_acc: 0.5387\n",
      "Epoch 704/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2816 - acc: 0.9105 - val_loss: 1.0951 - val_acc: 0.5118\n",
      "Epoch 705/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2742 - acc: 0.9079 - val_loss: 1.0615 - val_acc: 0.5286\n",
      "Epoch 706/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2763 - acc: 0.9062 - val_loss: 1.0431 - val_acc: 0.5320\n",
      "Epoch 707/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2858 - acc: 0.8953 - val_loss: 1.0436 - val_acc: 0.5421\n",
      "Epoch 708/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2801 - acc: 0.9020 - val_loss: 1.0566 - val_acc: 0.5286\n",
      "Epoch 709/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2728 - acc: 0.9096 - val_loss: 1.1513 - val_acc: 0.5152\n",
      "Epoch 710/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.2807 - acc: 0.9029 - val_loss: 1.0478 - val_acc: 0.5421\n",
      "Epoch 711/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2748 - acc: 0.9079 - val_loss: 1.1581 - val_acc: 0.5354\n",
      "Epoch 712/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.3018 - acc: 0.8868 - val_loss: 1.0708 - val_acc: 0.5185\n",
      "Epoch 713/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2732 - acc: 0.9113 - val_loss: 1.1027 - val_acc: 0.5253\n",
      "Epoch 714/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2829 - acc: 0.9071 - val_loss: 1.1430 - val_acc: 0.5051\n",
      "Epoch 715/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2810 - acc: 0.9037 - val_loss: 1.0941 - val_acc: 0.5118\n",
      "Epoch 716/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2754 - acc: 0.9062 - val_loss: 1.0498 - val_acc: 0.5354\n",
      "Epoch 717/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2762 - acc: 0.9071 - val_loss: 1.0470 - val_acc: 0.5354\n",
      "Epoch 718/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2712 - acc: 0.9155 - val_loss: 1.0645 - val_acc: 0.5387\n",
      "Epoch 719/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2740 - acc: 0.9113 - val_loss: 1.0492 - val_acc: 0.5488\n",
      "Epoch 720/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2732 - acc: 0.9071 - val_loss: 1.0540 - val_acc: 0.5488\n",
      "Epoch 721/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2766 - acc: 0.9046 - val_loss: 1.1009 - val_acc: 0.5253\n",
      "Epoch 722/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2794 - acc: 0.9054 - val_loss: 1.0693 - val_acc: 0.5253\n",
      "Epoch 723/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2688 - acc: 0.9130 - val_loss: 1.0537 - val_acc: 0.5455\n",
      "Epoch 724/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2752 - acc: 0.9046 - val_loss: 1.1072 - val_acc: 0.5387\n",
      "Epoch 725/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2790 - acc: 0.8961 - val_loss: 1.0528 - val_acc: 0.5522\n",
      "Epoch 726/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2732 - acc: 0.9079 - val_loss: 1.0695 - val_acc: 0.5387\n",
      "Epoch 727/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2755 - acc: 0.9062 - val_loss: 1.1164 - val_acc: 0.4949\n",
      "Epoch 728/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2846 - acc: 0.9079 - val_loss: 1.0571 - val_acc: 0.5387\n",
      "Epoch 729/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2664 - acc: 0.9122 - val_loss: 1.0959 - val_acc: 0.5152\n",
      "Epoch 730/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2737 - acc: 0.9029 - val_loss: 1.0813 - val_acc: 0.5320\n",
      "Epoch 731/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2722 - acc: 0.9096 - val_loss: 1.1092 - val_acc: 0.5084\n",
      "Epoch 732/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2691 - acc: 0.9181 - val_loss: 1.1066 - val_acc: 0.5219\n",
      "Epoch 733/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2779 - acc: 0.8978 - val_loss: 1.0908 - val_acc: 0.5084\n",
      "Epoch 734/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2701 - acc: 0.9130 - val_loss: 1.0886 - val_acc: 0.5488\n",
      "Epoch 735/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2817 - acc: 0.8944 - val_loss: 1.0639 - val_acc: 0.5387\n",
      "Epoch 736/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2732 - acc: 0.9122 - val_loss: 1.0689 - val_acc: 0.5455\n",
      "Epoch 737/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2658 - acc: 0.9147 - val_loss: 1.0998 - val_acc: 0.5017\n",
      "Epoch 738/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2741 - acc: 0.9037 - val_loss: 1.1028 - val_acc: 0.5219\n",
      "Epoch 739/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2688 - acc: 0.9113 - val_loss: 1.0719 - val_acc: 0.5421\n",
      "Epoch 740/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2692 - acc: 0.9155 - val_loss: 1.1096 - val_acc: 0.5051\n",
      "Epoch 741/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2698 - acc: 0.9139 - val_loss: 1.1146 - val_acc: 0.5084\n",
      "Epoch 742/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2701 - acc: 0.9062 - val_loss: 1.0912 - val_acc: 0.5253\n",
      "Epoch 743/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2701 - acc: 0.9096 - val_loss: 1.0947 - val_acc: 0.5488\n",
      "Epoch 744/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2754 - acc: 0.9029 - val_loss: 1.0860 - val_acc: 0.5219\n",
      "Epoch 745/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2664 - acc: 0.9164 - val_loss: 1.0700 - val_acc: 0.5421\n",
      "Epoch 746/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2696 - acc: 0.9046 - val_loss: 1.0824 - val_acc: 0.5387\n",
      "Epoch 747/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2660 - acc: 0.9139 - val_loss: 1.0728 - val_acc: 0.5488\n",
      "Epoch 748/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2669 - acc: 0.9130 - val_loss: 1.1912 - val_acc: 0.5219\n",
      "Epoch 749/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2706 - acc: 0.9079 - val_loss: 1.0794 - val_acc: 0.5354\n",
      "Epoch 750/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2699 - acc: 0.9071 - val_loss: 1.0819 - val_acc: 0.5219\n",
      "Epoch 751/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2686 - acc: 0.9029 - val_loss: 1.0706 - val_acc: 0.5286\n",
      "Epoch 752/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2788 - acc: 0.9062 - val_loss: 1.0826 - val_acc: 0.5421\n",
      "Epoch 753/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2642 - acc: 0.9155 - val_loss: 1.0937 - val_acc: 0.5455\n",
      "Epoch 754/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2657 - acc: 0.9147 - val_loss: 1.1258 - val_acc: 0.5286\n",
      "Epoch 755/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2626 - acc: 0.9029 - val_loss: 1.0866 - val_acc: 0.5354\n",
      "Epoch 756/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2634 - acc: 0.9172 - val_loss: 1.0772 - val_acc: 0.5522\n",
      "Epoch 757/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2679 - acc: 0.9046 - val_loss: 1.1004 - val_acc: 0.5253\n",
      "Epoch 758/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2730 - acc: 0.9046 - val_loss: 1.0933 - val_acc: 0.5354\n",
      "Epoch 759/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2649 - acc: 0.9164 - val_loss: 1.0953 - val_acc: 0.5488\n",
      "Epoch 760/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2603 - acc: 0.9139 - val_loss: 1.0819 - val_acc: 0.5219\n",
      "Epoch 761/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2635 - acc: 0.9122 - val_loss: 1.1434 - val_acc: 0.5219\n",
      "Epoch 762/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2650 - acc: 0.9105 - val_loss: 1.0955 - val_acc: 0.5084\n",
      "Epoch 763/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2671 - acc: 0.9062 - val_loss: 1.1083 - val_acc: 0.5286\n",
      "Epoch 764/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2624 - acc: 0.9155 - val_loss: 1.1563 - val_acc: 0.5253\n",
      "Epoch 765/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2632 - acc: 0.9105 - val_loss: 1.1424 - val_acc: 0.5084\n",
      "Epoch 766/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2587 - acc: 0.9231 - val_loss: 1.0902 - val_acc: 0.5421\n",
      "Epoch 767/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2645 - acc: 0.9071 - val_loss: 1.1058 - val_acc: 0.5354\n",
      "Epoch 768/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2660 - acc: 0.9012 - val_loss: 1.1569 - val_acc: 0.5084\n",
      "Epoch 769/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2654 - acc: 0.9122 - val_loss: 1.0901 - val_acc: 0.5286\n",
      "Epoch 770/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.2583 - acc: 0.9096 - val_loss: 1.0996 - val_acc: 0.5354\n",
      "Epoch 771/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2597 - acc: 0.9206 - val_loss: 1.1085 - val_acc: 0.5455\n",
      "Epoch 772/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.2621 - acc: 0.9130 - val_loss: 1.0803 - val_acc: 0.5253\n",
      "Epoch 773/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2587 - acc: 0.9164 - val_loss: 1.0959 - val_acc: 0.5455\n",
      "Epoch 774/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2537 - acc: 0.9274 - val_loss: 1.2118 - val_acc: 0.5084\n",
      "Epoch 775/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2664 - acc: 0.9054 - val_loss: 1.1040 - val_acc: 0.5286\n",
      "Epoch 776/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2623 - acc: 0.9189 - val_loss: 1.0805 - val_acc: 0.5421\n",
      "Epoch 777/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2571 - acc: 0.9079 - val_loss: 1.1019 - val_acc: 0.5488\n",
      "Epoch 778/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2609 - acc: 0.9189 - val_loss: 1.0793 - val_acc: 0.5387\n",
      "Epoch 779/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2551 - acc: 0.9181 - val_loss: 1.1068 - val_acc: 0.5185\n",
      "Epoch 780/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2648 - acc: 0.9139 - val_loss: 1.1130 - val_acc: 0.5185\n",
      "Epoch 781/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2535 - acc: 0.9198 - val_loss: 1.1009 - val_acc: 0.5455\n",
      "Epoch 782/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2611 - acc: 0.9139 - val_loss: 1.0889 - val_acc: 0.5589\n",
      "Epoch 783/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2568 - acc: 0.9172 - val_loss: 1.0857 - val_acc: 0.5522\n",
      "Epoch 784/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2525 - acc: 0.9223 - val_loss: 1.1243 - val_acc: 0.5152\n",
      "Epoch 785/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2626 - acc: 0.9181 - val_loss: 1.1086 - val_acc: 0.5387\n",
      "Epoch 786/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2518 - acc: 0.9231 - val_loss: 1.0983 - val_acc: 0.5253\n",
      "Epoch 787/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2576 - acc: 0.9139 - val_loss: 1.1611 - val_acc: 0.5051\n",
      "Epoch 788/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2552 - acc: 0.9206 - val_loss: 1.0961 - val_acc: 0.5387\n",
      "Epoch 789/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2629 - acc: 0.9155 - val_loss: 1.1617 - val_acc: 0.4983\n",
      "Epoch 790/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2610 - acc: 0.9113 - val_loss: 1.1028 - val_acc: 0.5354\n",
      "Epoch 791/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2565 - acc: 0.9130 - val_loss: 1.1133 - val_acc: 0.5253\n",
      "Epoch 792/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2529 - acc: 0.9215 - val_loss: 1.1255 - val_acc: 0.5286\n",
      "Epoch 793/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2657 - acc: 0.9037 - val_loss: 1.1874 - val_acc: 0.5185\n",
      "Epoch 794/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2540 - acc: 0.9155 - val_loss: 1.1920 - val_acc: 0.5017\n",
      "Epoch 795/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2553 - acc: 0.9147 - val_loss: 1.0969 - val_acc: 0.5455\n",
      "Epoch 796/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2488 - acc: 0.9265 - val_loss: 1.1492 - val_acc: 0.5253\n",
      "Epoch 797/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2615 - acc: 0.9054 - val_loss: 1.1104 - val_acc: 0.5286\n",
      "Epoch 798/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2564 - acc: 0.9071 - val_loss: 1.1154 - val_acc: 0.5556\n",
      "Epoch 799/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2467 - acc: 0.9240 - val_loss: 1.1184 - val_acc: 0.5253\n",
      "Epoch 800/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2671 - acc: 0.9071 - val_loss: 1.1357 - val_acc: 0.5152\n",
      "Epoch 801/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2496 - acc: 0.9257 - val_loss: 1.1500 - val_acc: 0.5354\n",
      "Epoch 802/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2473 - acc: 0.9206 - val_loss: 1.1164 - val_acc: 0.5152\n",
      "Epoch 803/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2585 - acc: 0.9155 - val_loss: 1.1145 - val_acc: 0.5286\n",
      "Epoch 804/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2509 - acc: 0.9223 - val_loss: 1.1104 - val_acc: 0.5421\n",
      "Epoch 805/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2472 - acc: 0.9240 - val_loss: 1.0978 - val_acc: 0.5488\n",
      "Epoch 806/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2503 - acc: 0.9206 - val_loss: 1.1406 - val_acc: 0.5387\n",
      "Epoch 807/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2525 - acc: 0.9147 - val_loss: 1.1899 - val_acc: 0.5421\n",
      "Epoch 808/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2525 - acc: 0.9172 - val_loss: 1.1379 - val_acc: 0.5320\n",
      "Epoch 809/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2477 - acc: 0.9274 - val_loss: 1.1353 - val_acc: 0.5354\n",
      "Epoch 810/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2494 - acc: 0.9164 - val_loss: 1.1041 - val_acc: 0.5455\n",
      "Epoch 811/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2537 - acc: 0.9096 - val_loss: 1.1753 - val_acc: 0.5051\n",
      "Epoch 812/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2463 - acc: 0.9257 - val_loss: 1.1217 - val_acc: 0.5455\n",
      "Epoch 813/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2522 - acc: 0.9231 - val_loss: 1.1422 - val_acc: 0.5354\n",
      "Epoch 814/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2551 - acc: 0.9130 - val_loss: 1.1815 - val_acc: 0.5185\n",
      "Epoch 815/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2543 - acc: 0.9130 - val_loss: 1.1268 - val_acc: 0.5421\n",
      "Epoch 816/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2489 - acc: 0.9215 - val_loss: 1.1288 - val_acc: 0.5152\n",
      "Epoch 817/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2520 - acc: 0.9155 - val_loss: 1.1135 - val_acc: 0.5556\n",
      "Epoch 818/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.2487 - acc: 0.9122 - val_loss: 1.1059 - val_acc: 0.5387\n",
      "Epoch 819/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2463 - acc: 0.9198 - val_loss: 1.1759 - val_acc: 0.5152\n",
      "Epoch 820/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2522 - acc: 0.9181 - val_loss: 1.1167 - val_acc: 0.5421\n",
      "Epoch 821/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.2458 - acc: 0.9189 - val_loss: 1.1184 - val_acc: 0.5354\n",
      "Epoch 822/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2447 - acc: 0.9257 - val_loss: 1.1622 - val_acc: 0.5421\n",
      "Epoch 823/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2509 - acc: 0.9189 - val_loss: 1.1297 - val_acc: 0.5286\n",
      "Epoch 824/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2419 - acc: 0.9231 - val_loss: 1.1265 - val_acc: 0.5219\n",
      "Epoch 825/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2488 - acc: 0.9105 - val_loss: 1.1206 - val_acc: 0.5253\n",
      "Epoch 826/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2466 - acc: 0.9215 - val_loss: 1.1126 - val_acc: 0.5488\n",
      "Epoch 827/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2440 - acc: 0.9147 - val_loss: 1.1592 - val_acc: 0.5488\n",
      "Epoch 828/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2470 - acc: 0.9189 - val_loss: 1.1126 - val_acc: 0.5354\n",
      "Epoch 829/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2447 - acc: 0.9189 - val_loss: 1.1218 - val_acc: 0.5320\n",
      "Epoch 830/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2420 - acc: 0.9198 - val_loss: 1.1440 - val_acc: 0.5421\n",
      "Epoch 831/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2485 - acc: 0.9130 - val_loss: 1.1521 - val_acc: 0.5354\n",
      "Epoch 832/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2438 - acc: 0.9155 - val_loss: 1.1431 - val_acc: 0.5286\n",
      "Epoch 833/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2386 - acc: 0.9189 - val_loss: 1.1884 - val_acc: 0.5084\n",
      "Epoch 834/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2544 - acc: 0.9172 - val_loss: 1.1600 - val_acc: 0.5253\n",
      "Epoch 835/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2402 - acc: 0.9231 - val_loss: 1.1598 - val_acc: 0.5219\n",
      "Epoch 836/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2470 - acc: 0.9189 - val_loss: 1.1239 - val_acc: 0.5286\n",
      "Epoch 837/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2457 - acc: 0.9240 - val_loss: 1.2183 - val_acc: 0.5084\n",
      "Epoch 838/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2418 - acc: 0.9172 - val_loss: 1.1298 - val_acc: 0.5219\n",
      "Epoch 839/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2374 - acc: 0.9324 - val_loss: 1.1669 - val_acc: 0.5286\n",
      "Epoch 840/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2452 - acc: 0.9189 - val_loss: 1.1413 - val_acc: 0.5253\n",
      "Epoch 841/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2382 - acc: 0.9265 - val_loss: 1.1578 - val_acc: 0.5387\n",
      "Epoch 842/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2464 - acc: 0.9088 - val_loss: 1.1463 - val_acc: 0.5455\n",
      "Epoch 843/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2393 - acc: 0.9206 - val_loss: 1.1545 - val_acc: 0.5320\n",
      "Epoch 844/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2463 - acc: 0.9206 - val_loss: 1.2006 - val_acc: 0.5286\n",
      "Epoch 845/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2379 - acc: 0.9257 - val_loss: 1.1355 - val_acc: 0.5118\n",
      "Epoch 846/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2344 - acc: 0.9231 - val_loss: 1.1414 - val_acc: 0.5185\n",
      "Epoch 847/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2452 - acc: 0.9206 - val_loss: 1.1435 - val_acc: 0.5455\n",
      "Epoch 848/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2571 - acc: 0.9113 - val_loss: 1.1364 - val_acc: 0.5387\n",
      "Epoch 849/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2351 - acc: 0.9307 - val_loss: 1.1432 - val_acc: 0.5219\n",
      "Epoch 850/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2347 - acc: 0.9291 - val_loss: 1.1487 - val_acc: 0.5488\n",
      "Epoch 851/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2479 - acc: 0.9155 - val_loss: 1.1988 - val_acc: 0.5051\n",
      "Epoch 852/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2399 - acc: 0.9172 - val_loss: 1.2070 - val_acc: 0.5488\n",
      "Epoch 853/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2364 - acc: 0.9215 - val_loss: 1.1381 - val_acc: 0.5253\n",
      "Epoch 854/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.2412 - acc: 0.9240 - val_loss: 1.1305 - val_acc: 0.5320\n",
      "Epoch 855/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2452 - acc: 0.9206 - val_loss: 1.1390 - val_acc: 0.5421\n",
      "Epoch 856/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2330 - acc: 0.9282 - val_loss: 1.1642 - val_acc: 0.5421\n",
      "Epoch 857/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2389 - acc: 0.9257 - val_loss: 1.1542 - val_acc: 0.5253\n",
      "Epoch 858/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2319 - acc: 0.9274 - val_loss: 1.1417 - val_acc: 0.5320\n",
      "Epoch 859/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2485 - acc: 0.9071 - val_loss: 1.1454 - val_acc: 0.5455\n",
      "Epoch 860/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2335 - acc: 0.9240 - val_loss: 1.1456 - val_acc: 0.5320\n",
      "Epoch 861/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2359 - acc: 0.9189 - val_loss: 1.1543 - val_acc: 0.5219\n",
      "Epoch 862/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2369 - acc: 0.9240 - val_loss: 1.1799 - val_acc: 0.5488\n",
      "Epoch 863/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2418 - acc: 0.9206 - val_loss: 1.1494 - val_acc: 0.5286\n",
      "Epoch 864/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2348 - acc: 0.9240 - val_loss: 1.1525 - val_acc: 0.5354\n",
      "Epoch 865/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.2440 - acc: 0.9172 - val_loss: 1.1824 - val_acc: 0.5152\n",
      "Epoch 866/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2417 - acc: 0.9130 - val_loss: 1.1431 - val_acc: 0.5320\n",
      "Epoch 867/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2370 - acc: 0.9265 - val_loss: 1.1401 - val_acc: 0.5354\n",
      "Epoch 868/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2449 - acc: 0.9130 - val_loss: 1.1569 - val_acc: 0.5185\n",
      "Epoch 869/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2314 - acc: 0.9231 - val_loss: 1.1718 - val_acc: 0.5286\n",
      "Epoch 870/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2317 - acc: 0.9240 - val_loss: 1.2119 - val_acc: 0.5219\n",
      "Epoch 871/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2406 - acc: 0.9172 - val_loss: 1.1989 - val_acc: 0.5185\n",
      "Epoch 872/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2295 - acc: 0.9257 - val_loss: 1.1415 - val_acc: 0.5320\n",
      "Epoch 873/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2332 - acc: 0.9282 - val_loss: 1.1468 - val_acc: 0.5320\n",
      "Epoch 874/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2468 - acc: 0.9130 - val_loss: 1.1444 - val_acc: 0.5455\n",
      "Epoch 875/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2288 - acc: 0.9341 - val_loss: 1.1772 - val_acc: 0.5320\n",
      "Epoch 876/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2416 - acc: 0.9231 - val_loss: 1.1579 - val_acc: 0.5387\n",
      "Epoch 877/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2327 - acc: 0.9240 - val_loss: 1.1714 - val_acc: 0.5320\n",
      "Epoch 878/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2379 - acc: 0.9172 - val_loss: 1.1632 - val_acc: 0.5286\n",
      "Epoch 879/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2386 - acc: 0.9155 - val_loss: 1.1612 - val_acc: 0.5320\n",
      "Epoch 880/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2280 - acc: 0.9257 - val_loss: 1.1520 - val_acc: 0.5387\n",
      "Epoch 881/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2361 - acc: 0.9257 - val_loss: 1.1573 - val_acc: 0.5455\n",
      "Epoch 882/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2375 - acc: 0.9223 - val_loss: 1.1607 - val_acc: 0.5455\n",
      "Epoch 883/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2233 - acc: 0.9324 - val_loss: 1.1474 - val_acc: 0.5354\n",
      "Epoch 884/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2451 - acc: 0.9189 - val_loss: 1.1502 - val_acc: 0.5455\n",
      "Epoch 885/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2250 - acc: 0.9316 - val_loss: 1.1489 - val_acc: 0.5455\n",
      "Epoch 886/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2307 - acc: 0.9291 - val_loss: 1.1675 - val_acc: 0.5387\n",
      "Epoch 887/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2301 - acc: 0.9248 - val_loss: 1.2544 - val_acc: 0.5152\n",
      "Epoch 888/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2249 - acc: 0.9265 - val_loss: 1.1695 - val_acc: 0.5219\n",
      "Epoch 889/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2311 - acc: 0.9248 - val_loss: 1.1376 - val_acc: 0.5522\n",
      "Epoch 890/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2303 - acc: 0.9274 - val_loss: 1.1488 - val_acc: 0.5320\n",
      "Epoch 891/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2330 - acc: 0.9274 - val_loss: 1.2018 - val_acc: 0.5488\n",
      "Epoch 892/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2278 - acc: 0.9316 - val_loss: 1.2076 - val_acc: 0.5286\n",
      "Epoch 893/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2333 - acc: 0.9223 - val_loss: 1.1592 - val_acc: 0.5488\n",
      "Epoch 894/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2304 - acc: 0.9274 - val_loss: 1.1536 - val_acc: 0.5488\n",
      "Epoch 895/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2225 - acc: 0.9291 - val_loss: 1.1691 - val_acc: 0.5219\n",
      "Epoch 896/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2341 - acc: 0.9240 - val_loss: 1.1469 - val_acc: 0.5455\n",
      "Epoch 897/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2272 - acc: 0.9307 - val_loss: 1.1585 - val_acc: 0.5387\n",
      "Epoch 898/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2319 - acc: 0.9231 - val_loss: 1.1622 - val_acc: 0.5320\n",
      "Epoch 899/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2271 - acc: 0.9198 - val_loss: 1.1628 - val_acc: 0.5320\n",
      "Epoch 900/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2304 - acc: 0.9206 - val_loss: 1.1694 - val_acc: 0.5556\n",
      "Epoch 901/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2231 - acc: 0.9299 - val_loss: 1.1944 - val_acc: 0.5286\n",
      "Epoch 902/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2366 - acc: 0.9206 - val_loss: 1.1613 - val_acc: 0.5286\n",
      "Epoch 903/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2352 - acc: 0.9147 - val_loss: 1.1906 - val_acc: 0.5387\n",
      "Epoch 904/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2239 - acc: 0.9333 - val_loss: 1.2001 - val_acc: 0.5253\n",
      "Epoch 905/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2301 - acc: 0.9240 - val_loss: 1.2053 - val_acc: 0.5387\n",
      "Epoch 906/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.2196 - acc: 0.9367 - val_loss: 1.2860 - val_acc: 0.5421\n",
      "Epoch 907/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.2349 - acc: 0.9139 - val_loss: 1.1936 - val_acc: 0.5421\n",
      "Epoch 908/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2284 - acc: 0.9307 - val_loss: 1.1821 - val_acc: 0.5421\n",
      "Epoch 909/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2202 - acc: 0.9307 - val_loss: 1.1605 - val_acc: 0.5185\n",
      "Epoch 910/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2299 - acc: 0.9206 - val_loss: 1.1719 - val_acc: 0.5421\n",
      "Epoch 911/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2211 - acc: 0.9282 - val_loss: 1.1816 - val_acc: 0.5354\n",
      "Epoch 912/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2221 - acc: 0.9307 - val_loss: 1.1840 - val_acc: 0.5219\n",
      "Epoch 913/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2208 - acc: 0.9333 - val_loss: 1.1585 - val_acc: 0.5387\n",
      "Epoch 914/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2276 - acc: 0.9206 - val_loss: 1.2753 - val_acc: 0.5219\n",
      "Epoch 915/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2231 - acc: 0.9324 - val_loss: 1.1652 - val_acc: 0.5387\n",
      "Epoch 916/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2211 - acc: 0.9350 - val_loss: 1.2345 - val_acc: 0.5253\n",
      "Epoch 917/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2278 - acc: 0.9257 - val_loss: 1.1649 - val_acc: 0.5320\n",
      "Epoch 918/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2262 - acc: 0.9257 - val_loss: 1.2044 - val_acc: 0.5084\n",
      "Epoch 919/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2279 - acc: 0.9231 - val_loss: 1.1917 - val_acc: 0.5253\n",
      "Epoch 920/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2277 - acc: 0.9248 - val_loss: 1.1977 - val_acc: 0.5219\n",
      "Epoch 921/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2213 - acc: 0.9299 - val_loss: 1.1748 - val_acc: 0.5421\n",
      "Epoch 922/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2165 - acc: 0.9426 - val_loss: 1.1783 - val_acc: 0.5488\n",
      "Epoch 923/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2238 - acc: 0.9299 - val_loss: 1.1737 - val_acc: 0.5354\n",
      "Epoch 924/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2292 - acc: 0.9181 - val_loss: 1.1865 - val_acc: 0.5286\n",
      "Epoch 925/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2232 - acc: 0.9198 - val_loss: 1.2294 - val_acc: 0.5185\n",
      "Epoch 926/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2236 - acc: 0.9189 - val_loss: 1.1990 - val_acc: 0.5421\n",
      "Epoch 927/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2226 - acc: 0.9282 - val_loss: 1.2512 - val_acc: 0.5152\n",
      "Epoch 928/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2241 - acc: 0.9189 - val_loss: 1.1758 - val_acc: 0.5320\n",
      "Epoch 929/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2188 - acc: 0.9307 - val_loss: 1.2169 - val_acc: 0.5185\n",
      "Epoch 930/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2253 - acc: 0.9341 - val_loss: 1.2088 - val_acc: 0.5387\n",
      "Epoch 931/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2177 - acc: 0.9248 - val_loss: 1.1933 - val_acc: 0.5421\n",
      "Epoch 932/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2206 - acc: 0.9248 - val_loss: 1.1849 - val_acc: 0.5286\n",
      "Epoch 933/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.2239 - acc: 0.9248 - val_loss: 1.1885 - val_acc: 0.5286\n",
      "Epoch 934/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2188 - acc: 0.9299 - val_loss: 1.1892 - val_acc: 0.5286\n",
      "Epoch 935/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2145 - acc: 0.9316 - val_loss: 1.1747 - val_acc: 0.5354\n",
      "Epoch 936/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2247 - acc: 0.9231 - val_loss: 1.1901 - val_acc: 0.5219\n",
      "Epoch 937/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2196 - acc: 0.9257 - val_loss: 1.2032 - val_acc: 0.5387\n",
      "Epoch 938/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2205 - acc: 0.9299 - val_loss: 1.2096 - val_acc: 0.5455\n",
      "Epoch 939/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2202 - acc: 0.9358 - val_loss: 1.2018 - val_acc: 0.5253\n",
      "Epoch 940/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2165 - acc: 0.9291 - val_loss: 1.1667 - val_acc: 0.5421\n",
      "Epoch 941/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2140 - acc: 0.9400 - val_loss: 1.2366 - val_acc: 0.5387\n",
      "Epoch 942/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2228 - acc: 0.9282 - val_loss: 1.1932 - val_acc: 0.5421\n",
      "Epoch 943/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2229 - acc: 0.9291 - val_loss: 1.2052 - val_acc: 0.5387\n",
      "Epoch 944/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2145 - acc: 0.9350 - val_loss: 1.2924 - val_acc: 0.5152\n",
      "Epoch 945/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2177 - acc: 0.9341 - val_loss: 1.1850 - val_acc: 0.5488\n",
      "Epoch 946/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2188 - acc: 0.9324 - val_loss: 1.1881 - val_acc: 0.5488\n",
      "Epoch 947/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2200 - acc: 0.9324 - val_loss: 1.2361 - val_acc: 0.5051\n",
      "Epoch 948/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2176 - acc: 0.9316 - val_loss: 1.1861 - val_acc: 0.5387\n",
      "Epoch 949/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2116 - acc: 0.9341 - val_loss: 1.1877 - val_acc: 0.5354\n",
      "Epoch 950/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2159 - acc: 0.9291 - val_loss: 1.3005 - val_acc: 0.5185\n",
      "Epoch 951/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2146 - acc: 0.9367 - val_loss: 1.1884 - val_acc: 0.5286\n",
      "Epoch 952/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2233 - acc: 0.9231 - val_loss: 1.2464 - val_acc: 0.5354\n",
      "Epoch 953/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2148 - acc: 0.9307 - val_loss: 1.1777 - val_acc: 0.5354\n",
      "Epoch 954/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2174 - acc: 0.9265 - val_loss: 1.1915 - val_acc: 0.5253\n",
      "Epoch 955/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2140 - acc: 0.9367 - val_loss: 1.2165 - val_acc: 0.5320\n",
      "Epoch 956/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.2253 - acc: 0.9282 - val_loss: 1.1899 - val_acc: 0.5387\n",
      "Epoch 957/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2143 - acc: 0.9341 - val_loss: 1.2003 - val_acc: 0.5320\n",
      "Epoch 958/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.2155 - acc: 0.9307 - val_loss: 1.2102 - val_acc: 0.5219\n",
      "Epoch 959/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2128 - acc: 0.9333 - val_loss: 1.3024 - val_acc: 0.5253\n",
      "Epoch 960/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2126 - acc: 0.9324 - val_loss: 1.1901 - val_acc: 0.5354\n",
      "Epoch 961/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2138 - acc: 0.9316 - val_loss: 1.2129 - val_acc: 0.5219\n",
      "Epoch 962/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2183 - acc: 0.9265 - val_loss: 1.3106 - val_acc: 0.5084\n",
      "Epoch 963/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2108 - acc: 0.9350 - val_loss: 1.2060 - val_acc: 0.5320\n",
      "Epoch 964/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2103 - acc: 0.9291 - val_loss: 1.2471 - val_acc: 0.5354\n",
      "Epoch 965/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2139 - acc: 0.9358 - val_loss: 1.2024 - val_acc: 0.5455\n",
      "Epoch 966/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2103 - acc: 0.9417 - val_loss: 1.3332 - val_acc: 0.5017\n",
      "Epoch 967/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2124 - acc: 0.9324 - val_loss: 1.2376 - val_acc: 0.5354\n",
      "Epoch 968/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2218 - acc: 0.9223 - val_loss: 1.2964 - val_acc: 0.5219\n",
      "Epoch 969/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2177 - acc: 0.9291 - val_loss: 1.1863 - val_acc: 0.5421\n",
      "Epoch 970/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2077 - acc: 0.9375 - val_loss: 1.2221 - val_acc: 0.5421\n",
      "Epoch 971/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2128 - acc: 0.9358 - val_loss: 1.2186 - val_acc: 0.5320\n",
      "Epoch 972/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2123 - acc: 0.9375 - val_loss: 1.2164 - val_acc: 0.5152\n",
      "Epoch 973/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2115 - acc: 0.9316 - val_loss: 1.3116 - val_acc: 0.5051\n",
      "Epoch 974/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2169 - acc: 0.9282 - val_loss: 1.2181 - val_acc: 0.5185\n",
      "Epoch 975/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2050 - acc: 0.9375 - val_loss: 1.2516 - val_acc: 0.5219\n",
      "Epoch 976/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2104 - acc: 0.9341 - val_loss: 1.2428 - val_acc: 0.5253\n",
      "Epoch 977/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2128 - acc: 0.9307 - val_loss: 1.2258 - val_acc: 0.4983\n",
      "Epoch 978/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2066 - acc: 0.9358 - val_loss: 1.2113 - val_acc: 0.5421\n",
      "Epoch 979/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2101 - acc: 0.9350 - val_loss: 1.2171 - val_acc: 0.5185\n",
      "Epoch 980/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2147 - acc: 0.9333 - val_loss: 1.2359 - val_acc: 0.5387\n",
      "Epoch 981/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2085 - acc: 0.9333 - val_loss: 1.1969 - val_acc: 0.5286\n",
      "Epoch 982/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2071 - acc: 0.9383 - val_loss: 1.2058 - val_acc: 0.5387\n",
      "Epoch 983/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2193 - acc: 0.9257 - val_loss: 1.2666 - val_acc: 0.5152\n",
      "Epoch 984/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.2087 - acc: 0.9350 - val_loss: 1.2348 - val_acc: 0.5219\n",
      "Epoch 985/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2077 - acc: 0.9392 - val_loss: 1.2322 - val_acc: 0.5354\n",
      "Epoch 986/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2020 - acc: 0.9392 - val_loss: 1.2279 - val_acc: 0.5455\n",
      "Epoch 987/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2250 - acc: 0.9215 - val_loss: 1.2521 - val_acc: 0.5286\n",
      "Epoch 988/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2058 - acc: 0.9367 - val_loss: 1.2457 - val_acc: 0.5253\n",
      "Epoch 989/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2050 - acc: 0.9333 - val_loss: 1.2723 - val_acc: 0.5185\n",
      "Epoch 990/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2184 - acc: 0.9307 - val_loss: 1.2745 - val_acc: 0.5253\n",
      "Epoch 991/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2096 - acc: 0.9367 - val_loss: 1.2303 - val_acc: 0.5354\n",
      "Epoch 992/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2089 - acc: 0.9409 - val_loss: 1.3420 - val_acc: 0.5152\n",
      "Epoch 993/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2109 - acc: 0.9307 - val_loss: 1.2296 - val_acc: 0.5219\n",
      "Epoch 994/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2204 - acc: 0.9291 - val_loss: 1.2056 - val_acc: 0.5387\n",
      "Epoch 995/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2048 - acc: 0.9375 - val_loss: 1.2316 - val_acc: 0.5253\n",
      "Epoch 996/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2141 - acc: 0.9299 - val_loss: 1.2067 - val_acc: 0.5421\n",
      "Epoch 997/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2033 - acc: 0.9367 - val_loss: 1.2358 - val_acc: 0.5320\n",
      "Epoch 998/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2136 - acc: 0.9316 - val_loss: 1.2634 - val_acc: 0.5589\n",
      "Epoch 999/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2008 - acc: 0.9341 - val_loss: 1.2513 - val_acc: 0.5387\n",
      "Epoch 1000/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2133 - acc: 0.9291 - val_loss: 1.2449 - val_acc: 0.5320\n",
      "Epoch 1001/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2076 - acc: 0.9350 - val_loss: 1.2299 - val_acc: 0.5253\n",
      "Epoch 1002/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2045 - acc: 0.9350 - val_loss: 1.2172 - val_acc: 0.5455\n",
      "Epoch 1003/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2022 - acc: 0.9367 - val_loss: 1.2268 - val_acc: 0.5589\n",
      "Epoch 1004/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2034 - acc: 0.9383 - val_loss: 1.2517 - val_acc: 0.5320\n",
      "Epoch 1005/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2073 - acc: 0.9341 - val_loss: 1.2237 - val_acc: 0.5286\n",
      "Epoch 1006/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2094 - acc: 0.9375 - val_loss: 1.2555 - val_acc: 0.5185\n",
      "Epoch 1007/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2083 - acc: 0.9307 - val_loss: 1.2388 - val_acc: 0.5320\n",
      "Epoch 1008/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2042 - acc: 0.9400 - val_loss: 1.2559 - val_acc: 0.5421\n",
      "Epoch 1009/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2034 - acc: 0.9350 - val_loss: 1.3126 - val_acc: 0.5118\n",
      "Epoch 1010/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2088 - acc: 0.9299 - val_loss: 1.2383 - val_acc: 0.5354\n",
      "Epoch 1011/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2026 - acc: 0.9375 - val_loss: 1.2268 - val_acc: 0.5522\n",
      "Epoch 1012/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2173 - acc: 0.9240 - val_loss: 1.2302 - val_acc: 0.5387\n",
      "Epoch 1013/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2008 - acc: 0.9307 - val_loss: 1.2343 - val_acc: 0.5455\n",
      "Epoch 1014/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2005 - acc: 0.9358 - val_loss: 1.2337 - val_acc: 0.5253\n",
      "Epoch 1015/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2041 - acc: 0.9392 - val_loss: 1.2521 - val_acc: 0.5387\n",
      "Epoch 1016/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2053 - acc: 0.9333 - val_loss: 1.3236 - val_acc: 0.5185\n",
      "Epoch 1017/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1972 - acc: 0.9434 - val_loss: 1.2613 - val_acc: 0.5421\n",
      "Epoch 1018/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2006 - acc: 0.9392 - val_loss: 1.2205 - val_acc: 0.5286\n",
      "Epoch 1019/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1964 - acc: 0.9459 - val_loss: 1.2359 - val_acc: 0.5253\n",
      "Epoch 1020/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2050 - acc: 0.9341 - val_loss: 1.2496 - val_acc: 0.5320\n",
      "Epoch 1021/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2044 - acc: 0.9375 - val_loss: 1.3581 - val_acc: 0.5152\n",
      "Epoch 1022/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2123 - acc: 0.9257 - val_loss: 1.2380 - val_acc: 0.5488\n",
      "Epoch 1023/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1991 - acc: 0.9341 - val_loss: 1.2483 - val_acc: 0.5421\n",
      "Epoch 1024/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1970 - acc: 0.9392 - val_loss: 1.2293 - val_acc: 0.5488\n",
      "Epoch 1025/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1995 - acc: 0.9451 - val_loss: 1.2326 - val_acc: 0.5421\n",
      "Epoch 1026/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2105 - acc: 0.9316 - val_loss: 1.2239 - val_acc: 0.5455\n",
      "Epoch 1027/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1995 - acc: 0.9375 - val_loss: 1.2278 - val_acc: 0.5286\n",
      "Epoch 1028/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1992 - acc: 0.9350 - val_loss: 1.2438 - val_acc: 0.5455\n",
      "Epoch 1029/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1980 - acc: 0.9383 - val_loss: 1.3671 - val_acc: 0.5253\n",
      "Epoch 1030/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.2055 - acc: 0.9324 - val_loss: 1.2212 - val_acc: 0.5219\n",
      "Epoch 1031/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2018 - acc: 0.9333 - val_loss: 1.3176 - val_acc: 0.5354\n",
      "Epoch 1032/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1958 - acc: 0.9426 - val_loss: 1.2648 - val_acc: 0.5387\n",
      "Epoch 1033/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1986 - acc: 0.9392 - val_loss: 1.2373 - val_acc: 0.5354\n",
      "Epoch 1034/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1980 - acc: 0.9358 - val_loss: 1.2826 - val_acc: 0.5084\n",
      "Epoch 1035/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2002 - acc: 0.9375 - val_loss: 1.2740 - val_acc: 0.5387\n",
      "Epoch 1036/1100\n",
      "1184/1184 [==============================] - 0s 15us/step - loss: 0.2019 - acc: 0.9316 - val_loss: 1.2716 - val_acc: 0.5421\n",
      "Epoch 1037/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2003 - acc: 0.9417 - val_loss: 1.2869 - val_acc: 0.5286\n",
      "Epoch 1038/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1983 - acc: 0.9409 - val_loss: 1.2425 - val_acc: 0.5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1039/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9341 - val_loss: 1.2547 - val_acc: 0.5320\n",
      "Epoch 1040/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2002 - acc: 0.9409 - val_loss: 1.2646 - val_acc: 0.5421\n",
      "Epoch 1041/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1933 - acc: 0.9434 - val_loss: 1.2647 - val_acc: 0.5421\n",
      "Epoch 1042/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2016 - acc: 0.9383 - val_loss: 1.2463 - val_acc: 0.5253\n",
      "Epoch 1043/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1989 - acc: 0.9392 - val_loss: 1.2774 - val_acc: 0.5219\n",
      "Epoch 1044/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2085 - acc: 0.9282 - val_loss: 1.3743 - val_acc: 0.5185\n",
      "Epoch 1045/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1939 - acc: 0.9375 - val_loss: 1.2570 - val_acc: 0.5354\n",
      "Epoch 1046/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1941 - acc: 0.9383 - val_loss: 1.2845 - val_acc: 0.5253\n",
      "Epoch 1047/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2041 - acc: 0.9383 - val_loss: 1.2692 - val_acc: 0.5320\n",
      "Epoch 1048/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2019 - acc: 0.9350 - val_loss: 1.2744 - val_acc: 0.5320\n",
      "Epoch 1049/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2031 - acc: 0.9350 - val_loss: 1.2389 - val_acc: 0.5488\n",
      "Epoch 1050/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1969 - acc: 0.9367 - val_loss: 1.2863 - val_acc: 0.5118\n",
      "Epoch 1051/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1923 - acc: 0.9434 - val_loss: 1.2610 - val_acc: 0.5421\n",
      "Epoch 1052/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1993 - acc: 0.9333 - val_loss: 1.2834 - val_acc: 0.5522\n",
      "Epoch 1053/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1954 - acc: 0.9375 - val_loss: 1.2488 - val_acc: 0.5421\n",
      "Epoch 1054/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2058 - acc: 0.9316 - val_loss: 1.2780 - val_acc: 0.5320\n",
      "Epoch 1055/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1923 - acc: 0.9375 - val_loss: 1.2629 - val_acc: 0.5219\n",
      "Epoch 1056/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.2020 - acc: 0.9265 - val_loss: 1.2597 - val_acc: 0.5387\n",
      "Epoch 1057/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1908 - acc: 0.9400 - val_loss: 1.3021 - val_acc: 0.5421\n",
      "Epoch 1058/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1975 - acc: 0.9392 - val_loss: 1.2733 - val_acc: 0.5219\n",
      "Epoch 1059/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1955 - acc: 0.9400 - val_loss: 1.2571 - val_acc: 0.5455\n",
      "Epoch 1060/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1937 - acc: 0.9375 - val_loss: 1.2643 - val_acc: 0.5387\n",
      "Epoch 1061/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.2070 - acc: 0.9350 - val_loss: 1.3029 - val_acc: 0.5320\n",
      "Epoch 1062/1100\n",
      "1184/1184 [==============================] - 0s 16us/step - loss: 0.1962 - acc: 0.9383 - val_loss: 1.2675 - val_acc: 0.5118\n",
      "Epoch 1063/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1922 - acc: 0.9383 - val_loss: 1.2779 - val_acc: 0.5354\n",
      "Epoch 1064/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1967 - acc: 0.9341 - val_loss: 1.2710 - val_acc: 0.5387\n",
      "Epoch 1065/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1927 - acc: 0.9367 - val_loss: 1.2795 - val_acc: 0.5185\n",
      "Epoch 1066/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1994 - acc: 0.9341 - val_loss: 1.2611 - val_acc: 0.5354\n",
      "Epoch 1067/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1894 - acc: 0.9417 - val_loss: 1.2821 - val_acc: 0.5219\n",
      "Epoch 1068/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1967 - acc: 0.9358 - val_loss: 1.2596 - val_acc: 0.5320\n",
      "Epoch 1069/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1859 - acc: 0.9459 - val_loss: 1.2706 - val_acc: 0.5253\n",
      "Epoch 1070/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1956 - acc: 0.9341 - val_loss: 1.2449 - val_acc: 0.5455\n",
      "Epoch 1071/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1942 - acc: 0.9409 - val_loss: 1.2783 - val_acc: 0.5185\n",
      "Epoch 1072/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1897 - acc: 0.9434 - val_loss: 1.2796 - val_acc: 0.5455\n",
      "Epoch 1073/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1915 - acc: 0.9400 - val_loss: 1.5335 - val_acc: 0.5387\n",
      "Epoch 1074/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1997 - acc: 0.9324 - val_loss: 1.2844 - val_acc: 0.5320\n",
      "Epoch 1075/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1892 - acc: 0.9400 - val_loss: 1.3172 - val_acc: 0.5253\n",
      "Epoch 1076/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1998 - acc: 0.9299 - val_loss: 1.2977 - val_acc: 0.5286\n",
      "Epoch 1077/1100\n",
      "1184/1184 [==============================] - 0s 23us/step - loss: 0.1929 - acc: 0.9434 - val_loss: 1.3631 - val_acc: 0.5084\n",
      "Epoch 1078/1100\n",
      "1184/1184 [==============================] - 0s 22us/step - loss: 0.1888 - acc: 0.9409 - val_loss: 1.2679 - val_acc: 0.5219\n",
      "Epoch 1079/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2062 - acc: 0.9324 - val_loss: 1.2787 - val_acc: 0.5118\n",
      "Epoch 1080/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1880 - acc: 0.9434 - val_loss: 1.4794 - val_acc: 0.5286\n",
      "Epoch 1081/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1973 - acc: 0.9282 - val_loss: 1.2793 - val_acc: 0.5387\n",
      "Epoch 1082/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1882 - acc: 0.9392 - val_loss: 1.4215 - val_acc: 0.5253\n",
      "Epoch 1083/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1945 - acc: 0.9291 - val_loss: 1.2704 - val_acc: 0.5286\n",
      "Epoch 1084/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1932 - acc: 0.9375 - val_loss: 1.2892 - val_acc: 0.5320\n",
      "Epoch 1085/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1867 - acc: 0.9417 - val_loss: 1.3039 - val_acc: 0.5354\n",
      "Epoch 1086/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1931 - acc: 0.9426 - val_loss: 1.2545 - val_acc: 0.5387\n",
      "Epoch 1087/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1887 - acc: 0.9400 - val_loss: 1.2747 - val_acc: 0.5286\n",
      "Epoch 1088/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1893 - acc: 0.9417 - val_loss: 1.3137 - val_acc: 0.5253\n",
      "Epoch 1089/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.1863 - acc: 0.9476 - val_loss: 1.2589 - val_acc: 0.5421\n",
      "Epoch 1090/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.2009 - acc: 0.9350 - val_loss: 1.2659 - val_acc: 0.5421\n",
      "Epoch 1091/1100\n",
      "1184/1184 [==============================] - 0s 17us/step - loss: 0.1838 - acc: 0.9434 - val_loss: 1.2805 - val_acc: 0.5354\n",
      "Epoch 1092/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1875 - acc: 0.9350 - val_loss: 1.2758 - val_acc: 0.5320\n",
      "Epoch 1093/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1883 - acc: 0.9434 - val_loss: 1.3004 - val_acc: 0.5354\n",
      "Epoch 1094/1100\n",
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1943 - acc: 0.9400 - val_loss: 1.2826 - val_acc: 0.5455\n",
      "Epoch 1095/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1880 - acc: 0.9451 - val_loss: 1.3300 - val_acc: 0.5152\n",
      "Epoch 1096/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1945 - acc: 0.9392 - val_loss: 1.2597 - val_acc: 0.5387\n",
      "Epoch 1097/1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 0s 19us/step - loss: 0.1869 - acc: 0.9383 - val_loss: 1.3136 - val_acc: 0.5253\n",
      "Epoch 1098/1100\n",
      "1184/1184 [==============================] - 0s 20us/step - loss: 0.1869 - acc: 0.9392 - val_loss: 1.2705 - val_acc: 0.5488\n",
      "Epoch 1099/1100\n",
      "1184/1184 [==============================] - 0s 18us/step - loss: 0.2008 - acc: 0.9274 - val_loss: 1.2695 - val_acc: 0.5421\n",
      "Epoch 1100/1100\n",
      "1184/1184 [==============================] - 0s 21us/step - loss: 0.1861 - acc: 0.9392 - val_loss: 1.2948 - val_acc: 0.5152\n"
     ]
    }
   ],
   "source": [
    "validation_data_split = 0.2\n",
    "num_epochs = 1100\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 20\n",
    "early_patience = 100\n",
    "#tensorboard is used for visualization\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "#earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "#Early stopping happens when the quantity monitored stops increasing or decreasing\n",
    "# Read Dataset\n",
    "dataset = pd.read_csv('final_sub.csv')\n",
    "\n",
    "# Process Dataset\n",
    "processedData, processedLabel = processData(dataset)\n",
    "history = model.fit(processedData\n",
    "                    , processedLabel\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb]\n",
    "                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest = pd.read_csv('final_sub.csv')\n",
    "datatest1,datalabel = testData(datatest)\n",
    "#np.set_printoptions(precision=4, suppress=True)\n",
    "k,l = datatest1.shape\n",
    "\n",
    "eval_results = model.predict(datatest1)\n",
    "#print(\"\\nLoss, accuracy on test data: \")\n",
    "#print(\"%0.4f %0.2f%%\" % (eval_results[0], \\\n",
    " #eval_results[1]*100))\n",
    "\n",
    "for i in range(97):\n",
    "    if(eval_results[i]>0.5):\n",
    "        eval_results[i] = 1\n",
    "    else:\n",
    "        eval_results[i] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(k):\n",
    "    if (eval_results[i] == datalabel[1482+i]):\n",
    "        correct = correct +1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "        \n",
    "print (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1d107f0c50>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c396d1b38>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c36ca6588>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c38b7c198>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c372f6400>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on GSC dataset with concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "maxAcc = 0.0\n",
    "maxIter = 0\n",
    "C_Lambda = 0.03 #for regularization of closed form\n",
    "TrainingPercent = 80\n",
    "ValidationPercent = 10\n",
    "TestPercent = 10\n",
    "M = 20 # no of basis function\n",
    "PHI = [] #Matrix for basis function\n",
    "IsSynthetic = False\n",
    "\n",
    "def GetTargetVector(filePath,k):\n",
    "    t = []\n",
    "    with open(filePath, 'rU') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:  \n",
    "            t.append(int(row[k]))\n",
    "    #print(\"Raw Training Generated..\")\n",
    "    return t\n",
    "#append the csv file data in dataMatrix\n",
    "def GenerateRawData(filePath, IsSynthetic,k):    \n",
    "    dataMatrix = [] \n",
    "    with open(filePath, 'rU') as fi:\n",
    "        reader = csv.reader(fi)\n",
    "        for row in reader:\n",
    "            dataRow = []\n",
    "            for column in row[0:k]:\n",
    "\n",
    "                dataRow.append(float(column))\n",
    "            dataMatrix.append(dataRow) \n",
    "    #delete those columns have variance 0 \n",
    "    if IsSynthetic == False :\n",
    "        dataMatrix = np.delete(dataMatrix, [450,452,456,457,962,964,968], axis=1)\n",
    "    dataMatrix = np.transpose(dataMatrix)\n",
    "    return dataMatrix\n",
    "\n",
    "def GenerateTrainingTarget(rawTraining,TrainingPercent = 80):\n",
    "    TrainingLen = int(math.ceil(len(rawTraining)*(TrainingPercent*0.01)))\n",
    "    t           = rawTraining[:TrainingLen]\n",
    "    #print(str(TrainingPercent) + \"% Training Target Generated..\")\n",
    "    return t\n",
    "\n",
    "def GenerateTrainingDataMatrix(rawData, TrainingPercent = 80):\n",
    "    T_len = int(math.ceil(len(rawData[0])*0.01*TrainingPercent))\n",
    "    d2 = rawData[:,0:T_len]\n",
    "    #print(str(TrainingPercent) + \"% Training Data Generated..\")\n",
    "    return d2\n",
    "\n",
    "def GenerateValData(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData[0])*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    dataMatrix = rawData[:,TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Data Generated..\")  \n",
    "    return dataMatrix\n",
    "\n",
    "def GenerateValTargetVector(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData)*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    t =rawData[TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Target Data Generated..\")\n",
    "    return t\n",
    "#Big sigma contains variance at the diagonal elements\n",
    "#Big sigma contains variance at the diagonal elements\n",
    "def GenerateBigSigma(Data, MuMatrix,TrainingPercent,IsSynthetic):\n",
    "    print(len(Data)) #rows 41#\n",
    "    print(len(Data[0])) #columns 69k\n",
    "    print(Data.shape)\n",
    "    BigSigma    = np.zeros((len(Data),len(Data)))\n",
    "    DataT       = np.transpose(Data)\n",
    "    print(len(DataT[0]))#column\n",
    "    print(DataT.shape)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))        \n",
    "    varVect     = []\n",
    "    for i in range(0,len(DataT[0])):#all columns of one feature\n",
    "        vct = []\n",
    "        for j in range(0,int(TrainingLen)):\n",
    "            vct.append(Data[i][j])    \n",
    "        varVect.append(np.var(vct))# variance of each feature vector as diagonal\n",
    "    \n",
    "    for j in range(len(Data)):\n",
    "        BigSigma[j][j] = varVect[j]\n",
    "    if IsSynthetic == True:\n",
    "        BigSigma = np.dot(3,BigSigma)\n",
    "    else:\n",
    "        BigSigma = np.dot(200,BigSigma)\n",
    "    ##print (\"BigSigma Generated..\")\n",
    "    return BigSigma\n",
    "\n",
    "def GetScalar(DataRow,MuRow, BigSigInv):#computing exponent function of gaussian basis function\n",
    "    R = np.subtract(DataRow,MuRow)\n",
    "    T = np.dot(BigSigInv,np.transpose(R))  \n",
    "    L = np.dot(R,T)\n",
    "    return L\n",
    "\n",
    "def GetRadialBasisOut(DataRow,MuRow, BigSigInv):    # compute phi matrix\n",
    "    phi_x = math.exp(-0.5*GetScalar(DataRow,MuRow,BigSigInv))\n",
    "    return phi_x\n",
    "\n",
    "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 80):\n",
    "    DataT = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
    "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
    "    BigSigInv = np.linalg.inv(BigSigma)\n",
    "    for  C in range(0,len(MuMatrix)):\n",
    "        for R in range(0,int(TrainingLen)):\n",
    "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
    "    #print (\"PHI Generated..\")\n",
    "    return PHI\n",
    "#Computation of closed form solution to obtain weights\n",
    "def GetWeightsClosedForm(PHI, T, Lambda):\n",
    "    Lambda_I = np.identity(len(PHI[0]))\n",
    "    for i in range(0,len(PHI[0])):\n",
    "        Lambda_I[i][i] = Lambda\n",
    "    PHI_T       = np.transpose(PHI)\n",
    "    PHI_SQR     = np.dot(PHI_T,PHI)\n",
    "    PHI_SQR_LI  = np.add(Lambda_I,PHI_SQR)\n",
    "    PHI_SQR_INV = np.linalg.inv(PHI_SQR_LI)\n",
    "    INTER       = np.dot(PHI_SQR_INV, PHI_T)\n",
    "    W           = np.dot(INTER, T)\n",
    "    ##print (\"Training Weights Generated..\")\n",
    "    return W\n",
    "\n",
    "\n",
    "#For obtaining validation erms , testing erms and training erms\n",
    "def GetValTest(VAL_PHI,W):\n",
    "    Y = np.dot(W,np.transpose(VAL_PHI))\n",
    "    ##print (\"Test Out Generated..\")\n",
    "    return Y\n",
    "#get erms by subtracting actual value - obtained value and then squaring it \n",
    "#and then summing all of them.\n",
    "def GetErms(VAL_TEST_OUT,ValDataAct):\n",
    "    sum = 0.0\n",
    "    t=0\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    val = 0.0\n",
    "    for i in range (0,len(VAL_TEST_OUT)):\n",
    "        sum = sum + math.pow((ValDataAct[i] - VAL_TEST_OUT[i]),2)\n",
    "        if(int(np.around(VAL_TEST_OUT[i], 0)) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(VAL_TEST_OUT)))\n",
    "    ##print (\"Accuracy Generated..\")\n",
    "    ##print (\"Validation E_RMS : \" + str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "    return (str(accuracy) + ',' +  str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: 'U' mode is deprecated\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114451,)\n",
      "(1017, 114451)\n",
      "(14306,)\n",
      "(1017, 14306)\n",
      "(14306,)\n",
      "(1017, 14306)\n",
      "1017\n",
      "143063\n",
      "(1017, 143063)\n",
      "1017\n",
      "(143063, 1017)\n"
     ]
    }
   ],
   "source": [
    "RawTarget = GetTargetVector('finalGSC.csv',1024)\n",
    "RawData   = GenerateRawData('finalGSC.csv',IsSynthetic,1024)\n",
    "\n",
    "TrainingTarget = np.array(GenerateTrainingTarget(RawTarget,TrainingPercent))\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)\n",
    "print(TrainingTarget.shape)\n",
    "print(TrainingData.shape)\n",
    "\n",
    "ValDataAct = np.array(GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget))))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "TestDataAct = np.array(GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct))))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "\n",
    "ErmsArr = []\n",
    "AccuracyArr = []\n",
    "#In order to get different Mu specify value of M in K- Means\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(np.transpose(TrainingData))\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "BigSigma     = GenerateBigSigma(RawData, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(RawData, Mu, BigSigma, TrainingPercent)\n",
    "W            = GetWeightsClosedForm(TRAINING_PHI,TrainingTarget,(C_Lambda)) \n",
    "\n",
    "TEST_PHI     = GetPhiMatrix(TestData, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(ValData, Mu, BigSigma, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "W_Now        = np.zeros(20) #Randomly intiliaze weight at the beguning\n",
    "print(W_Now)\n",
    "La           = 2\n",
    "learningRate = 0.01 #determines the step size for updating weights\n",
    "L_Erms_Val   = []\n",
    "L_Erms_TR    = []\n",
    "L_Erms_Test  = []\n",
    "W_Mat        = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #process of updation of wts acc to stochastic gradient descent solution\n",
    "    #print ('---------Iteration: ' + str(i) + '--------------')\n",
    "    Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),TRAINING_PHI[i])),TRAINING_PHI[i])\n",
    "    La_Delta_E_W  = np.dot(La,W_Now)\n",
    "    Delta_E       = np.add(Delta_E_D,La_Delta_E_W)    \n",
    "    Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "    W_T_Next      = W_Now + Delta_W\n",
    "    W_Now         = W_T_Next\n",
    "    \n",
    "    #-----------------TrainingData Accuracy---------------------#\n",
    "    TR_TEST_OUT   = GetValTest(TRAINING_PHI,W_T_Next) \n",
    "    Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "    L_Erms_TR.append(float(Erms_TR.split(',')[1]))\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "    VAL_TEST_OUT  = GetValTest(VAL_PHI,W_T_Next) \n",
    "    Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "    L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "    TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "    Erms_Test = GetErms(TEST_OUT,TestDataAct)\n",
    "    L_Erms_Test.append(float(Erms_Test.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Gradient Descent Solution--------------------\n",
      "M = 15 \n",
      "Lambda  = 0.0001\n",
      "eta=0.003\n",
      "E_rms Training   = 0.66896\n",
      "E_rms Validation = 0.6738\n",
      "E_rms Testing    = 0.67101\n"
     ]
    }
   ],
   "source": [
    "print ('----------Gradient Descent Solution--------------------')\n",
    "print (\"M = 15 \\nLambda  = 0.0001\\neta=0.003\")\n",
    "print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on GSC Dataset using Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: 'U' mode is deprecated\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114451,)\n",
      "(1024, 114451)\n",
      "(14306,)\n",
      "(1024, 14306)\n",
      "(14306,)\n",
      "(1024, 14306)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1024,) and (114451,) not aligned: 1024 (dim 0) != 114451 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-02033f4cd0f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m114451\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mwnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwnew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#wnext = wnew - eta*(a-y)*xi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1024,) and (114451,) not aligned: 1024 (dim 0) != 114451 (dim 0)"
     ]
    }
   ],
   "source": [
    "RawTarget = GetTargetVector('finalGSC.csv',1024)\n",
    "RawData   = GenerateRawData('finalGSC.csv',True,1024)\n",
    "\n",
    "TrainingTarget = np.array(GenerateTrainingTarget(RawTarget,TrainingPercent))\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)\n",
    "print(TrainingTarget.shape)\n",
    "print(TrainingData.shape)\n",
    "\n",
    "ValDataAct = np.array(GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget))))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "TestDataAct = np.array(GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct))))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = np.transpose(TrainingData)\n",
    "wnew = np.zeros(1024)\n",
    "b =0 \n",
    "for i in range(114451):\n",
    "    wnew = np.transpose(wnew)\n",
    "    z = np.dot(wnew,TrainingData[i]) + b\n",
    "    a = 1.0/(1.0+ math.exp(-z))\n",
    "    #wnext = wnew - eta*(a-y)*xi\n",
    "    wnext = wnew - np.dot(learningRate*(a-TrainingTarget[i]),TrainingData[i])\n",
    "    wnew = wnext\n",
    "    \n",
    "    b = b - learningRate*(a - TrainingTarget[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training = 58.114826432272324\n",
      "Accuracy Validation = 58.143436320424996\n",
      "Accuracy Testing = 57.659232328882055\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "def GetValTestLog(VAL_PHI,W):\n",
    "    for i in range(114451):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test.append(a) \n",
    "    return test\n",
    "TR_TEST_OUT   = GetValTestLog(TrainingData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "L_Erms_Val.append(float(Erms_Val.split(',')[0]))\n",
    "#print (\"Accuracy Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print(\"Accuracy Training = \" + str(float(Erms_TR.split(',')[0])))\n",
    "\n",
    "\n",
    "test = []\n",
    "ValData = np.transpose(ValData)\n",
    "def GetValTestLog(VAL_PHI,W):\n",
    "    for i in range(14306):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test.append(a) \n",
    "    return test\n",
    "TR_TEST_OUT   = GetValTestLog(ValData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,ValDataAct)\n",
    "L_Erms_Val.append(float(Erms_Val.split(',')[0]))\n",
    "#print (\"Accuracy Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print(\"Accuracy Validation = \" + str(float(Erms_TR.split(',')[0])))\n",
    "\n",
    "test1 = []\n",
    "TestData = np.transpose(TestData)\n",
    "def GetTestLog(VAL_PHI,W):\n",
    "    for i in range(14303):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test1.append(a) \n",
    "    return test1\n",
    "TR_TEST_OUT   = GetTestLog(TestData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,TestDataAct)\n",
    "L_Erms_Test.append(float(Erms_Test.split(',')[0]))\n",
    "#print (\"accuracy Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "print(\"Accuracy Testing = \" + str(float(Erms_TR.split(',')[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on GSC Dataset with subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: 'U' mode is deprecated\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'U' mode is deprecated\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114451,)\n",
      "(508, 114451)\n",
      "(14306,)\n",
      "(508, 14306)\n",
      "(14306,)\n",
      "(508, 14306)\n",
      "508\n",
      "143063\n",
      "(508, 143063)\n",
      "508\n",
      "(143063, 508)\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "RawTarget = GetTargetVector('finalGSCsub.csv',512)\n",
    "RawData   = GenerateRawData('finalGSCsub.csv',IsSynthetic,512)\n",
    "\n",
    "TrainingTarget = np.array(GenerateTrainingTarget(RawTarget,TrainingPercent))\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)\n",
    "print(TrainingTarget.shape)\n",
    "print(TrainingData.shape)\n",
    "\n",
    "ValDataAct = np.array(GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget))))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "TestDataAct = np.array(GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct))))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "\n",
    "ErmsArr = []\n",
    "AccuracyArr = []\n",
    "#In order to get different Mu specify value of M in K- Means\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(np.transpose(TrainingData))\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "BigSigma     = GenerateBigSigma(RawData, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(RawData, Mu, BigSigma, TrainingPercent)\n",
    "W            = GetWeightsClosedForm(TRAINING_PHI,TrainingTarget,(C_Lambda)) \n",
    "\n",
    "TEST_PHI     = GetPhiMatrix(TestData, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(ValData, Mu, BigSigma, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "W_Now        = np.zeros(10) #Randomly intiliaze weight at the beguning\n",
    "\n",
    "La           = 2\n",
    "learningRate = 0.01 #determines the step size for updating weights\n",
    "L_Erms_Val   = []\n",
    "L_Erms_TR    = []\n",
    "L_Erms_Test  = []\n",
    "W_Mat        = []\n",
    "\n",
    "for i in range(0,400):\n",
    "    #process of updation of wts acc to stochastic gradient descent solution\n",
    "    #print ('---------Iteration: ' + str(i) + '--------------')\n",
    "    Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),TRAINING_PHI[i])),TRAINING_PHI[i])\n",
    "    La_Delta_E_W  = np.dot(La,W_Now)\n",
    "    Delta_E       = np.add(Delta_E_D,La_Delta_E_W)    \n",
    "    Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "    W_T_Next      = W_Now + Delta_W\n",
    "    W_Now         = W_T_Next\n",
    "    \n",
    "    #-----------------TrainingData Accuracy---------------------#\n",
    "    TR_TEST_OUT   = GetValTest(TRAINING_PHI,W_T_Next) \n",
    "    Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "    L_Erms_TR.append(float(Erms_TR.split(',')[1]))\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "    VAL_TEST_OUT  = GetValTest(VAL_PHI,W_T_Next) \n",
    "    Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "    L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "    TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "    Erms_Test = GetErms(TEST_OUT,TestDataAct)\n",
    "    L_Erms_Test.append(float(Erms_Test.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Gradient Descent Solution--------------------\n",
      "M = 10 \n",
      "Lambda  = 0.0001\n",
      "eta=0.003\n",
      "E_rms Training   = 0.57937\n",
      "E_rms Validation = 0.57979\n",
      "E_rms Testing    = 0.58309\n"
     ]
    }
   ],
   "source": [
    "print ('----------Gradient Descent Solution--------------------')\n",
    "print (\"M = 10 \\nLambda  = 0.0001\\neta=0.003\")\n",
    "print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression On GSC Dataset with subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: 'U' mode is deprecated\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114451,)\n",
      "(512, 114451)\n",
      "(14306,)\n",
      "(512, 14306)\n",
      "(14306,)\n",
      "(512, 14306)\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "RawTarget = GetTargetVector('finalGSCsub.csv',512)\n",
    "RawData   = GenerateRawData('finalGSCsub.csv',True,512)\n",
    "\n",
    "TrainingTarget = np.array(GenerateTrainingTarget(RawTarget,TrainingPercent))\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)\n",
    "print(TrainingTarget.shape)\n",
    "print(TrainingData.shape)\n",
    "\n",
    "ValDataAct = np.array(GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget))))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "TestDataAct = np.array(GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct))))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = np.transpose(TrainingData)\n",
    "wnew = np.zeros(512)\n",
    "b =0 \n",
    "for i in range(114451):\n",
    "    wnew = np.transpose(wnew)\n",
    "    z = np.dot(wnew,TrainingData[i]) + b\n",
    "    a = 1.0/(1.0+ math.exp(-z))\n",
    "    #wnext = wnew - eta*(a-y)*xi\n",
    "    wnext = wnew - np.dot(learningRate*(a-TrainingTarget[i]),TrainingData[i])\n",
    "    wnew = wnext\n",
    "    \n",
    "    b = b - learningRate*(a - TrainingTarget[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training =50.069462040523895\n",
      "Accuracy Validation =50.07689081504264\n",
      "Accuracy Testing =49.36726560861358\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "def GetValTestLog(VAL_PHI,W):\n",
    "    for i in range(114451):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test.append(a) \n",
    "    return test\n",
    "TR_TEST_OUT   = GetValTestLog(TrainingData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "L_Erms_Val.append(float(Erms_Val.split(',')[0]))\n",
    "#print (\"accuracy Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print(\"Accuracy Training =\" + str(float(Erms_TR.split(',')[0])))\n",
    "test = []\n",
    "ValData = np.transpose(ValData)\n",
    "def GetValTestLog(VAL_PHI,W):\n",
    "    for i in range(14306):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test.append(a) \n",
    "    return test\n",
    "TR_TEST_OUT   = GetValTestLog(ValData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,ValDataAct)\n",
    "#L_Erms_Val.append(float(Erms_Val.split(',')[0]))\n",
    "#print (\"accuracy Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print(\"Accuracy Validation =\" + str(float(Erms_TR.split(',')[0])))\n",
    "\n",
    "\n",
    "\n",
    "test1 = []\n",
    "TestData = np.transpose(TestData)\n",
    "def GetTestLog(VAL_PHI,W):\n",
    "    for i in range(14303):\n",
    "        \n",
    "        Y = np.dot(W,VAL_PHI[i])\n",
    "        a = 1.0/(1.0+ math.exp(-Y))\n",
    "        test1.append(a) \n",
    "    return test1\n",
    "TR_TEST_OUT   = GetTestLog(TestData,wnew) \n",
    "\n",
    "Erms_TR       = GetErms(TR_TEST_OUT,TestDataAct)\n",
    "#L_Erms_Test.append(float(Erms_Test.split(',')[0]))\n",
    "#print (\"accuracy Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "print(\"Accuracy Testing =\" + str(float(Erms_TR.split(',')[0])))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "#VAL_TEST_OUT  = GetValTest(ValData,wnew) \n",
    "#Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "#print(Erms_Val)\n",
    "#L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "#TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "#Erms_Test = GetErms(TEST_OUT,TestDataAct)\n",
    "#L_Erms_Test.append(float(Erms_Test.split(',')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Implementation on GSC dataset using concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def processData(dataset):\n",
    "    \n",
    "    # Why do we have to process?  We do not needvindexes, we only need values.\n",
    "    #We are converting the dataset back to array \n",
    "    #for further processing them to binary form\n",
    "    data   = dataset.iloc[:133063,0:1024]\n",
    "    labels = dataset.iloc[:133063,1024]\n",
    "    #to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "    #processedData  = encodeData(data)\n",
    "    #processedLabel = encodeLabel(labels)\n",
    "    print (data)\n",
    "    print(labels)\n",
    "    return data, labels\n",
    "\n",
    "def testData(dataset): \n",
    "    data = dataset.iloc[133063:,0:1024] \n",
    "    labels = dataset.iloc[133063:,1024]\n",
    "#to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "#processedData  = encodeData(data)\n",
    "#processedLabel = encodeLabel(labels)\n",
    "#print (data)\n",
    "#print(labels)\n",
    "    return data, labels\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "input_size = 1024\n",
    "drop_out = 0.2\n",
    "first_dense_layer_nodes  = 512\n",
    "second_dense_layer = 512\n",
    "second_dense_layer_nodes = 1\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    # Why do we need a model? A model is a core data  srtucture in keras and used to organize layers.\n",
    "    # Why use Dense layer and then activation? We need to tell the system how the model is by specifying input and dense layer size,\n",
    "    #after specifying we apply activation.\n",
    "    # Why use sequential model with layers? sequential model is a linear way of stacking layers, \n",
    "    #where a layer connects just to the next layer. Here we have a fixed souce of input and output.\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    #relu always gives value such that if x<0 it will give 0 otherwise it will give the number itself\n",
    "    #activation function are used to map input to output\n",
    "    \n",
    "    # Why dropout? WE used dropout to avoid overfitting of model\n",
    "    #model.add(Dropout(drop_out))\n",
    "    #model.add(Dense(second_dense_layer))\n",
    "    #model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    # Why Softmax?\n",
    "    # softmax is an activation function used when we are doing classification \n",
    "    #and softmax will give probabilities of various classes involved\n",
    "    model.summary()\n",
    "    \n",
    "    # Why use categorical_crossentropy? We use categorial cross entropy when the target is in categorical format\n",
    "    # Here we are distribuiting the number in 4 categories, thus using categorical crossentropy\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # optimizer allows the internal learnable parameter (weights)to get adjusted.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 525,313\n",
      "Trainable params: 525,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...    1.290  0.725  \\\n",
      "0       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "2       1    0    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "3       0    1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "4       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "5       1    1    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "6       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "7       1    1    1    0    0    0    0    1    1    0  ...        0      0   \n",
      "8       0    0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "9       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "10      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "11      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "12      0    0    1    0    0    0    0    0    1    0  ...        0      0   \n",
      "13      1    1    1    0    0    0    1    1    0    0  ...        0      0   \n",
      "14      1    0    0    0    1    0    1    0    0    0  ...        0      0   \n",
      "15      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "16      0    0    1    0    0    0    0    0    0    0  ...        1      0   \n",
      "17      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "18      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "19      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "20      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "21      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "22      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "23      0    1    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "24      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "25      1    1    1    0    1    0    0    1    1    0  ...        0      0   \n",
      "26      1    1    1    0    0    0    1    1    1    0  ...        0      0   \n",
      "27      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "28      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "29      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "...    ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...    ...   \n",
      "143032  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143033  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143034  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143035  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143036  0    0    0    0    1    0    0    0    0    0  ...        0      0   \n",
      "143037  0    1    1    0    0    0    1    1    1    0  ...        0      0   \n",
      "143038  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143039  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143040  0    0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "143041  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143042  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143043  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143044  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143045  0    1    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "143046  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143047  0    1    1    1    0    0    0    1    0    1  ...        0      0   \n",
      "143048  1    1    1    0    0    1    1    1    1    0  ...        0      0   \n",
      "143049  0    0    0    0    0    0    0    0    0    0  ...        1      0   \n",
      "143050  0    0    0    0    1    0    0    0    0    0  ...        0      1   \n",
      "143051  0    0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "143052  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143053  1    1    0    0    1    0    1    0    0    0  ...        0      0   \n",
      "143054  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143055  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143056  0    1    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "143057  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143058  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143059  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143060  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143061  0    1    0    0    0    0    0    0    0    0  ...        1      0   \n",
      "\n",
      "        0.726  0.727  0.728  0.729  0.730  0.731  0.732  1.291  \n",
      "0           0      0      0      0      0      0      0      1  \n",
      "1           0      0      0      0      0      0      0      0  \n",
      "2           0      0      0      0      0      0      0      0  \n",
      "3           0      0      0      0      0      0      0      0  \n",
      "4           0      0      0      0      0      0      0      0  \n",
      "5           0      0      0      0      0      0      0      0  \n",
      "6           0      0      0      0      0      0      0      1  \n",
      "7           0      0      0      0      0      0      0      1  \n",
      "8           0      0      0      0      0      0      0      1  \n",
      "9           0      0      0      0      0      0      0      0  \n",
      "10          0      0      0      0      0      0      0      1  \n",
      "11          0      0      0      0      0      0      0      0  \n",
      "12          0      0      0      0      0      0      0      1  \n",
      "13          0      0      0      0      0      0      0      1  \n",
      "14          0      0      0      0      0      0      0      1  \n",
      "15          0      0      0      0      0      0      0      0  \n",
      "16          0      0      0      0      0      0      0      1  \n",
      "17          0      0      0      0      0      0      0      1  \n",
      "18          0      0      0      0      0      0      0      0  \n",
      "19          0      0      0      0      1      0      0      1  \n",
      "20          0      0      0      0      0      0      0      0  \n",
      "21          0      0      0      0      0      0      0      0  \n",
      "22          0      0      0      0      0      0      0      0  \n",
      "23          0      0      0      0      0      0      0      1  \n",
      "24          0      0      0      0      0      0      0      0  \n",
      "25          0      0      0      0      0      0      0      1  \n",
      "26          0      0      0      0      0      0      0      1  \n",
      "27          0      0      0      0      0      0      0      1  \n",
      "28          0      1      0      0      0      1      0      1  \n",
      "29          0      0      0      0      0      0      0      1  \n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "143032      0      0      0      0      0      0      0      1  \n",
      "143033      0      0      0      0      0      0      0      0  \n",
      "143034      0      0      0      0      0      0      0      0  \n",
      "143035      0      0      0      0      0      0      0      1  \n",
      "143036      0      0      0      0      0      0      0      1  \n",
      "143037      0      0      0      0      0      0      0      1  \n",
      "143038      0      0      0      0      0      0      0      0  \n",
      "143039      0      0      0      0      0      0      0      0  \n",
      "143040      0      0      0      0      0      0      0      1  \n",
      "143041      0      0      0      0      0      0      0      1  \n",
      "143042      0      0      0      0      0      0      0      1  \n",
      "143043      0      0      0      0      0      0      0      0  \n",
      "143044      0      0      0      0      0      0      0      1  \n",
      "143045      0      0      0      0      0      0      0      1  \n",
      "143046      0      0      0      0      0      0      0      0  \n",
      "143047      0      0      0      0      0      0      0      0  \n",
      "143048      0      0      0      0      0      0      0      1  \n",
      "143049      0      0      1      0      0      0      0      0  \n",
      "143050      0      0      0      0      0      0      0      1  \n",
      "143051      0      0      0      0      0      0      0      1  \n",
      "143052      0      0      0      0      0      0      0      1  \n",
      "143053      0      0      0      0      0      0      0      1  \n",
      "143054      0      0      0      0      0      0      0      1  \n",
      "143055      0      0      0      0      0      0      0      0  \n",
      "143056      0      0      0      0      0      0      0      0  \n",
      "143057      0      0      0      0      0      0      0      0  \n",
      "143058      0      0      0      0      0      0      0      0  \n",
      "143059      0      0      0      0      0      0      0      1  \n",
      "143060      0      0      0      0      0      0      0      1  \n",
      "143061      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[143062 rows x 1025 columns]\n",
      "        0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...    1.289  1.290  \\\n",
      "0       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "2       1    0    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "3       0    1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "4       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "5       1    1    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "6       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "7       1    1    1    0    0    0    0    1    1    0  ...        0      0   \n",
      "8       0    0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "9       0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "10      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "11      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "12      0    0    1    0    0    0    0    0    1    0  ...        0      0   \n",
      "13      1    1    1    0    0    0    1    1    0    0  ...        0      0   \n",
      "14      1    0    0    0    1    0    1    0    0    0  ...        0      0   \n",
      "15      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "16      0    0    1    0    0    0    0    0    0    0  ...        0      1   \n",
      "17      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "18      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "19      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "20      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "21      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "22      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "23      0    1    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "24      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "25      1    1    1    0    1    0    0    1    1    0  ...        0      0   \n",
      "26      1    1    1    0    0    0    1    1    1    0  ...        0      0   \n",
      "27      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "28      0    0    0    0    0    0    0    0    0    0  ...        1      0   \n",
      "29      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "...    ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...    ...   \n",
      "133033  0    1    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "133034  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133035  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133036  1    0    1    1    0    0    0    0    0    1  ...        0      0   \n",
      "133037  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133038  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133039  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133040  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133041  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133042  0    0    0    0    0    0    0    0    0    0  ...        0      1   \n",
      "133043  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133044  0    0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "133045  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133046  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133047  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133048  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133049  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133050  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133051  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133052  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133053  0    0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "133054  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133055  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133056  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133057  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133058  1    1    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "133059  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133060  0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133061  1    1    0    0    0    0    1    0    0    0  ...        0      0   \n",
      "133062  0    1    1    0    0    0    0    1    1    0  ...        0      0   \n",
      "\n",
      "        0.725  0.726  0.727  0.728  0.729  0.730  0.731  0.732  \n",
      "0           0      0      0      0      0      0      0      0  \n",
      "1           0      0      0      0      0      0      0      0  \n",
      "2           0      0      0      0      0      0      0      0  \n",
      "3           0      0      0      0      0      0      0      0  \n",
      "4           0      0      0      0      0      0      0      0  \n",
      "5           0      0      0      0      0      0      0      0  \n",
      "6           0      0      0      0      0      0      0      0  \n",
      "7           0      0      0      0      0      0      0      0  \n",
      "8           0      0      0      0      0      0      0      0  \n",
      "9           0      0      0      0      0      0      0      0  \n",
      "10          0      0      0      0      0      0      0      0  \n",
      "11          0      0      0      0      0      0      0      0  \n",
      "12          0      0      0      0      0      0      0      0  \n",
      "13          0      0      0      0      0      0      0      0  \n",
      "14          0      0      0      0      0      0      0      0  \n",
      "15          0      0      0      0      0      0      0      0  \n",
      "16          0      0      0      0      0      0      0      0  \n",
      "17          0      0      0      0      0      0      0      0  \n",
      "18          0      0      0      0      0      0      0      0  \n",
      "19          0      0      0      0      0      1      0      0  \n",
      "20          0      0      0      0      0      0      0      0  \n",
      "21          0      0      0      0      0      0      0      0  \n",
      "22          0      0      0      0      0      0      0      0  \n",
      "23          0      0      0      0      0      0      0      0  \n",
      "24          0      0      0      0      0      0      0      0  \n",
      "25          0      0      0      0      0      0      0      0  \n",
      "26          0      0      0      0      0      0      0      0  \n",
      "27          0      0      0      0      0      0      0      0  \n",
      "28          0      0      1      0      0      0      1      0  \n",
      "29          0      0      0      0      0      0      0      0  \n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "133033      0      0      0      0      0      0      0      0  \n",
      "133034      0      0      0      0      0      0      0      0  \n",
      "133035      0      0      0      0      0      0      0      0  \n",
      "133036      0      0      0      0      0      0      0      0  \n",
      "133037      0      0      0      0      0      0      0      0  \n",
      "133038      0      0      0      0      0      0      0      0  \n",
      "133039      0      0      0      0      0      0      0      0  \n",
      "133040      0      0      0      0      0      0      0      0  \n",
      "133041      0      1      0      0      0      0      0      0  \n",
      "133042      0      0      0      1      0      0      0      0  \n",
      "133043      0      0      0      0      0      0      0      0  \n",
      "133044      0      0      0      0      0      0      0      0  \n",
      "133045      0      0      0      0      0      0      0      0  \n",
      "133046      0      0      0      0      0      0      0      0  \n",
      "133047      0      0      0      0      0      0      0      0  \n",
      "133048      0      0      0      0      0      0      0      0  \n",
      "133049      0      0      0      0      0      0      0      0  \n",
      "133050      0      0      0      0      0      0      0      0  \n",
      "133051      0      0      0      0      0      0      0      0  \n",
      "133052      0      0      0      0      0      0      0      0  \n",
      "133053      0      0      0      0      0      0      0      0  \n",
      "133054      0      0      0      0      0      0      0      0  \n",
      "133055      0      0      0      0      0      0      0      0  \n",
      "133056      0      0      0      0      0      0      0      0  \n",
      "133057      0      0      0      0      0      0      0      0  \n",
      "133058      0      0      0      0      0      0      0      0  \n",
      "133059      0      0      0      0      0      0      0      0  \n",
      "133060      0      0      0      0      0      0      0      0  \n",
      "133061      0      0      0      0      0      0      0      0  \n",
      "133062      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[133063 rows x 1024 columns]\n",
      "0         1\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "5         0\n",
      "6         1\n",
      "7         1\n",
      "8         1\n",
      "9         0\n",
      "10        1\n",
      "11        0\n",
      "12        1\n",
      "13        1\n",
      "14        1\n",
      "15        0\n",
      "16        1\n",
      "17        1\n",
      "18        0\n",
      "19        1\n",
      "20        0\n",
      "21        0\n",
      "22        0\n",
      "23        1\n",
      "24        0\n",
      "25        1\n",
      "26        1\n",
      "27        1\n",
      "28        1\n",
      "29        1\n",
      "         ..\n",
      "133033    1\n",
      "133034    0\n",
      "133035    0\n",
      "133036    1\n",
      "133037    0\n",
      "133038    0\n",
      "133039    0\n",
      "133040    0\n",
      "133041    1\n",
      "133042    0\n",
      "133043    0\n",
      "133044    1\n",
      "133045    0\n",
      "133046    0\n",
      "133047    0\n",
      "133048    0\n",
      "133049    0\n",
      "133050    1\n",
      "133051    1\n",
      "133052    0\n",
      "133053    0\n",
      "133054    1\n",
      "133055    1\n",
      "133056    0\n",
      "133057    0\n",
      "133058    1\n",
      "133059    1\n",
      "133060    1\n",
      "133061    0\n",
      "133062    1\n",
      "Name: 1.291, Length: 133063, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 106450 samples, validate on 26613 samples\n",
      "Epoch 1/12\n",
      "106450/106450 [==============================] - 13s 127us/step - loss: 0.4828 - acc: 0.7625 - val_loss: 0.3699 - val_acc: 0.8417\n",
      "Epoch 2/12\n",
      "106450/106450 [==============================] - 13s 120us/step - loss: 0.3014 - acc: 0.8704 - val_loss: 0.2551 - val_acc: 0.8984\n",
      "Epoch 3/12\n",
      "106450/106450 [==============================] - 12s 116us/step - loss: 0.2115 - acc: 0.9132 - val_loss: 0.2071 - val_acc: 0.9173\n",
      "Epoch 4/12\n",
      "106450/106450 [==============================] - 13s 123us/step - loss: 0.1556 - acc: 0.9383 - val_loss: 0.2242 - val_acc: 0.9038\n",
      "Epoch 5/12\n",
      "106450/106450 [==============================] - 13s 125us/step - loss: 0.1161 - acc: 0.9549 - val_loss: 0.1854 - val_acc: 0.9280\n",
      "Epoch 6/12\n",
      "106450/106450 [==============================] - 13s 120us/step - loss: 0.0897 - acc: 0.9660 - val_loss: 0.2457 - val_acc: 0.9152\n",
      "Epoch 7/12\n",
      "106450/106450 [==============================] - 13s 122us/step - loss: 0.0671 - acc: 0.9749 - val_loss: 0.2064 - val_acc: 0.9306\n",
      "Epoch 8/12\n",
      "106450/106450 [==============================] - 13s 122us/step - loss: 0.0530 - acc: 0.9807 - val_loss: 0.2368 - val_acc: 0.9256\n",
      "Epoch 9/12\n",
      "106450/106450 [==============================] - 13s 124us/step - loss: 0.0412 - acc: 0.9854 - val_loss: 0.2134 - val_acc: 0.9330\n",
      "Epoch 10/12\n",
      "106450/106450 [==============================] - 13s 121us/step - loss: 0.0336 - acc: 0.9884 - val_loss: 0.2315 - val_acc: 0.9362\n",
      "Epoch 11/12\n",
      "106450/106450 [==============================] - 13s 126us/step - loss: 0.0258 - acc: 0.9917 - val_loss: 0.2436 - val_acc: 0.9344\n",
      "Epoch 12/12\n",
      "106450/106450 [==============================] - 13s 120us/step - loss: 0.0204 - acc: 0.9934 - val_loss: 0.2435 - val_acc: 0.9369\n"
     ]
    }
   ],
   "source": [
    "validation_data_split = 0.2\n",
    "num_epochs = 12\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 20\n",
    "early_patience = 100\n",
    "#tensorboard is used for visualization\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "#earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "#Early stopping happens when the quantity monitored stops increasing or decreasing\n",
    "# Read Dataset\n",
    "dataset = pd.read_csv('finalGSC.csv')\n",
    "print(dataset)\n",
    "# Process Dataset\n",
    "processedData, processedLabel = processData(dataset)\n",
    "history = model.fit(processedData\n",
    "                    , processedLabel\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb]\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest = pd.read_csv('finalGSC.csv')\n",
    "datatest1,datalabel = testData(datatest)\n",
    "#np.set_printoptions(precision=4, suppress=True)\n",
    "k,l = datatest1.shape\n",
    "print(k)\n",
    "eval_results = model.predict(datatest1)\n",
    "#print(\"\\nLoss, accuracy on test data: \")\n",
    "#print(\"%0.4f %0.2f%%\" % (eval_results[0], \\\n",
    " #eval_results[1]*100))\n",
    "\n",
    "for i in range(k):\n",
    "    if(eval_results[i]>0.5):\n",
    "        eval_results[i] = 1\n",
    "    else:\n",
    "        eval_results[i] = 0\n",
    "        \n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.35\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(k):\n",
    "    if (eval_results[i] == datalabel[133063+i]):\n",
    "        correct = correct +1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "        \n",
    "print (correct/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1c3bd80438>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c3b40a080>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c3b41aa90>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c36fdb6a0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAMGCAYAAADIvDGrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl8VPW9//HXN5NMJjshgQAJEFaVVSWAXhWDK65Ytx9arbZVuqjttba31lr1ahert7u2lba22qq4W1DUVmuktVgBBWQRZSesIWGb7Ml8f3+cgQwxgSEzOSeTvJ+Px3nknDPfmfOZ7/Xqu9/vme8x1lpEREREpHMleV2AiIiISE+g0CUiIiLiAoUuERERERcodImIiIi4QKFLRERExAUKXSIiIiIuUOgSERERcYFCl4iIiIgLFLpEREREXJB8pAbGmEeBC4Gd1toxbbxugF8A5wM1wPXW2vfDr10H3Blu+n1r7WNHul5+fr4tLi6O+gt0VHV1NRkZGZ1+HXGov92l/naf+txd6m93qb/bt3jx4l3W2j7RtD1i6AL+BDwEPN7O6+cBI8LbZOA3wGRjTG/gbqAEsMBiY8wca+3uw12suLiYRYsWRVN7TMrKyigtLe3064hD/e0u9bf71OfuUn+7S/3dPmPMxmjbHnF60Vo7H6g6TJPpwOPW8S7QyxjTHzgX+Lu1tioctP4OTIu2MBEREZHuJB73dBUCmyOOy8Pn2jsvIiIi0uNEM714JKaNc/Yw5z/9AcbMBGYCFBQUUFZWFoeyDi8YDLpyHXGov92l/naf+txd6m93qb/jIx6hqxwYGHFcBGwNny9tdb6srQ+w1s4CZgGUlJTY1vPGjY2NlJeXU1dXF4dyHTk5OQQCgbh93tEKBAIUFRWRkpLiWQ1u0v0A7lJ/u0997i71t7vU3/ERj9A1B7jZGDMb50b6vdbabcaY14EfGmNyw+3OAb7TkQuUl5eTlZVFcXExzo8lY7d//36ysrLi8llHy1pLZWUl5eXlDBkyxJMaREREuqPmkKWxOURjc4iQhZy0rjO4Ec2SEU/hjFjlG2PKcX6RmAJgrf0tMA9nuYg1OEtGfD78WpUx5j5gYfij7rXWHu6G/HbV1dXFNXB5zRhDXl4eFRUVXpciIiJyWM0hS32TZW9NI40hJ8w0NlkamkM0hVr2G5tDNDU7gSfy+MB+Y1OIxmbrfEZTSzBqbG7Zb4j4DOfY0hSx39gUvmazpaEpfI2Qc74hImgdMKJvJn//xunedV4rRwxd1tqrjvC6BW5q57VHgUc7VtqhukvgOqC7fR8REfFWKGSpaWympr6JmoZmqhvCf+ubqG1oprqhmZrwuZr6pvCxc666vpnaRufvwTbh99Y3hZwLvPG3uNabZCDFl4Tfl0RKchLJScY5Tk4ixWdITnLO+33O+TR/y36KL4lkn3Hee2BLNqQktez7fUn0zvDHteZYxWN6UURERKIUCllqG51QVNvQ3CrohINPY0Qwqm865Lj2QKCqb6am0flb3dBEXWMo6hqMgfQUH+mpyaT7faT7k8nw+8gKJNMvO0B6qo90v48MfzJpfh9bN23gmJEjDoaeZJ8TjPytA1By+DjJhMOT0+5gMIrY9yX1vMEHhS4REZEIDU0hahudcNPyt4naBud8TUMTdeHzNY3N1IXb1YT/1h3Yb4jYD593RpSaj6qeg6Eo1Udaio+M1GQyU5Ppm5VKhj85HJCSDwlJGRHnDrw3PcVpm+FPJpCSdFQzLmVlWyk9Vfcgx0qhS0REEoa1lpqGZvbUh9hUWUNNY1OrcHT4v61DUl1jxH74fFOozdWN2mUMpKU4gSjNf+jf3Aw/hbk+AuHXDwlQ4dGlg6Ho4IhTS3AKJPtI6oEjQt2VQtdRuOSSS9i8eTN1dXV8/etfZ+bMmbz22mvccccdNDc3k5+fz5tvvkkwGOSWW25h0aJFGGO4++67ueyyy7wuX0SkS6hvamZfbRP76hrZW9vIvtpG9tU1tezXNrKvrpF9teFzdc65veF2zQdC0VtvRXW91OQk0vw+0lN8BPwt4Scr4IwWpfsPhKRk0vxJ4dCUHP6bFD7f8r5A+O+BcJWafHSjRtJzJVzo+t+5K1i5dV/Mn9Pc3IzP5wNg1IBs7r5o9BHf8+ijj9K7d29qa2uZOHEi06dP58Ybb2T+/PkMGTKEqirnx5n33XcfOTk5fPjhhwDs3n3Yx02KiCSU5pAlWHdoaNp7hKAU2eZI9x75fUlkp6WQk5ZMdloKuel+ivMyyE5LJjuQQnZaCls3rmPc6OMOhp+DQajVSFMgxdcj7x2SrinhQpeXfvnLX/Liiy8CsHnzZmbNmsWUKVMOrrXVu3dvAN544w1mz5598H25ubmf/jAREQ/VNzWzu7olCO2tiQxKTa1CU/hceD9Y34Q9zAxckoHstJRwQEomJy2FvlmZZAdSyElPITvgnGtpEw5Y4f1Aiu+I9ZeVbaZ0QlEce0Sk8yVc6IpmRCoaR7s4allZGW+88QYLFiwgPT2d0tJSxo8fz+rVqz/V1lqroWYRcU0oZNlb20hVTQNV1c62u7qByvDfA+cP7gcbqG44/M3cGX5fOAw5waiwV4Dj+mdFhKRPh6cDgSrDn6z7kETakHChyyt79+4lNzeX9PR0PvroI959913q6+t5++23Wb9+/cHpxd69e3POOefw0EMP8fOf/xxwphc12iUi0appaAqHpEYqq+vZXdNAVXUjVdX1VFU3OuEpHKB2Vzewu6aB9u79Tvf7yE330zvDT26Gn6F9MsPHKeRm+OmV5j84GnUgUGUHkkn2Jbn7pUV6AIWuKE2bNo3f/va3jBs3jmOOOYaTTjqJPn36MGvWLC699FJCoRB9+/bl73//O3feeSc33XQTY8aMwefzcffdd3PppZd6/RVExANNzSF21zSGg1MbI1GtRqeqahravefJl2RaAlO6n5EFmQcD1YEt8jg33U+a/8hTdSLiDoWuKKWmpvLqq6+2+dp55513yHFmZiaPPfaYG2WJiAestVQE69myu5Yte2rZtqeOD1Y3MG/XUmckKiJI7a1tbPdzslKT6Z3phKOC7ADH9c8+GJbywiNTvTNS6J2RSu90P1kBTduJJDKFLhGRVpqaQ2zfV8eW3bWUh4PVgYB1YGtoOnQ0KtlAXmWFE5AyUhg9IDsiOIW3dOc4L8NPr3Q//mRN4Yn0JApdItLj1DU2HxqkWv3dvq+uZS2osPzMVApz0xjVP5uzRxVQ2CvN2XLTGNArjfff/RdTp0716BuJSCJImNDV3X4RaA/3e2sRicne2saIIFXTMkIVPrcr2HBIe1+SoV92gMLcNCYP6U1hbkugKuzlhKojLWPQnf79JCKdIyFCVyAQoLKykry8vG7xLzZrLZWVlQQCAa9LEUk41lp2BRsiQlTNwTB1YCpwf13TIe9JTU46GKKO6599SKAqzE2jX3ZAv9YTkU6XEKGrqKiI8vJyKioq4vaZdXV1noaeQCBAUZEW9hNpLfJ+qk/dSxXer291P1VWavLBENUyUpV+8Fx+pr9b/A82EUlsCRG6UlJSDq76Hi9lZWWccMIJcf1MEYlOc8iydU8tayuCrN9VzbqKatbvcra276fyU9grjWP7Z3HmcX3DI1TpB0eqctJSPPomIiLRS4jQJSKJaXd1A+t2BVlXUc26XdWsr6hm3a4gGyprDvn1X1ZqMkP7ZFBSnEtReJSqKLdlCjCax8KIiHR1Cl0iEpO6xmY2VtawfleQteERq3XhEazdNS1rVCUnGQblpTM0P5PSY/oyND+DIfkZDO2Tqek/EekRFLpE5IhCIcu2fXUHR6oOjFytqwiyZU/tIQ8/7puVytA+GZw3tj9D8zMY2ieDIfmZDMxN083qItKjKXSJyEF7axsPGalaV1HN2oogGyqrD3k0TYbfx5A+GZw4KJfLTixiaJ8MhuZnMqRPBpmp+teKiEhb9G9HkR6moSnEpqoa1lUED7nPav2u6kPWr/IlGQbmpjG0TyanDs9nSDhYDe2TQd+sVE0HiogcJYUukW7IWsuOfXWsrQge/GXggdGrzbtrD/l1YH5mKkPzMzjruIKD91gNyc9gUO90PaZGRCSOogpdxphpwC8AH/B7a+39rV4fDDwK9AGqgGusteXh15qBD8NNN1lrL45T7SISVlXdwPsbd7N4024Wb9zNsk011L3+5sHXAylJDMnPZHRhDheNH3DwPqsh+RlabkFExCVHDF3GGB/wMHA2UA4sNMbMsdaujGj2f8Dj1trHjDFnAD8Crg2/VmutPT7OdYv0WKGQZU1FkMUbnYD1/sbdrNtVDUCKzzBqQA6nFCZTesIxB0et+mUHSErSdKCIiJeiGemaBKyx1q4DMMbMBqYDkaFrFHBreP8t4KV4FinSkwXrm1i6eU9LyNq0++BjbvIy/Jw4OJcrJw5kwuBcxhbmEEjxUVZWRunJxd4WLiIih4gmdBUCmyOOy4HJrdosBS7DmYL8DJBljMmz1lYCAWPMIqAJuN9aq0Am0g5rLeW7aw8GrMUbd/PR9n2ELBgDxxRkcdH4AUwYlMuEwbkMzkvXDe0iIgnCWGsP38CYK4BzrbU3hI+vBSZZa2+JaDMAeAgYAszHCWCjrbV7jTEDrLVbjTFDgX8AZ1pr17a6xkxgJkBBQcGE2bNnx+0LticYDJKZmdnp1xGH+rttjSHLxr0hPtkTYs2eZtbsCbG33vn/yYAPhvVKYngvHyNykxia4yM9JbqApf52n/rcXepvd6m/2zd16tTF1tqSaNpGM9JVDgyMOC4CtkY2sNZuBS4FMMZkApdZa/dGvIa1dp0xpgw4AVjb6v2zgFkAJSUltrS0NJraY1JWVoYb1xGH+tuxc38d72/cw/vhG94/LN9LQ7Oz/tWg3umcMSqXEwfnUjI4l5EFWfg6eB+W+tt96nN3qb/dpf6Oj2hC10JghDFmCLAFmAFcHdnAGJMPVFlrQ8B3cH7JiDEmF6ix1taH25wCPBDH+kW6rOaQZfX2/Sze5NzsvnjjbjZV1QDg9yUxtiiH608p5sRBuZw4uBd9swIeVywiIp3piKHLWttkjLkZeB1nyYhHrbUrjDH3AoustXOAUuBHxhiLM714U/jtxwGPGGNCQBLOPV0rP3URkW5gb20jH4QD1vub9vDBpt1UNzQD0CcrlQmDcrn2pMGcODiXMYXZpCbrIc4iIj1JVOt0WWvnAfNanbsrYv854Lk23vdvYGyMNYp0OdZa1u+qPvhrwsUbd/PJziDWQpKBY/tlc+mJRUwY7NzwXpSbphveRUR6OK1ILxKF2oZmlpXvOThV+P6mPVRVO4/MyQokc+KgXC4cN4AJg3MZP7CXnj8oIiKfov8yiLShsTnEO2t28fbHFby/cTcrtu6jKfzonKH5GZxxbN+Do1jD+2Rq4VERETkihS6RsOaQ5T/rK5m7dBuvLd/G7ppGUpOTGD+wFzdOGcqEQc4vC3tn+L0uVUREEpBCl/RooZDl/U27eXnZNl75cBsV++tJ9/s467gCLhzXnykj+xBI0Q3vIiISO4Uu6XGstXy4ZS9zl27llWXb2Lq3Dn9yEmcc05eLxg/gjGP7kuZX0BIRkfhS6JIewVrL6h37mbt0Ky8v28bGyhpSfIbTRvThW9OO4azjCsgKpHhdpoiIdGMKXdKtra0I8vLSbcxdtpU1O4MkGThleD5fLR3GuaP70Std92eJiIg7FLqk29lcVcPLy7Yxd+lWVm7bhzEwsbg3910yhvPG9CM/M9XrEkVEpAdS6JJuYfveOl5e5kwdLtm8B4DjB/biexeO4oKx/emXo0fsiIiItxS6JGHtCtbz6ofbmLtsGws3VGEtjB6QzbenHcuF4/ozsHe61yWKiIgcpNAlCWVPTQOvr9jO3KXb+PfaXYQsDO+byX+fOZILx/dnWJ9Mr0sUERFpk0KXdHn76xp5Y9UO5i7dxj8/qaCx2TI4L52vlg7nwvH9OaYgS881FBGRLk+hS7qk2oZm3vxoBy8v3cY/Vu+koSnEgJwAnz9lCBeNG8CYwmwFLRERSSgKXdJl1Dc18/bqCuYu28abq3ZQ09BMn6xUrp40iIvG9+eEgbl6xqGIiCQshS7x1IEHS89duo2/rdzO/romctNTuOSEQi4c15/JQ/LwKWiJiEg3oNAlrmvrwdJZqcmcO6YfF47rzynD80nxJXldpoiISFwpdIkrQtayaENVmw+Wvmj8AKaMzCc1Wc87FBGR7kuhSzpVXWMzf/jXev7wdi1Vry/Qg6VFRKTHUuiSTmGt5fUV2/n+K6so313LmHwf35s+Rg+WFhGRHkuhS+Lu4x37+d+5K3hnTSXHFGTx5I2Tadi8nNITirwuTURExDMKXRI3e2sa+dkbH/PndzeSmZrMvdNHc/WkQST7kijb7HV1IiIi3lLokpg1hyxPL9zMg69/xN7aRq6ePIjbzj6G3Ay/16WJiIh0GQpdEpOFG6q4Z84KVmzdx6QhvbnnotGMGpDtdVkiIiJdTlSLIRljphljVhtj1hhjbm/j9cHGmDeNMcuMMWXGmKKI164zxnwS3q6LZ/HinW17a/naUx9wxW8XsLu6gYeuPoGnZ56kwCUiItKOI450GWN8wMPA2UA5sNAYM8dauzKi2f8Bj1trHzPGnAH8CLjWGNMbuBsoASywOPze3fH+IuKOusZmfv/PdTz81lqareVrZ47gK6cP09IPIiIiRxDN9OIkYI21dh2AMWY2MB2IDF2jgFvD+28BL4X3zwX+bq2tCr/378A04KnYSxc3WWv528odfP+VlWyuquW8Mf244/zjGNg73evSREREEkI0oasQiPztWTkwuVWbpcBlwC+AzwBZxpi8dt5b2PoCxpiZwEyAgoICysrKoiy/44LBoCvX6Q62BEM8uaqeFZUhCjMN/zMxwKi8/axd9h5ro/wM9be71N/uU5+7S/3tLvV3fEQTutp62rBtdfxN4CFjzPXAfGAL0BTle7HWzgJmAZSUlNjS0tIoyopNWVkZblwnke2tbeQXb3zCYws2kOH3cc9Fx3LNSYNJ7sBzEdXf7lJ/u0997i71t7vU3/ERTegqBwZGHBcBWyMbWGu3ApcCGGMygcustXuNMeVAaav3lsVQr7igOWR5dtFmHnx9NVU1DVw1aRC3nT2SvMxUr0sTERFJWNGEroXACGPMEJwRrBnA1ZENjDH5QJW1NgR8B3g0/NLrwA+NMbnh43PCr0sXtWhDFffMXcHyLfuYWJzLYxdNYkxhjtdliYiIJLwjhi5rbZMx5macAOUDHrXWrjDG3AssstbOwRnN+pExxuJML94Ufm+VMeY+nOAGcO+Bm+qla9m+t477X13FS0u20i87wC9mHM/F4wdgTFszxCIiInK0oloc1Vo7D5jX6txdEfvPAc+1895HaRn5ki6mvqmZ3/9zPQ+/tYamkOXmqcP56tRhpPu1bq6IiEg86b+sPZS1ljdW7eT7r6xkY2UN544u4Lvnj2JQnpaAEBER6QwKXT3Qmp1B7n15JfM/rmBE30z+8sXJnDoi3+uyREREujWFrh5kX10jv3zjE/707w2k+X3cdeEorj15MCkdWAJCREREjo5CVw8QClmeW1zOA69/RGV1AzMmDuSb5xyjJSBERERcpNDVzS3euJv/nbuCZeV7mTA4lz9eP4mxRVoCQkRExG0KXd3Uzn113P/aR7zw/hYKslO1BISIiIjHFLq6mfqmZh791wYe+scnNDZbvlo6jJumDicjVf+nFhER8ZL+S9yN/OOjHdw7dyUbKms467gCvnfhcQzOy/C6LBEREUGhq1tYWxHkvpdXUra6gmF9Mnj8C5OYMrKP12WJiIhIBIWuBLa/rpFf/WMNf3xnPYFkH3decBzX/VexloAQERHpghS6ElAoZHn+/XJ+/NpqKqvruXLCQL417RjytQSEiIhIl6XQlWCWbN7D3XNWsHTzHk4c1ItHry9hXFEvr8sSERGRI1DoSiA/nLeKWfPX0TcrlZ9eOZ5Lji8kKUlLQIiIiCQCha4E8eqH25g1fx0zJg7kzgtHkaklIERERBKK/sudAHYF6/nuS8sZW5jDfZeM0Y3yIiIiCUj/9e7irLXc8cKHBOub+MmV4xW4REREEpT+C97FvbRkC39buYNvnjOSkQVZXpcjIiIiHaTQ1YVt21vLXX9dwcTiXL546lCvyxEREZEYKHR1UdZavv38hzQ1W/7vivH49CtFERGRhKbQ1UU99d5m5n9cwR0X6PmJIiIi3YFCVxe0qbKG77+yktNG5HPN5EFelyMiIiJxoNDVxYRClm8+txSfMfz4snEYo2lFERGR7iCq0GWMmWaMWW2MWWOMub2N1wcZY94yxnxgjFlmjDk/fL7YGFNrjFkS3n4b7y/Q3Tz6znreW1/F3RePZkCvNK/LERERkTg54uKoxhgf8DBwNlAOLDTGzLHWroxodifwjLX2N8aYUcA8oDj82lpr7fHxLbt7WrNzPw+8vpqzjivgshMLvS5HRERE4iiaka5JwBpr7TprbQMwG5jeqo0FssP7OcDW+JXYMzQ1h7jtmaVk+H388NIxmlYUERHpZqIJXYXA5ojj8vC5SPcA1xhjynFGuW6JeG1IeNrxbWPMabEU25399u21LC3fy/cvGUvfrIDX5YiIiEicGWvt4RsYcwVwrrX2hvDxtcAka+0tEW2+Ef6snxhjTgb+AIwBUoBMa22lMWYC8BIw2lq7r9U1ZgIzAQoKCibMnj07bl+wPcFgkMzMzE6/TjQ27mvm3gV1lBT4+Mrx3TNwdaX+7gnU3+5Tn7tL/e0u9Xf7pk6duthaWxJN22geeF0ODIw4LuLT04dfBKYBWGsXGGMCQL61didQHz6/2BizFhgJLIp8s7V2FjALoKSkxJaWlkZTe0zKyspw4zpHUt/UzP0PvUPvTMtvb5xCbobf65I6RVfp755C/e0+9bm71N/uUn/HRzTTiwuBEcaYIcYYPzADmNOqzSbgTABjzHFAAKgwxvQJ34iPMWYoMAJYF6/iu4NfvvkJH23fz/2Xju22gUtERESiGOmy1jYZY24GXgd8wKPW2hXGmHuBRdbaOcBtwO+MMbfi3FR/vbXWGmOmAPcaY5qAZuDL1tqqTvs2CeaDTbv5Tdlariwp4szjCrwuR0RERDpRNNOLWGvn4dwgH3nuroj9lcApbbzveeD5GGvslmobmrntmaX0z0njexeO8rocERER6WRRhS6JvwdfX826XdU8ccNksgIpXpcjIiIinUyPAfLAgrWVPPrOeq47eTCnDM/3uhwRERFxgUKXy4L1TXzruaUU56Xz7fOO9bocERERcYmmF132g1dWsXVPLc9++WTS/ep+ERGRnkIjXS4qW72Tp97bxMwpw5gwuLfX5YiIiIiLFLpcsremkW8/v4yRBZncevYIr8sRERERl2l+yyX3zF1BZbCBP1w3kdRkn9fliIiIiMs00uWC15Zv48UPtnDLGSMYU5jjdTkiIiLiAYWuTrYrWM8dLy5nbGEOX506zOtyRERExCMKXZ3IWssdL3xIsL6Jn1w5nhSfultERKSnUgroRC8t2cLfVu7gm+eMZGRBltfliIiIiIcUujrJtr213PXXFZQMzuWLpw71uhwRERHxmEJXJ7DW8u3nP6Sp2fJ/V4zHl2S8LklEREQ8ptDVCZ56bzPzP67gjvOPpTg/w+tyREREpAtQ6IqzTZU1fP+VlZw6PJ/PTh7sdTkiIiLSRSh0xVEoZPnmc0vxGcOPLx9HkqYVRUREJEyhK47++O8NvLe+irsuGkVhrzSvyxEREZEuRKErTtbsDPLAax9x1nF9uXxCkdfliIiISBej0BUHTc0hbnt2KWl+Hz+8dCzGaFpRREREDqUHXsfBI/PXsXTzHh66+gT6ZgW8LkdERES6II10xWjl1n38/I2PuXBcfy4cN8DrckRERKSLUuiKQUNTiG88s4Re6X7umz7G63JERESkC4sqdBljphljVhtj1hhjbm/j9UHGmLeMMR8YY5YZY86PeO074fetNsacG8/ivfbLNz/ho+37uf/SseRm+L0uR0RERLqwI97TZYzxAQ8DZwPlwEJjzBxr7cqIZncCz1hrf2OMGQXMA4rD+zOA0cAA4A1jzEhrbXO8v4jbPti0m1+XreHKkiLOPK7A63JERESki4tmpGsSsMZau85a2wDMBqa3amOB7PB+DrA1vD8dmG2trbfWrgfWhD8vodU2NHPbM0vpn5PG9y4c5XU5IiIikgCiCV2FwOaI4/LwuUj3ANcYY8pxRrluOYr3JpwHX1/Nul3VPHD5OLICKV6XIyIiIgkgmiUj2lp0yrY6vgr4k7X2J8aYk4E/G2PGRPlejDEzgZkABQUFlJWVRVFWbILBYIeus6qymUcX1nHmoGQay5dTVh7/2rqjjva3dIz6233qc3epv92l/o6PaEJXOTAw4riIlunDA74ITAOw1i4wxgSA/Cjfi7V2FjALoKSkxJaWlkZZfseVlZVxtNcJ1jdx58/nU5yXzq9uOI10v5Y5i1ZH+ls6Tv3tPvW5u9Tf7lJ/x0c004sLgRHGmCHGGD/OjfFzWrXZBJwJYIw5DggAFeF2M4wxqcaYIcAI4L14Fe+2H7yyiq17avnJleMVuEREROSoHDE5WGubjDE3A68DPuBRa+0KY8y9wCJr7RzgNuB3xphbcaYPr7fWWmCFMeYZYCXQBNyUqL9cLFu9k6fe28SXTh/KhMG9vS5HREREEkxUwzXW2nk4N8hHnrsrYn8lcEo77/0B8IMYavTc3ppGvv38MkYWZHLrWSO9LkdEREQSkObIonDP3BVUBhv4/ecmEkjxeV2OiIiIJCA9BugIXlu+jRc/2MLNZwxnbFGO1+WIiIhIglLoOoxdwXq+++JyxhRmc9PU4V6XIyIiIglM04vtsNZy54vL2V/XxFNXHk+KT/lUREREOk5Joh1/XbKV11Zs57ZzRjKyIMvrckRERCTBKXS1YfveOu7663ImDM7lhtOGel2OiIiIdAMKXa1Ya/n288tobLb85Irx+JLaepKRiIiIyNFR6Gpl9sLNvP1xBXecfyzF+RlelyMiIiLdhEJXhM1VNXz/5ZWcOjyfz04e7HU5IiKx4qthAAAgAElEQVQi0o0odIWFQpZvPruUJGP48eXjSNK0ooiIiMSRQlfYH/+9gf+sr+Kui0ZR2CvN63JERESkm1HoAtbsDPLAax9x1nF9uXxCkdfliIiISDfU40NXU3OI255dSprfxw8vHYsxmlYUERGR+OvxK9I/Mn8dSzfv4aGrT6BvVsDrckRERKSb6tEjXSu37uPnb3zMheP6c+G4AV6XIyIiIt1Yjw1dTSHLN55ZQk6an/umj/G6HBEREenmeuz04l/XNPLR9hp+/7kScjP8XpcjIiIi3VyPHOn6YNNuXl7XyBUTijhrVIHX5YiIiEgP0ONCV11jM7c9u5TcgOF7F43yuhwRERHpIXrc9GKSMVwwtj+BfeVkB1K8LkdERER6iB430uVPTuK2c45hdL7P61JERESkB+lxoUtERETECwpdIiIiIi5Q6BIRERFxgUKXiIiIiAsUukRERERcYKy1XtdwCGNMBbDRhUsNAja5cB1xqL/dpf52n/rcXepvd6m/2zfYWtsnmoZdLnS5xRhTEW0nSezU3+5Sf7tPfe4u9be71N/x0ZOnF/d4XUAPo/52l/rbfepzd6m/3aX+joOeHLr2el1AD6P+dpf6233qc3epv92l/o6Dnhy6ZnldQA+j/naX+tt96nN3qb/dpf6Ogx57T5eIiIiIm3rySJeIiIiIaxS6RERERFyg0CUiIiLiAoUuERERERcodImIiIi4QKFLRERExAUKXSIiIiIuUOgSERERcYFCl4iIiIgLFLpEREREXKDQJSIiIuIChS4RERERFyh0iYiIiLhAoUtERETEBQpdIiIiIi5Q6BIRERFxgUKXiIiIiAsUukRERERcoNAlIiIi4gKFLhEREREXKHSJiIiIuEChS0RERMQFCl0iIiIiLlDoEhEREXFBTKHLGDPNGLPaGLPGGHN7G69fb4ypMMYsCW83xHI9ERERkUSV3NE3GmN8wMPA2UA5sNAYM8dau7JV06ettTfHUKOIiIhIwutw6AImAWustesAjDGzgelA69B1VPLz821xcXEsHxGV6upqMjIyOv064lB/u0v97T71ubvU3+5Sf7dv8eLFu6y1faJpG0voKgQ2RxyXA5PbaHeZMWYK8DFwq7V2cxttDiouLmbRokUxlBWdsrIySktLO/064lB/u0v97T71ubvU3+5Sf7fPGLMx6rbW2o5e5ArgXGvtDeHja4FJ1tpbItrkAUFrbb0x5svAldbaM9r4rJnATICCgoIJs2fP7lBNRyMYDJKZmdnp1xGH+ttd6m/3qc/dpf52l/q7fVOnTl1srS2Jpm0sI13lwMCI4yJga2QDa21lxOHvgB+39UHW2lnALICSkhLrRppWaneX+ttd6m/3qc/dpf52l/o7PmL59eJCYIQxZogxxg/MAOZENjDG9I84vBhYFcP1RERERBJWh0e6rLVNxpibgdcBH/CotXaFMeZeYJG1dg7wNWPMxUATUAVcH4eaRUREpItqbGykvLycuro6r0uJq0AgQFFRESkpKR3+jFimF7HWzgPmtTp3V8T+d4DvxHKNuLMW3v01mftTgVKvqxEREelWysvLycrKori4GGOM1+XEhbWWyspKysvLGTJkSIc/p+etSF+3Fxb8mjHLfwTBCq+rERER6Vbq6urIy8vrNoELwBhDXl5ezKN3PS90pfWCGU+Q0rgPnvkcNDV4XZGIiEi30p0C1wHx+E49L3QBDDie1cfcApv+Da992+tqREREJI666vIWMd3Tlch2FkxhVG4j/PuX0G8clHze65JERESkG+uZI10HnHUPDD8L5n0LNi7wuhoRERGJI2st3/rWtxgzZgxjx47l6aefBmDbtm1MmTKF448/njFjxvDPf/6T5uZmrr/++oNtf/azn8W9nh470gVAkg8u+z387gx45lqYWQY5RV5XJSIiInHwwgsvsGTJEpYuXcquXbuYOHEiU6ZM4cknn+Tcc8/lu9/9Ls3NzdTU1LBkyRK2bNnC8uXLAdizZ0/c6+nZoQsgLRdmPAW/PxNmfxa+8BqkpHldlYiISOJ79XbY/mF8P7PfWDjv/qia/utf/+Kqq67C5/NRUFDA6aefzsKFC5k4cSJf+MIXaGxs5JJLLuH4449n6NChrFu3jltuuYULLriAc845J75109OnFw/oeyxc+jvYtgTmft1Zy0tEREQSWnvPl54yZQrz58+nsLCQa6+9lscff5zc3FyWLl1KaWkpDz/8MDfccEPc69FI1wHHng9Tvwtv/cBJ0f91y5HfIyIiIu2LckSqs0yZMoVHHnmE6667jqqqKubPn8+DDz7Ixo0bKSws5MYbb6S6upr333+f888/H7/fz2WXXcawYcO4/vrr416PQlek077pDIP+/S7oOwqGn+l1RSIiItJBn/nMZ1iwYAHjx4/HGMMDDzxAv379eOyxx3jwwQdJSUkhMzOTxx9/nC1btvD5z3+eUCgEwI9+9KO416PQFSkpCS75DfxhLTz3BbjxH5A3zOuqRERE5CgEg0HAWdD0wQcf5MEHHzzk9euuu47rrrvuU+97//33O7Uu3dPVWmomzHgCjIHZV0P9fq8rEhERkW5AoastvYfAFX+CXZ/Ai1+G8FCjiIiISEcpdLVnaCmc83346GWY/4DX1YiIiEiCU+g6nJO+AuOvhrIfwaqXva5GREQkIbS3VEMii8d3Uug6HGPgwp/BgBPhxS/BzlVeVyQiItKlBQIBKisru1XwstZSWVlJIBCI6XP068UjSQk4N9bPKoWnrnJ+0Zje2+uqREREuqSioiLKy8upqKjwupS4CgQCFBXF9qhAha5oZA+AK/8Mf7rAWUris8+BT10nIiLSWkpKCkOGDPG6jC5J04vRGjQZLvwprHsL3rjb62pEREQkwWi45mic+DnYtgwWPAT9x8O4K72uSERERBKERrqO1rQfweBTYc4tsKVzV64VERGR7kOh62j5UuDKxyCjDzx9DQR3el2RiIiIJACFro7IyIcZT0JNFTx9LTQ1eF2RiIiIdHExhS5jzDRjzGpjzBpjzO2HaXe5McYaY0piuV6X0n8cXPIwbH4XXv0fr6sRERGRLq7DocsY4wMeBs4DRgFXGWNGtdEuC/ga8J+OXqvLGnMZnHorLP4jLPyD19WIiIhIFxbLSNckYI21dp21tgGYDUxvo919wANAXQzX6rrO+B4MP9sZ7dr4b6+rERERkS7KdHSZfmPM5cA0a+0N4eNrgcnW2psj2pwA3GmtvcwYUwZ801q7qI3PmgnMBCgoKJgwe/bsDtV0NILBIJmZmXH5rOTGICe+/y2Sm6pZPOEn1Af6xOVzu5N49rccmfrbfepzd6m/3aX+bt/UqVMXW2ujun0qlnW6TBvnDiY4Y0wS8DPg+iN9kLV2FjALoKSkxJaWlsZQVnTKysqI63WOHwm/P5OTN/4KPv8a+NPj99ndQNz7Ww5L/e0+9bm71N/uUn/HRyzTi+XAwIjjImBrxHEWMAYoM8ZsAE4C5nSrm+kj9RkJl/7OWTx17tegGz3oU0RERGIXS+haCIwwxgwxxviBGcCcAy9aa/daa/OttcXW2mLgXeDitqYXu41jpsEZ34UPn4V//8rrakRERKQL6XDostY2ATcDrwOrgGestSuMMfcaYy6OV4EJ57RvwqhLnOczrnnD62pERESki4jp2YvW2nnAvFbn7mqnbWks10oYxsAlv4bKNfDcF+DGtyBvmNdViYiIiMe0In1n8GfAjCfA+GD21VC/3+uKRERExGMKXZ0ltxiu+BPs+gRe+BKEQl5XJCIiIh5S6OpMQ0+Hc38Iq1+Bt+/3uhoRERHxUEz3dEkUJn8Jti+Dt38MBWNgVM/9jYGIiEhPppGuzmYMXPBTKCyBF78MO1Z4XZGIiIh4QKHLDSkB+H9/gdQs58b6miqvKxIRERGXKXS5Jbu/E7z2bYXnPg/NTV5XJCIiIi5S6HLTwIlw4c9gXZmzeKqIiIj0GLqR3m0nXOM8n3HBQ86N9cdf5XVFIiIi4gKNdHnh3B9A8Wkw9+uwZbHX1YiIiIgLFLq84EuBKx6DzAKYfQ3s3+F1RSIiItLJFLq8kpEHVz0JdXvgmWuhqd7rikRERKQTKXR5qd9YmP4wbP4PzPsWWOt1RSIiItJJdCO918ZcCjuWwz9/Av3HwcQbvK5IREREOoFGurqCqXfCiHPh1W/Dhne8rkZEREQ6gUJXV5CUBJf9DnKHwDOfgz2bva5IRERE4kyhq6sI5MBVT0Fzg/OooIYarysSERGROFLo6kryR8Blf4DtH8KcW3RjvYiISDei0NXVjDwHzrwLlj8H7/zC62pEREQkThS6uqJTb4XRl8Ib98Anb3hdjYiIiMSBQldXZAxMDz+b8bkvwK41XlckIiIiMVLo6qr8GTDjCfAlOzfW1+3zuiIRERGJQUyhyxgzzRiz2hizxhhzexuvf9kY86ExZokx5l/GmFGxXK/HyR3sPKOxcg28MBNCIa8rEhERkQ7qcOgyxviAh4HzgFHAVW2EqiettWOttccDDwA/7XClPdWQ02Da/fDxq1D2I6+rERERkQ6KZaRrErDGWrvOWtsAzAamRzaw1kbOiWUAWgOhIybdCCdcC/MfgA/+oqUkREREElAsoasQiFw6vTx87hDGmJuMMWtxRrq+FsP1ei5j4IKfwOBT4a83wRNXQNV6r6sSERGRo2BsB0dNjDFXAOdaa28IH18LTLLW3tJO+6vD7a9r47WZwEyAgoKCCbNnz+5QTUcjGAySmZnZ6deJJxNqpnDLKxRveAJjQ2wadDmbBl2KTUrxurQjSsT+TmTqb/epz92l/naX+rt9U6dOXWytLYmmbSyh62TgHmvtueHj7wBYa9u88cgYkwTsttbmHO5zS0pK7KJFizpU09EoKyujtLS006/TKfZthde/CytegN7DnFGwYVO9ruqwErq/E5D6233qc3epv92l/m6fMSbq0BXL9OJCYIQxZogxxg/MAOa0KmRExOEFwCcxXE8OyB4AV/wRrnkBsPDnS+DZz8O+bV5XJiIiIu3ocOiy1jYBNwOvA6uAZ6y1K4wx9xpjLg43u9kYs8IYswT4BvCpqUWJwfAz4SsLoPQO+OgVeGgivPsbaG7yujIRERFpJTmWN1tr5wHzWp27K2L/67F8vkQhJQCl34axl8O8b8Frt8OSJ+HCn0FRVKOdIiIi4gKtSN9d5A2Da553FlOt3gW/Pwvmfh1qqryuTERERFDo6l6MgdGXwM3vwck3wft/hodK4IMntLaXiIiIxxS6uqPULDj3B/Cl+ZA3HP76Vfjj+bBjpdeViYiI9FgKXd1ZvzHw+dfg4oeg4iN45DT42/egPuh1ZSIiIj2OQld3l5QEJ14LNy+C8VfBv38JD0+GVXM15SgiIuIiha6eIiMPpj8EX/gbpPWCp6+BJ6/U44RERERcotDV0wyaDDPfhnN/CBv/Db8+Cd5+EJrqva5MRESkW1Po6ol8yc6vG29eCCOnwVvfh9/8F6wr87oyERGRbkuhqyfLHgBXPgaffR5CzfD4dHjui7B/u9eViYiIdDsKXQIjzoKvvgul33FusH9oIvznESeIiYiISFwodIkjJQClt8NXFziPD3r1f2BWKZQv9royERGRbkGhSw6VNwyueQGu+BNUV8Dvz4S5/w21u72uTEREJKEpdMmnGQOjPwM3vQcnfRXefxx+VeI8SFtre4mIiHSIQpe0L5AN034IX3obeg+Fl74Cf7oAdq7yujIREZGEo9AlR9ZvLHzhdbjol7BzJfz2VPj7XdBQ7XVlIiIiCUOhS6KTlAQTroObF8P4GfDOL+ChSbDqZU05ioiIREGhS45ORh5Mf9gZ+QrkwNOfhSf/H+ze4HVlIiIiXZpCl3TMoJOce73O+T5s+Bc8fBLM/z89TkhERKQdCl3Scb4U+K9bwo8TOgf+cR/85hRY97bXlYmIiHQ5Cl0Su5xCuPJx+OxzEGqExy+G52+A/Tu8rkxERKTLUOiS+BlxtvM4odO/DSv/Cg+VwH9m6XFCIiIiKHRJvKWkwdQ74CsLoPBEePVb8Lup5OxZoV85iohIjxZT6DLGTDPGrDbGrDHG3N7G698wxqw0xiwzxrxpjBkcy/UkgeQPh2tfgsv/CPt3cMKSO5wHaf/rZ7Bvm9fViYiIuK7DocsY4wMeBs4DRgFXGWNGtWr2AVBirR0HPAc80NHrSQIyBsZcCrcs5qNjboGMfHjjHvjZKHjiCmcKsqnB6ypFRERcEctI1yRgjbV2nbW2AZgNTI9sYK19y1pbEz58FyiK4XqSqFIz2d7/LPjCa87iqqf8N2z/EJ75HPzkGHj1dudYRESkG4sldBUCmyOOy8Pn2vNF4NUYrifdQf5wOOtuuHWF82vHIVNg0R+cRws9MsW58b6myusqRURE4s7YDt7cbIy5AjjXWntD+PhaYJK19pY22l4D3Aycbq391OqZxpiZwEyAgoKCCbNnz+5QTUcjGAySmZnZ6dcRx+H6O7lxHwU75tNv+5tkBdcRMsnsyp/Mtv5nsTt3PBify9UmPv3z7T71ubvU3+5Sf7dv6tSpi621JdG0TY7hOuXAwIjjImBr60bGmLOA79JO4AKw1s4CZgGUlJTY0tLSGMqKTllZGW5cRxxH7u+LnT/blpG05An6LnuavsvegexCGH8VHH815A1zo9RuQf98u0997i71t7vU3/ERy/TiQmCEMWaIMcYPzADmRDYwxpwAPAJcbK3dGcO1pKfoPw7O+zHcthqueAz6joJ//RR+dSL88Xz44AmoD3pdpYiIyFHrcOiy1jbhTBm+DqwCnrHWrjDG3GuMCQ9b8CCQCTxrjFlijJnTzseJHCo5FUZfAtc859z/deZdsH87/PWrzs33f70JNr2rtb9ERCRhxDK9iLV2HjCv1bm7IvbPiuXzRQDIHgCn3QanfsMJWkv+Aitegg/+AnnDnanH8Vc57URERLoorUgvicMYGHwyTH/YmX6c/mvILIA374WfjYa/XO6EsaY2bx0UERHxVEwjXSKeSc2EEz7rbJVrYcmTzvbsdZCWC+P+Hxz/WeceMRERkS5AI12S+PKGwZnfg1uXwzXPw9BSWPQoPHIa/PY0+M8jWvtLREQ8p5Eu6T6SfDD8LGerqYLlz8MHf4ZX/wf+dicccz6ccC0Mm+q0FRERcZFCl3RP6b1h0o3Otv1DZ6mJZU/DypcgawCMnwEnXKO1v0RExDWaXpTur99YOO9+5+b7Kx93jt/5ubP216PTnF9Bau0vERHpZBrpkp4j2Q+jpjvbvm2wbLYTuP56E8z7Hxj9GefG/EEnO7+UFBERiSOFLumZsvvDqbfCKf8Nm99z1v5a/oLzt/dQ55eP46+CnMM9w11ERCR6Cl3SsxkDgyY727T7YeUcZ/TrH/fBWz+A4tNg2BnOzfcFYyFJM/IiItIxCl0iB/gz4PirnK1qnbPu16qX4Y27nS09H4aeDkOnOstS9Bp4pE8UERE5SKFLpC29h8IZdzrbvm2w/m1Y+xase8tZigKcRxANneqMghWfCoEcb2sWEZEuTaFL5Eiy+ztLTIyf4Txge+cqWFfmBLAlT8LC34HxQeEEJ4ANLYWiieBL8bhwERHpShS6RI6GMVAwytlO/io0NUD5e04IW/sWzH8Q3v4x+DOd0a8DI2H5I/WLSBGRHk6hSyQWyX4nXBWf6kxF1u6G9f9sGQn7+DWnXdYAZwTswEhYZl/PShYREW8odInEU1oujLrY2QB2b3TC17oyJ4AtfdI533d0OIBNhcEnOzfxi4hIt6bQJdKZcgfDhOudLRSC7UvDN+SXwXu/gwUPgc8PAye3jIT1P17PhhQR6YYUukTckpQEA05wttO+AQ01sGmBMxK2tsxZG+wf90GgFwyZ0jIS1nuI15WLiEgcKHSJeMWfDsPPdDaAYMWhS1OsmuOczy12RsGGTnXCWHpvjwoWEZFYKHSJdBWZfWDs5c5mLVSuaQlgHz4Pi/8EGGekbGipMxI2cDIkp3pbt4iIREWhS6QrMgbyRzjb5JnQ3ARbFoenIt+Cd34B//opJKfB4P9qmYosGK2lKUREuiiFLpFE4EtueUZk6e1Qtw82vtMyEva3O512GX1h6On0ayiArTnQ51hISfO2dhERARS6RBJTIBuOOc/ZAPZuaVkbbF0Zx1ZXwOqHwCRB3ghnBKxgNBSMcf7mFGlETETEZQpdIt1BTiGc8FlnC4X4z2tPMXlwBuxY4WxbFsOKF1rap+a0BLF+Y5ww1vc4rRcmItKJYgpdxphpwC8AH/B7a+39rV6fAvwcGAfMsNY+F8v1RCQKSUnUphfC6FIYfUnL+bp9znMjdyxvCWNLZ8PC/eEGxlmeInJErGA09Cp2lrsQEZGYdDh0GWN8wMPA2UA5sNAYM8dauzKi2SbgeuCbsRQpInEQyG65L+yAUAj2bmoJYQcC2aqXAeu08WdC31GtpihHQSDHk68hIpKoYhnpmgSssdauAzDGzAamAwdDl7V2Q/i1UAzXEZHOkpTkrAOWWwzHXtByvqEGKla1hLHty2HFi7D4jy1tcgZ9eoqy91Ctpi8i0g5jre3YG425HJhmrb0hfHwtMNlae3Mbbf8EvNze9KIxZiYwE6CgoGDC7NmzO1TT0QgGg2RmZnb6dcSh/nZXp/S3taTWV5JRvYHM4AYyqjeSGdxAek05Bud/VzUn+anOGER1RjHBzGKqMwYTzCymKSU7vrV0Qfpn3F3qb3epv9s3derUxdbakmjaxjLS1dZPnzqU4Ky1s4BZACUlJba0tDSGsqJTVlaGG9cRh/rbXa72d1M9VKyGHcvx7VhB9o7lZG9fAtvfaGmTNeDTv6DMHwG+FHdqdIH+GXeX+ttd6u/4iCV0lQMDI46LgK2xlSMiCSc5FfqPc7ZIwZ2H3rS/Y7nzmKPmBuf1pBRnHbHIKcq+oyGzr5azEJFuKZbQtRAYYYwZAmwBZgBXx6UqEUl8mX0h8wwYdkbLueZG2PXJoTftr58PyyJuKUjNgfzhzvpiB1blzxvh3C+WEnD/e4iIxEmHQ5e1tskYczPwOs6SEY9aa1cYY+4FFllr5xhjJgIvArnARcaY/7XWjo5L5SKSeHwpzi8fC0YBV7Scr6lyAtjOlU4o2/UxbPjnoWHMJEGvQS1hLG845I909jMLNDomIl1eTOt0WWvnAfNanbsrYn8hzrSjiEj70nvDkNOcLVJ9EKrWhoPYJ1AZDmQb34HGmpZ2qdmQN8wJYXkjWkbK8obpMUgi0mVoRXoR6bpSM6H/eGeLFArB/q2twtgnsOEdWPZ0REMDvQZ+eqoyfwRk9dfomIi4SqFLRBJPUpLz/MicIhg29dDXGqqhcm1LEDsQyt5/FxqrW9r5M8NTlCNaRsfyR0LvYeBPd/f7iEiPoNAlIt2LP6PtX1NaC/u2fjqMbfoPfPjsoW1zBh56z9iBcJZdqNExEekwhS4R6RmMcR4MnlMIQ0sPfa2hpo17xz6BJU9AQ7ClXUpG+N6xEa2mLIe7+U1EJEEpdImI+NOh31hni2Qt7N92aBDb9QmUL4TlLxC5HvSpvgxYXuj8kjKzALL6hZfN6AdZBS3n03I1WibSQyl0iYi0xxjIHuBsQ08/9LXG2pZ7xyrXsuOjxRTmJENwB2xZBPt3QFPtpz/T528JYJkFhwayyKCW2bdbrdgvIgpdIiIdk5LmrKLfbwwAn4TKKIx8TIq1UL/PWZl//3YnjAV3hPd3QnA77F4PmxZAbVXb10jPawlgbY6chff9mRo9E0kACl0iIp3BGAjkOFv+iMO3bWqA6p3O6FhwhxPIDu6Ht12fOH9DjZ9+f0p6q5GzyKAWMYqWngdJvs75viJyRApdIiJeS/a3LIFxONZC7e5DR86CO8IBLTyCtmMlrC2D+r2ffr/xQUafQ0fOMvpAer4TyDLCfw/s+zM65euK9FQKXSIiicIYZ/X+9N7hRykdRkNNOJTtbAlk+7cfur9tKdRUQqip7c9ITgsHsHAQS88PB7PeEfsR5wO9nDXURKRNCl0iIt2RPx16D3G2w7EW6vY64aumEqp3hfd3hferWvYr1zqvRS6jEckkQVrvT4+YtRXYDryWnBr/7y7SRSl0iYj0ZMZAWi9nyxsW3Xsa61qCWU0lVEfu7wrvV0HFauc5mTVVRC6vcQh/lhPEMvIjwlheqynP/JY2qdn60YAkLIUuERE5OimBloVmoxFqhto9rUbQDuxXtuzv3wY7Vjj7TXVtf1ZSCqTnMTGUDJ+Ef7mZmtXyNzXz/7N35+FZlOf7/99X9pCESBIICEhAQfY1Ba1bFAWsrQjVyiKg1qJSQaj2o1a//tS22NZqFQEVbcsighSrpZVqWyWi1So7yL6oEBAISYAkEAjJ/fsjAUNM4IE8mclyvo4jhzPz3DNzzQWa05l5ZipZVsFnofoVKN7S3zgREaleIaElZ69iEoF2px/vHBQeOvms2YnpkrNp+RlbiYmKLrnUmb8PjubCkVw4klfxNzwrEhZdEsTKBrSI2NMsKxveYkvOvEXEllwm1Rk4OQ2FLhERqVnMSr45GREDjVpVOGRdejpNyj4XraxjR0rC15GDJaHsSF7pPw+Wmc47OagdX5b7NWSVWafwUGA1h4SVObNWJqhVtOxEeIv7Zv54eIuMK3kGnAJcnaTQJSIidUtYZMlPTGLVt1V0rCR8nVF4K50vOAAHdn4z7shBKr23rSwLqTiYRZSeWSt/Ju6kUFduXgGuRlHoEhERqUxo2DdfNKiq45dNjxwPZgfLhLS8CuZzvwl0BQfLBLjSZQEFuNCTL4OeFOICD3UhRQVQXKxHglSRQpeIiIgXyl42jUuu2racg6P5J4ewI7mnmC8T6o6fgSv7+WkC3OUAHwKhkSVnz47/hEWXm48qeUNCeOk/T5qvaHwl82FRdTLgKXSJiIjUNmalZ6RiS94uUBXFxaVn4M2zAtcAACAASURBVHJPvnxaJpRt3bCG81s2K3mJe2GZn2MFJesWFpQ8dLfsfOHhkmlXdHZ1hVUW1M4g2DVIgnb9qtafIFLoEhERqc9CQr4JcJXYcSid8yv74sLpFBWWCWnlQ9vx6eNhLYAxxwpK3qxwPNid+PwQuOKT9924vUKXiIiI1BOh4SU/UQ2rdz/OlQS8sqEtkPvePKTQJSIiIrWfWcnL48MiICre72oqVKW71MxsgJltNLMtZvZgBZ9HmtnrpZ9/amYpVdmfiIiISG111qHLzEKBKcC1QEdgqJmVf+39j4Ec59wFwB+A357t/kRERERqs6qc6eoNbHHObXPOHQXmAgPLjRkIzCidng/0NdNT2kRERKT+qUroag7sKDOfUbqswjHOuWPAASAIjwgWERERqV2qciN9RWesyn9NIJAxmNloYDRAcnIy6enpVSgrMHl5eZ7sR0qo395Sv72nnntL/faW+h0cVQldGUDLMvMtgF2VjMkwszAgHsguvyHn3DRgGoCZZV555ZVfVaGuQJ0HbPdgP1JC/faW+u099dxb6re31O/KVfxW9gqYc2f3DIvSELUJ6AvsBJYAw5xza8uM+SnQxTl3l5kNAQY75350VjsMMjPLdM419ruO+kL99pb67T313Fvqt7fU7+A46zNdzrljZnYP8C4QCvzJObfWzJ4AljrnFgB/BGaZ2RZKznANCUbRQbLf7wLqGfXbW+q399Rzb6nf3lK/g6BKD0d1zi0EFpZb9miZ6QLgpqrsoxod8LuAekb99pb67T313Fvqt7fU7yCoe6/wDtw0vwuoZ9Rvb6nf3lPPvaV+e0v9DoKzvqdLRERERAJXn890iYiIiHhGoUtERETEAwpdIiIiIh5Q6BIRERHxgEKXiIiIiAcUukREREQ8oNAlIiIi4gGFLhEREREPKHSJiIiIeEChS0RERMQDCl0iIiIiHlDoEhEREfGAQpeIiIiIBxS6RERERDyg0CUiIiLiAYUuEREREQ8odImIiIh4QKFLRERExAMKXSIiIiIeUOgSERER8YBCl4iIiIgHFLpEREREPKDQJSIiIuIBhS4RERERDwQUusxsgJltNLMtZvZgBZ+3MrP3zGy1maWbWYtynzc0s51mNjlYhYuIiIjUJqcNXWYWCkwBrgU6AkPNrGO5Yb8HZjrnugJPAE+W+/yXwAdVL1dERESkdgoLYExvYItzbhuAmc0FBgLryozpCEwonV4EvHX8AzPrBSQD7wCpp9tZUlKSS0lJCaT2KsnPzycmJqba9yMl1G9vqd/eU8+9pX57S/2u3LJly/Y55xoHMjaQ0NUc2FFmPgPoU27MKuCHwHPAICDOzBKBHOBpYATQN5CCUlJSWLp0aSBDqyQ9PZ20tLRq34+UUL+9pX57Tz33lvrtLfW7cmb2VaBjAwldVsEyV27+fmCymd0KLAZ2AseAMcBC59wOs4o2U7oDs9HAaIDk5GTS09MDKKtq8vLyPNmPlFC/vaV+e08995b67S31OzgCCV0ZQMsy8y2AXWUHOOd2AYMBzCwW+KFz7oCZXQxcZmZjgFggwszynHMPllt/GjANIDU11XmRppXavaV+e0v99p567i3121vqd3AEErqWAG3NrDUlZ7CGAMPKDjCzJCDbOVcMPAT8CcA5N7zMmFuB1PKBS0RERKQ+OG3ocs4dM7N7gHeBUOBPzrm1ZvYEsNQ5twBIA540M0fJ5cWfBrPIwsJCMjIyKCgoCNo24+PjWb9+fdC256eoqChatGhBeHi436WIiIhIJQI504VzbiGwsNyyR8tMzwfmn2Yb04HpZ1whkJGRQVxcHCkpKZzq3rAzkZubS1xcXFC25SfnHFlZWWRkZNC6dWu/yxEREalWRcVF7D+yn5yCHLILsskuyCarIOvEdPbh7BPTSdFJzLh2ht8lnxBQ6PJbQUFBUANXXWJmJCYmkpmZ6XcpIiICHCo8xN5De0t+Du/9ZvrQXgAaRjQkNjyW2IhY4iLiiIuIIzY89qR/xkXEERMeQ1hIrfg1XSXOOfIL878doMqEp7I/OQU5uG99nw9CLIRGkY1IiE4gISqBTkmdSGmY4v0BnUKt+dNU4KqceiMiUv2OFR8j63BWpYHq+E9eYd631o0Jj6FxdGPMjNyjueQdzaOg6PS3zESHRZeEsPC4b0Ja6XRsROzJAS68NMCVTsdGxBITHkOIef/GvyNFR8gpyCkJUBWEp/LLC4sLK9xOXEQciVGJJEQlkNIwhZ5NetIoqhEJUQkkRCec+CwhKoH4yHhfjvVM1JrQJSIiUh2cc+QW5rI3/9RhKqsgi2JXfNK6YRZGUoMkmkQ3oU18Gy5qdhGNGzQmuUEyTRo0OTEdE/7tB4sWFhWSV5hH7tFccgtLglje0TwOHj1IXmHJdG5h7omQlluYS05BDtsPbj+xXmVh5TjDToSyioLZ8enY8NIAVzpd9gxcdFg0xa6YrMNZ3w5PFSzLKcipMHgCRIZGnghJSdFJtGvU7lvh6fhPo6hGRIRGnP0fbA2k0FVNYmNjycur+C+diIh4o7CosNIQdfwn83Amh48d/ta68ZHxNGnQhCbRTWjXqF3JdLmfhKiEsz67Eh4aTqPQRjSKanTWx3ek6EhJaCsTzI5Pnwh0R3NPTOcV5rHn0B627N9yItgVuaJT7iPMwihyRbjtp7+k1zmp87cDVOlniVGJRIdF1+urMwpdIiJS6zjnyC7IPmWY2ntoLzlHcr61bkRIxInQ1DGxY4VhqnF0Y6LConw4sjMTGRpJZHQkSdFJZ7W+c47Dxw5/K5iVD2sZ2zPo2b7nt85G1YZLejVJrQtdv/3st2zI3lDl7RQVFREaGgpA+4T2PND7gVOOf+CBB2jVqhVjxowB4LHHHsPMWLx4MTk5ORQWFvKrX/2KgQMHnnbfeXl5DBw4sML1Zs6cye9//3vMjK5duzJr1iz27NnDXXfdxbZt2wB44YUX+O53v1uVwxcRqVV25u1k6e6lLNuzjBV7V5BxMINj24+dNMYwEqISaNKgCU1jmtK1cddvhankBsk0jGhYr8+2lGVmNAhvQIPwBiSTXOm49IPppLVP866wOqrWhS6/DBkyhPHjx58IXfPmzeOdd95hwoQJNGzYkH379nHRRRdx/fXXn/Zf5qioKN58881vrbdu3Tp+/etf89///pekpCSys7MBGDduHFdccQVvvvkmRUVFumwpInWac44duTtYumcpS3cvZemepXyd/zVQ8s2/nsk9uYALSG2felKYSoxOJDxEzyuUmqvWha7TnZEK1Jk+p6tHjx7s3buXXbt2kZmZSaNGjWjWrBkTJkxg8eLFhISEsHPnTvbs2UPTpk1PuS3nHL/4xS++td7777/PjTfeSFJSyWnihIQEAN5//31mzpwJQGhoKPHx8Wd51CIiNY9zji8OfnEiYC3bvYy9h0ser5AQlUCv5F6M6jSK1ORU2jZqS4iFlLyWpkOav4WLnKFaF7r8dOONNzJ//nx2797NkCFDmD17NpmZmSxbtozw8HBSUlICemp+Zes553TKW6SWOVZ8jDX71pBZmEmxK9b9LQEodsVs2b/lxOXCZXuWkVWQBUDj6MakJqeS2jSV1ORUWse31n8Xpc5Q6DoDQ4YM4Sc/+Qn79u3jgw8+YN68eTRp0oTw8HAWLVrEV199FdB2Dhw4UOF6ffv2ZdCgQUyYMIHExESys7NJSEigb9++vPDCC4wfP56ioiLy8/Np2LBhdR6qiJxGUXER//zyn7y46kW+Oljy7/DvZv+O1vGtueCcCzj/nPNP/PPc2HPrdRgrKi5iU86mE5cLl+9dzv4j+wFoGtOUi8+9+ETQOi/uPIUsqbMUus5Ap06dyM3NpXnz5jRr1ozhw4fzgx/8gNTUVLp370779u0D2k5l63Xq1ImHH36YK664gtDQUHr06MH06dN57rnnGD16NH/84x8JDQ3lhRde4OKLL67OQxWRShS7Yv711b94YeULbDuwjXaN2jHx0omsWbeG0ORQtu7fyqdff8rft/39xDrRYdG0iW/D+eecf1IYaxbTrE6GsWPFx9iQveHE5cLle5aTW5gLQIvYFqS1TKNXci9Sk1NpHttcIUvqDYWuM7RmzZoT00lJSXzyyScVjjvVze6nWm/UqFGMGjXqpGXJycn87W9/O4tqRSRYnHO8v/19pqyawuaczZwffz5PX/E0V7e6mhALIW5HHGm9006MP3DkANsObGPL/i1s3b+Vrfu38smuT1iwdcGJMdFh0Zwff3IQu+CcC2ga07RWBZHCokLWZq0tOZO1Zykr964kvzAfgJSGKfRL6XficmHTmFPf8ypSlyl0idQxhcWF7D+23+8y6gznHIszFjNl5RTWZ68npWEKv7nsNwxIGUBoSGil68VHxtOjSQ96NOlx0vIDRw6wdf/Wk8LYRzs/4m9bv/kfq5jwGM6PP58257Q5KYwlN0iuEWHsSNER1mSuORGyVmeuPvFw0fPjz+f7bb5PanIqvZJ70bhBY5+rFak5FLqq0Zo1axgxYsRJyyIjI/n00099qkjqut35u5mwaAKfZ33OGwvfYEj7IfRr1Y/wUH2N/kw55/h418dMWTmFNfvW0CK2Bb+65Fdc1+a6Kr2EOD4ynp7JPemZ3POk5fsL9rP1wNaTAtnijMW8teWtE2Niw2O/CWLx35wda9KgSbWGscPHDrM6c/WJe7JWZ67maPFRDKNdo3YMbjuY1ORUeiaXPDxTRCpWa0JXbfxmX5cuXVi5cmW178e5b7+aQeqfpbuXct8H93Gk6AhXN7yazUc28+CHD/LUkqe46cKbuKndTTRp0MTvMmuFT7/+lCkrp7Bi7wqaxTTjsYsf4/oLrq/WZ0CdE3UOvaJ60Su510nLcwpy2LJ/C9v2l16qPLCV9B3p/HXzX0+MiQuPO+ms2PEzY8dfsHymDhUeYsXeFSWPb9izjDX71nCs+BghFkL7hPYMaT/kRMiKj9QjbEQCVStCV1RUFFlZWSQmJta64FXdnHNkZWURFVXzX1ch1cM5x2sbXuP3S35Pi7gWPHflc2xfuZ3Lr7icT3Z9wpwNc3hp1Uu8svoV+rbqy9D2Q+nZpKf+XarA8j3LmbxyMkt2L6FJgyY80ucRBrUd5OtLdxtFNeI7Tb/Dd5p+56Tl2QXZJ50V27J/C+9tf483Nr9xYkxcRNxJlyfbxJcEs6TopJP+/HOP5paErNIb39dlraPIFRFqoXRK7MSIjiNITU6lR5MexEUE/nxDETlZrQhdLVq0ICMjg8zMzKBts6CgoM4ElaioKFq0aOF3GeKDgmMF/PJ/v2TB1gWktUzjyUufJDYilu1sJ8RCuKT5JVzS/BJ25O5g3sZ5/HXzX3n3y3dp16gdQ9sP5Xutv0eD8AZ+H4bvVmWuYsqKKXzy9SckRiXyYO8HubHdjUSGRvpdWqUSohJIaJpwUhg7/j7C8mHs31/9m/mb5p8Y1zCiIReccwEt4lqwOWczG3M2UuyKCQsJo2tSV27vfDupTVPp3ri7/n6IBFGtCF3h4eG0bt06qNtMT0+nR48epx8oUkPtytvF+EXjWZ+9njHdx3Bn1zsrffxAy7iW3Jd6H2O6j+GfX/yT19a/xuOfPM4zy55h0AWDuPnCmzmv4XkeH4H/1matZcqKKXy480MaRTbivl73cXP7m4kOi/a7tLNiZiRGJ5IYnUjvZr1PLHfOkVWQ9a0b+D/e9TGt41tzZ9c7SU1OpWvjrrXiJc8itVWtCF0icrLPvv6M+z+4n8LiQiZfNZkrWl4R0HrRYdEMbjuYQRcMYmXmSuasn8Nr619j1rpZXNr8Uoa2H8olzS+pk8+OKmtj9kamrJzCoh2LaBjRkHt73suw9sPq7FkdMyMpOomk6CT6NOvjdzki9ZZCl0gt4pxj1rpZPLPsGVo1bMVzVz5HSnzKGW/HzE48ziDzUCbzN81n3qZ5jHlvDC3jWjLkwiEMvGBgnbtJeuv+rUxdOZV/ffUv4sLjGNN9DCM6jCA2Itbv0kSkHlDoEqklDh87zGMfP8bCLxZy9XlX86tLf0VMeEyVt9u4QWPu7n43d3S5g/e2v8ecDXN4aulTTF45mevaXMeQC4dwYcKFQTgC/3x54EteWPUC//zin0SHRTO662hGdhxZ50KliNRsCl0itUBGbgbjF41nU84mxvUYxx1d7gj6tw/DQ8MZ0HoAA1oPYEP2BuZumMs/tv6D+Zvm0yu5F0PbD+Wq866q1scmBNuO3B28uOpF/rHtH0SGRnJb59u4tdOtNIpq5HdpIlIPBRS6zGwA8BwQCrzinPtNuc9bAX8CGgPZwC3OuQwz6w68ADQEioBfO+deD2L9InXex7s+5v8W/x/FrpgpfadwWYvLqn2f7RPa89h3H2NCrwm8teUt5myYw/0f3E+T6CbcdOFN3NjuRpKik6q9jrO1K28X01ZP429b/kZoSCi3dLiF2zrfVqNrFpG677Shy8xCgSnANUAGsMTMFjjn1pUZ9ntgpnNuhpldBTwJjAAOASOdc5vN7FxgmZm965zTO0pETsM5x5/X/pnnlj9Hm/g2TLpyEi0btvS0hvjIeEZ1GsUtHW7hv7v+y2sbXmPKyim8tPol+rXqx9D2Q+nWuFuNeebXnvw9vLzmZd7Y/AaGcdOFN3FHlzv0UFgRqRECOdPVG9jinNsGYGZzgYFA2dDVEZhQOr0IeAvAObfp+ADn3C4z20vJ2TCFLpFTOFR4iEc/fpR3v3yX/in9eeK7T/j6zbrQkFAub3E5l7e4nC8PfMnrG1/nrS1vsfCLhXRI6MDQ9kO5tvW1vj1uYN/hfbyy5hX+svEvFLtiBrUdxOiuo/VyZRGpUQIJXc2BHWXmM4Dy3zleBfyQkkuQg4A4M0t0zmUdH2BmvYEIYGuVKhap43Yc3MG96feydf9WftbrZ9za6dYacyYJICU+hQd6P8DYHmP5x7Z/MGfDHB79+FGeXvY0g9sO5uYLb6Z5bHNPaskuyObPn/+ZuRvmUlhcyPXnX8+d3e70bP8iImfCTvfePjO7CejvnLujdH4E0Ns5N7bMmHOByUBrYDElAayTc+5A6efNgHRglHPufxXsYzQwGiA5ObnX3Llzq35kp5GXl0dsrL4m7hX1OzDrDq9j+r7pGMZtSbfRPrr9WW3Hy34759hyZAuLcxez+tBqHI7O0Z25PO5yLoy6sFoCY35RPu8dfI8Pcj+g0BWSGpPKtfHX0ji8cdD3FSj9HfeW+u0t9btyV1555TLnXGogYwMJXRcDjznn+pfOPwTgnHuykvGxwAbnXIvS+YaUBK4nnXN/OV1BqampbunSpYHUXiXp6emkpaVV+36khPp9as45XlnzCs+veJ52jdrx7JXP0iLu7F/t5Fe/d+fvZt7Gebyx+Q2yC7JJaZjCkPZDGHj+wKA8C+vg0YPMWjeLWetmcajwEANSBnBX97toE98mCNVXjf6Oe0v99pb6XTkzCzh0BXJ5cQnQ1sxaAzuBIcCwcjtMArKdc8XAQ5R8kxEziwDepOQm+9MGLpH6KL8wn0c+eoT/bP8P17a+lse/+3itfQ1N05imjOs5jru63cW/vvoXczbM4Tef/YZJyyfxg/N/wND2Qzn/nPPPeLv5hfm8uu5VZqybQe7RXK5pdQ13d7ubto3aVsNRiIhUj9OGLufcMTO7B3iXkkdG/Mk5t9bMngCWOucWAGnAk2bmKLm8+NPS1X8EXA4kmtmtpctudc6tDO5hSE31+b7PmfjpRHbt38Wtn9/KD9v9kLiIOL/LqjG+PPAl4xeN58uDX/Lz1J8zouOIGnX/1tmKCI3g+22+z/fbfJ+1+9by2obXeHPzm7y+8XX6NO3D0PZDuaLlFYSFnPo/QYcKDzFnwxymr53O/iP7SWuZxphuY+iQ2MGjIxERCZ6AntPlnFsILCy37NEy0/OB+RWs9yrwahVrlFoo72gez694njkb5tA4ujGNQhvx9LKneWHVCwxuO5jhHYZX6fJZXfDBjg948MMHCQ8J56VrXqqz78TrlNSJX1/6a+5LvY+/bv4r8zbOY3z6eJrGNOXmC29mcNvBJEQlnLROwbEC5m2cxx8//yPZBdlc0vwS7ul+D52TOvt0FCIiVacn0ktQOed4b/t7PPnpk2QezmRo+6GM7TGWpR8vpUmXJsxaN4u5G+by2obX6HteX0Z2HEn3Jt39LttTxa6Yl1a/xNSVU+mQ0IFnr3yWc2PP9busapcQlcAdXe7g1k638kHGB8zZMIfnlj/H1JVTubb1tQxtP5R2jdoxf9N8XlnzCpmHM+nTrA/3dL+n3v0dEZG6SaFLgubrvK+Z+OlE0jPSaZ/QnmevfJYujbuc+LxjYkeevOxJxvccz5wNc5i3aR7//urfdG3clZEdR9L3vL6nvdxU2+UezeUXH/2C9B3pXH/+9fy/i/6fb8+28ktYSBh9z+tL3/P6sm3/NuZsmMOCrQtYsHUBMeEx5Bfm07NJT357+W/5TtPv+F2uiEjQ1O3fcOKJY8XHeG39a0xeORmA+1PvZ3iH4ZUGqOSYZMb3Gs/orqP529a/MWvdLO7/4H7OjTmX4R2GM7jt4KB8062m2XZgG/e+fy87cnfwYO8HGdZ+WJ24f6sq2pzThocveph7e97Lgq0LWJW5ihsuuIGLml1U73sjInWPQpdUydp9a3n8k8dZn72ey1tczsN9Hg74UlmD8AYMbT+UH7X7ER9kfMCMtTN4aulTTF01lR+2/SHDOwyvM5fd3tv+Hg9/9DCRoZG83O9lncEpJzYilmEdhjGsw7DTDxYRqaUUuuSs5B3NY/LKyczZMIfEqESeSXuGq8+7+qzOToSGhHLVeVdx1XlX8fm+z5m5biaz189m9vrZXN3qakZ2HEnXxl2r4SiqX7ErZurKqby0+iU6J3bmD1f+Qa+mERGppxS65Iy999V7TPxsIpmHMhnSfghje4wN2mMgOid15neX/46f9foZr61/jfmb5vPul+/So0kPRnYcyZUtryQ0JDQo+6puB48e5KEPH2JxxmJuuOAGHrnoESJDI/0uS0REfKLQJQH7Ou9rJn42kfQd6bRr1I4/pP2h2s5ANY1pys9Sf8ad3e7krS1vMWvdLCakT6B5bHNGdBzBDRfcQEx4TLXsOxi25Gzh3kX3sitvF4/0eYQfXfgj3aMkIlLPKXTJaZW/Uf6+XvcxvONwwkPCq33fMeExDO8wnCEXDmHRjkXMXDeT33z2G6asmMKN7W5kWIdhNe5y3b+/+jcPf/QwDcIa8Mf+f6Rnck+/SxIRkRpAoUtOaW3WWh7/uORG+cuaX8bDFz1M89jmntcRGhLK1a2u5upWV7M6czWz1s1i5rqZzFw3k34p/RjVcRSdkjp5XldZRcVFTF45mVfWvELXxl155opnSI5J9rUmERGpORS6pEL5hflMXjGZ1za8RmJUIk9f8TTXtLqmRlwi69q4K09d8RS78nYxe/1s3tj8Bv/84p/0bNKTkZ1GktYizfP7vg4cOcADix/gv7v+y43tbuSh3g8RERrhaQ0iIlKzKXTJtxx/ovzeQ3u5+cKbGddzXI18X+K5sefy8+/8nLu73c1fN/+V2etnM37ReFrGteSWDrdwwwU30CC8QbXXsTF7I+MXjWf3od08evGj3NTupmrfp4iI1D4KXXLC7vzdTPx0Iot2LKJdo3Y8k/ZMrXhUQ2xELCM7jWRYh2G8t/09Zq6dyZOfPcnklZO5qd1NDG0/tNru+3rni3d49ONHiQuP48/9/6zX1YiISKUUuoSi4iLmbJjD8yuep9gV87NeP+OWjrd4cqN8MIWFhNE/pT/9U/qzcu9KZq6byfS105m5dib9W/dnZMeRdEzsGJR9HSs+xnPLn2P62un0aNKDZ9KeISk6KSjbFhGRukmhq55bm7WWJz55gnVZ67i0+aU8ctEjvtwoH2zdm3Sne5PuZORmMHv9bP66+a+8ve1tUpNTGdlxJFe0vIIQCzmrbe8v2M/PF/+c/339P26+8GYe+M4DhIfWroAqIiLeU+iqp8reKJ8QlcDvr/g9/Vr1qxE3ygdTi7gWPND7AcZ0H8NfN/+VV9e/yrhF42jVsBW3dLiF68+//ozu+1qftZ4J6RPYe2gvT3z3CQa1HVSN1YuISF1ydv+rL7Xa+9vfZ+BbA5m9fjY3tbuJBTcsoH9K/zoXuMqKi4hjVKdRLBy8kKcuf4q48Dh+/emv6fdGPyYtn8TeQ3tPu41/bPsHI/45gmPFx5gxYIYCl4iInBGd6apHdufv5slPn+T9He/TtlFbnk57mm6Nu/ldlqfCQ8IZ0HoA/VP6s2LvCmaum8kra17hz2v/zPdaf48RHUfQPqH9SescKz7G00uf5tX1r9IruRdPX/E0idGJPh2BiIjUVgpd9UD5G+Un9JrAiI4jat2N8sFkZvRM7knP5J7sOLiDV9e/yptb3mTB1gX0adqHkZ1GcmnzS9l/ZD/3f3A/S3YvYXiH4dyXel+97puIiJw9ha46bl3WOh7/5HHWZa3jkuaX8EifR2gR18LvsmqUlg1b8lCfhxjTfQxvbH6D2etn89P3fkpKwxQKigrIKchh4qUT+cH5P/C7VBERqcUUuuqoQ4WHmLxyMrPXzyYhKoGnrniK/q3q9n1bVRUfGc/tnW9nRMcR/OvLfzFz3UwKiwuZee3MoD1qQkRE6i+Frjpo0fZFTPxsInvy9/CjC3/EuJ7jaBjR0O+yao3wkHCua3Md17W5DuecgqqIiARFQN9eNLMBZrbRzLaY2YMVfN7KzN4zs9Vmlm5mLcp8NsrMNpf+jApm8XKy3fm7Gb9oPOMWlby2Z+a1M3nkokcUuKpAgUtERILltGe6zCwUmAJcA2QAS8xsgXNuXZlhvwdmOudmmNlVwJPACDNLAP4/IBVwwLLSdXOCfSD1WVFxEXM3zmXS8kkUu2LG9xzPyE4jdcO3iIhIDRLI5cXeKKD7NQAAIABJREFUwBbn3DYAM5sLDATKhq6OwITS6UXAW6XT/YF/O+eyS9f9NzAAmFP10gVKHtb5+CePszZrLZecewkPX/QwLeNa+l2WiIiIlBNI6GoO7CgznwH0KTdmFfBD4DlgEBBnZomVrFv73zFTAxwqPMSUlVN4df2rNIpsxFOXP1XnH3AqIiJSmwUSuir6Le7Kzd8PTDazW4HFwE7gWIDrYmajgdEAycnJpKenB1BW1eTl5Xmyn+qw5tAa/pL9F3KKcrg09lJ+0OgHRH0VxQdffeB3aZWqzf2ujdRv76nn3lK/vaV+B0cgoSsDKHu9qgWwq+wA59wuYDCAmcUCP3TOHTCzDCCt3Lrp5XfgnJsGTANITU11aWlp5YcEXXp6Ol7sJ5j25O/hN5/9hv9k/ocLzrmASRdPonuT7n6XFZDa2O/aTP32nnruLfXbW+p3cAQSupYAbc2sNSVnsIYAw8oOMLMkINs5Vww8BPyp9KN3gYlm1qh0vl/p53KGCosKuf3d29l7aK9ulBcREamFThu6nHPHzOweSgJUKPAn59xaM3sCWOqcW0DJ2awnzcxRcnnxp6XrZpvZLykJbgBPHL+pXs7M/M3z2Z67nal9p3JZi8v8LkdERETOUEAPR3XOLQQWllv2aJnp+cD8Stb9E9+c+ZKzcKjwEC+uepHvNP0Olza/1O9yRERE5CzoifS1wMx1M8kuyGZSz0n6dqKIiEgtFdAT6cU/OQU5TF87nb7n9aVb425+lyMiIiJnSaGrhnt5zcscPnaYcT3G+V2KiIiIVIFCVw32dd7XzN0wl4HnD6TNOW38LkdERESqQKGrBpuycgqGMab7GL9LERERkSpS6KqhtuRs4e/b/s7Q9kNpGtPU73JERESkihS6aqhJKybRIKwBd3S5w+9SREREJAgUumqglXtXsmjHIm7vfDvnRJ3jdzkiIiISBApdNYxzjj8s+wNJ0UkM7zDc73JEREQkSBS6apgPd37I8r3LuavrXTQIb+B3OSIiIhIkCl01SLEr5rnlz9EyriWD2w32uxwREREJIoWuGmThFwvZlLOJsT3GEh4S7nc5IiIiEkQKXTVEYVEhk1dMpkNCB/qn9Pe7HBEREQkyha4a4i+b/sLOvJ3c2/NeQkx/LCIiInWNfrvXAIcKD/HS6pfo3bQ33z33u36XIyIiItVAoasGmLFuBtkF2dzb817MzO9yREREpBoodPksuyCbGWtncPV5V9O1cVe/yxEREZFqotDls5dXv8zhY4cZ23Os36WIiIhINVLo8tGuvF28vvF1brjgBtrEt/G7HBEREalGCl0+mrJyCiEWwt3d7va7FBEREalmCl0+2Zyzmb9v/TvD2g+jaUxTv8sRERGRaqbQ5ZNJKyYRGx7Lj7v82O9SRERExAMBhS4zG2BmG81si5k9WMHn55nZIjNbYWarzex7pcvDzWyGma0xs/Vm9lCwD6A2WrF3Bek70rm9y+3ER8b7XY6IiIh44LShy8xCgSnAtUBHYKiZdSw37BFgnnOuBzAEmFq6/CYg0jnXBegF3GlmKcEpvXZyzvHssmdJik5iWPthfpcjIiIiHgnkTFdvYItzbptz7igwFxhYbowDGpZOxwO7yiyPMbMwIBo4ChysctW12Ic7P2T53uXc3e1uGoQ38LscERER8Uggoas5sKPMfEbpsrIeA24xswxgIXD8oVPzgXzga2A78HvnXHZVCq7NioqLeHb5s5wXdx6D2g7yuxwRERHxUFgAYyp6L40rNz8UmO6ce9rMLgZmmVlnSs6SFQHnAo2AD83sP865bSftwGw0MBogOTmZ9PT0MzuKs5CXl+fJfspakreEzTmbuTXpVv67+L+e7ttvfvS7PlO/vaeee0v99pb6HRyBhK4MoGWZ+RZ8c/nwuB8DAwCcc5+YWRSQBAwD3nHOFQJ7zey/QCpwUuhyzk0DpgGkpqa6tLS0Mz+SM5Seno4X+znuaNFRfvPWb+iQ0IEJ35tAiNWvL4563e/6Tv32nnruLfXbW+p3cATym38J0NbMWptZBCU3yi8oN2Y70BfAzDoAUUBm6fKrrEQMcBGwIVjF1yZ/2fQXdubtZHzP8fUucImIiEgAocs5dwy4B3gXWE/JtxTXmtkTZnZ96bD7gJ+Y2SpgDnCrc85R8q3HWOBzSsLbn51zq6vhOGq0/MJ8pq2eRp+mfbj43Iv9LkdERER8EMjlRZxzCym5Qb7sskfLTK8DLqlgvTxKHhtRr81cO5PsgmzG9xqPWUW3yImIiEhdp+tc1Sy7IJvpa6dzTatr6JzU2e9yRERExCcKXdXs5dUvc6ToCGN7jD39YBEREamzFLqq0c68nby+8XVuuOAGWse39rscERER8ZFCVzWaunIqIRbC3d3u9rsUERER8ZlCVzXZlLOJv2/9O8M6DCM5JtnvckRERMRnCl3V5PnlzxMbEcuPO//Y71JERESkBlDoqgbL9ywnPSOd2zvfTnxkvN/liIiISA2g0BVkzjmeXf4sjaMbM7zDcL/LERERkRpCoSvIFmcsZsXeFdzV7S6iw6L9LkdERERqCIWuICoqLuLZ5c/SqmErBrUd5Hc5IiIiUoModAXRwi8WsmX/Fu7pcQ/hIeF+lyMiIiI1iEJXkBwtOsrkFZPpmNiRfq36+V2OiIiI1DAKXUEyb+M8duXv4t6e9xJiaquIiIicTOkgCPIL85m2ehp9mvXhu+d+1+9yREREpAZS6AqCGWtnkHMkh/E9x/tdioiIiNRQCl1VlHU4ixlrZ3BNq2vonNTZ73JERESkhlLoqqKX17zMkaIjjOsxzu9SREREpAZT6KqCjNwMXt/4OoPaDiIlPsXvckRERKQGU+iqgqkrpxJqodzV9S6/SxEREZEaTqHrLG3M3sg/tv2D4R2GkxyT7Hc5IiIiUsMpdJ2lSSsmERsRy+2db/e7FBEREakFAgpdZjbAzDaa2RYze7CCz88zs0VmtsLMVpvZ98p81tXMPjGztWa2xsyignkAfli2ZxmLMxbz484/Jj4y3u9yREREpBYIO90AMwsFpgDXABnAEjNb4JxbV2bYI8A859wLZtYRWAikmFkY8Cowwjm3yswSgcKgH4WHnHM8u+xZmkQ3YViHYX6XIyIiIrVEIGe6egNbnHPbnHNHgbnAwHJjHNCwdDoe2FU63Q9Y7ZxbBeCcy3LOFVW9bP98kPEBKzNXclf3u4gOi/a7HBEREaklAgldzYEdZeYzSpeV9Rhwi5llUHKWa2zp8naAM7N3zWy5mf1fFev1VVFxEc8tf46UhikMumCQ3+WIiIhILXLay4uAVbDMlZsfCkx3zj1tZhcDs8ysc+n2LwW+AxwC3jOzZc65907agdloYDRAcnIy6enpZ3YUZyEvL++M9/Np3qds2b+F25Nu56PFH1VPYXXU2fRbzp767T313Fvqt7fU7+AIJHRlAC3LzLfgm8uHx/0YGADgnPuk9Gb5pNJ1P3DO7QMws4VAT+Ck0OWcmwZMA0hNTXVpaWlnfCBnKj09nTPZz9Gio0x8cyKdEjsx/nvjMasoi0plzrTfUjXqt/fUc2+p395Sv4MjkMuLS4C2ZtbazCKAIcCCcmO2A30BzKwDEAVkAu8CXc2sQelN9VcA66iFXt/4Ol/nf834XgpcIiIicuZOe6bLOXfMzO6hJECFAn9yzq01syeApc65BcB9wMtmNoGSS4+3OucckGNmz1AS3Byw0Dn3dnUdTHXJO5rHy6tf5qJmF3FRs4v8LkdERERqoUAuL+KcW0jJDfJllz1aZnodcEkl675KyWMjaq0Z62aQcySH8T3H+12KiIiI1FJ6Iv1p7Du8jxlrZ9CvVT86JXXyuxwRERGppRS6TuPl1S9ztOgoY3uMPf1gERERkUoodJ3CjtwdzNs0j8FtB5MSn+J3OSIiIlKLKXSdwtSVUwmzMO7qdpffpYiIiEgtp9BViY3ZG3l729sM7zCcJg2a+F2OiIiI1HIKXZV4bvlzxEbEclvn2/wuRUREROoAha4KLN29lA93fsgdXe4gPjLe73JERESkDlDoKsc5x7PLn6VJdBOGtR/mdzkiIiJSRyh0lZO+I51Vmau4u/vdRIVF+V2OiIiI1BEKXWUUFRcxacUkUhqmcMMFN/hdjoiIiNQhCl1l/H3b39myfwtje4wlLCSgNySJiIiIBEShq9SRoiNMXTmVzomduabVNX6XIyIiInWMQlep1ze8ztf5XzO+13jMzO9yREREpI5R6ALyjubx8pqXubjZxfRp1sfvckRERKQOUugCpq+dzv4j+xnfa7zfpYiIiEgdVe9D177D+5i5biYDUgbQMbGj3+WIiIhIHVXvQ9e01dMoLCrknh73+F2KiIiI1GH1OnTtyN3BXzb9hcFtB9OqYSu/yxEREZE6rF6HrskrJhNmYdzZ7U6/SxEREZE6rt6GroyjGSz8YiG3dLyFJg2a+F2OiIiI1HH1NnT9PefvNIxoyG2db/O7FBEREakH6mXoWrJ7CesK1nFHlztoGNHQ73JERESkHggodJnZADPbaGZbzOzBCj4/z8wWmdkKM1ttZt+r4PM8M7s/WIWfLecczy5/lnNCz2Fo+6F+lyMiIiL1xGnf6mxmocAU4BogA1hiZgucc+vKDHsEmOece8HMOgILgZQyn/8B+GfQqq6Cw8cOk9wgmc5FnYkKi/K7HBEREaknAjnT1RvY4pzb5pw7CswFBpYb44Dj1+nigV3HPzCzG4BtwNqql1t1DcIb8EzaM1wUe5HfpYiIiEg9Ekjoag7sKDOfUbqsrMeAW8wsg5KzXGMBzCwGeAB4vMqVBpleai0iIiJeOu3lRaCidOLKzQ8Fpjvnnjazi4FZZtaZkrD1B+dc3qlCjpmNBkYDJCcnk56eHkjtVZKXl+fJfqSE+u0t9dt76rm31G9vqd/BEUjoygBalplvQZnLh6V+DAwAcM59YmZRQBLQB7jRzH4HnAMUm1mBc25y2ZWdc9OAaQCpqakuLS3tLA7lzKSnp+PFfqSE+u0t9dt76rm31G9vqd/BEUjoWgK0NbPWwE5gCDCs3JjtQF9gupl1AKKATOfcZccHmNljQF75wCUiIiJSH5z2ni7n3DHgHuBdYD0l31Jca2ZPmNn1pcPuA35iZquAOcCtzrnylyBFRERE6i2radnIzDKBrzzY1XmUnKETb6jf3lK/vaeee0v99pb6XblWzrnGgQyscaHLK2aWGWiTpOrUb2+p395Tz72lfntL/Q6OevkaoFL7/S6gnlG/vaV+e08995b67S31Owjqc+g64HcB9Yz67S3123vqubfUb2+p30FQn0PXNL8LqGfUb2+p395Tz72lfntL/Q6CentPl4iIiIiX6vOZLhERERHPKHSJiIiIeEChS0RERMQDCl0iIiIiHlDoEhEREfGAQpeIiIiIBxS6RERERDyg0CUiIiLiAYUuEREREQ8odImIiIh4QKFLRERExAMKXSIiIiIeUOgSERER8YBCl4iIiIgHFLpEREREPKDQJSIiIuIBhS4RERERDyh0iYiIiHhAoUtERETEAwpdIiIiIh5Q6BIRERHxgEKXiIiIiAcUukREREQ8oNAlIiIi4gGFLhEREREPKHSJiIiIeCDM7wLKS0pKcikpKdW+n/z8fGJiYqp9P1JC/faW+u099dxb6re31O/KLVu2bJ9zrnEgY2tc6EpJSWHp0qXVvp/09HTS0tKqfT9SQv32lvrtPfXcW+q3t9TvypnZV4GO1eVFEREREQ8odImIiIh4QKFLRERExAM17p4uERER8U5hYSEZGRkUFBRUOiY+Pp7169d7WFXNExUVRYsWLQgPDz/rbdTL0JX/v08J3fW132WIiIj4LiMjg7i4OFJSUjCzCsfk5uYSFxfncWU1h3OOrKwsMjIyaN269Vlvp95dXizKyydj7Fhi33rL71JERER8V1BQQGJiYqWBS8DMSExMPOXZwEDUu9AVGhtDwm23ErV6NYfXfO53OSIiIr5T4Dq9YPSo3oUugISRIymOiSHz+Ul+lyIiIiL1RL0MXaGxseT3u4b8xR9yaMUKv8sRERGRAMXGxlb62Zdffknnzp09rObM1MvQBXAoLY3QhAQyJ+lsl4iIiFS/ehu6iIwk8Sc/4dAn/yP/s8/8rkZERKReeuCBB5g6deqJ+ccee4zHH3+cvn370rNnT7p06cLf/va3M95uQUEBt912G126dKFHjx4sWrQIgLVr19K7d2+6d+9O165d2bx5M/n5+Vx33XV069aNzp078/rrrwft+Mqql4+MOK7R0CFk/+lP7Jv0PA1mzdSNhCIiUq/tnjiRI+s3fGv5saIiskNDz2qbkR3a0/QXv6j08yFDhjB+/HjGjBkDwLx583jnnXeYMGECDRs2ZN++fVx00UVcf/31Z/R7esqUKQCsWbOGDRs20K9fPzZt2sSLL77Ivffey/Dhwzl69ChFRUUsXLiQc889l7fffhuAAwcOnNWxnk79PdMFhERFkXjnnRxaupRDn3zidzkiIiL1To8ePdi7dy+7du1i1apVNGrUiGbNmvGLX/yCrl27cvXVV7Nz50727NlzRtv96KOPGDFiBADt27enVatWbNq0iYsvvpiJEyfy29/+lq+++oro6Gi6dOnCf/7zHx544AE+/PBD4uPjq+NQ6/eZLoBzbrqRrFdeIXPS8zS4+GKd7RIRkXqrsjNS1f1w1BtvvJH58+eze/duhgwZwuzZs8nMzGTZsmWEh4eTkpJyxs/Ics5VuHzYsGH06dOHt99+m/79+/PKK69w1VVXsWzZMhYuXMhDDz1Ev379ePTRR4NxaCep12e6AEIiI0m66y4Or1xJ/ocf+l2OiIhIvTNkyBDmzp3L/PnzufHGGzlw4ABNmjQhPDycRYsW8dVXX53xNi+//HJmz54NwKZNm9i+fTsXXngh27Zto02bNowbN47rr7+e1atXs2vXLho0aMAtt9zC/fffz/Lly4N9iIBCFwDnDB5EePPmZE56vtJkLCIiItWjU6dO5Obm0rx5c5o1a8bw4cNZunQpqampzJ49m/bt25/xNseMGUNRURFdunTh5ptvZvr06URGRvL666/TuXNnunfvzoYNGxg5ciRr1qw5cXP9r3/9ax555JFqOEpdXgTAIiJIGnM3Xz/8CHmLFhF31VV+lyQiIlKvrFmz5sR0UlISn1Ryr3VeXl6l20hJSeHzz0veNhMVFcX06dO/Neahhx7ioYceOmlZ//796d+//1lUfWYCOtNlZgPMbKOZbTGzByv4/C4zW2NmK83sIzPrWLo8xcwOly5faWYvBvsAgiV+4EDCW51XcraruNjvckRERKSOOe2ZLjMLBaYA1wAZwBIzW+CcW1dm2GvOuRdLx18PPAMMKP1sq3Oue3DLDj4LC6PxT3/Krv97gNx//ZuGA6o/8YqIiMiZW7NmzYlvJh4XGRnJp59+6lNFgQnk8mJvYItzbhuAmc0FBgInQpdz7mCZ8TFArbwxquF117HvxZfInPw8cddcjZ3lM0lERESk+nTp0oWVK1f6XcYZC+TyYnNgR5n5jNJlJzGzn5rZVuB3wLgyH7U2sxVm9oGZXValaquZhYbS+J6fcnTLVg7+8x2/yxEREfGEvkR2esHokZ1uI2Z2E9DfOXdH6fwIoLdzbmwl44eVjh9lZpFArHMuy8x6AW8BncqdGcPMRgOjAZKTk3vNnTu3qsd1Wnl5eRW/NLO4mIRfT8SOFZL16KOgs11BUWm/pVqo395Tz72lfgdPbGwsycnJxMfHV/qsyqKiIkLr8e9D5xwHDhxgz54937qR/8orr1zmnEsNZDuBXF7MAFqWmW8B7DrF+LnAC6VFHgGOlE4vKz0T1g5YWnYF59w0YBpAamqqS0tLC6T2KklPT6ey/RwsKmLn2HF0P5jLOYNuqPZa6oNT9VuCT/32nnruLfU7eAoLC8nIyGDnzp2VjikoKCAqKsrDqmqeqKgounXrRnh4+FlvI5DQtQRoa2atgZ3AEGBY2QFm1tY5t7l09jpgc+nyxkC2c67IzNoAbYFtZ12tR+KuvprIjh3YN3Uq8d+/DqtCg0VERGqy8PBwWrdufcox6enp9OjRw6OK6q7T3tPlnDsG3AO8C6wH5jnn1prZE6XfVAS4x8zWmtlK4GfAqNLllwOrzWwVMB+4yzmXHfSjCDIzo/HYsRTu2MH+t97yuxwRERGpAwJ6OKpzbiGwsNyyR8tM31vJem8Ab1SlQL/EpqUR1bUr+154gfiBAwmJiPC7JBEREanF9BqgShw/23Vs19fsnz/f73JERESkllPoOoWYSy8humdPsl58ieIjR/wuR0RERGoxha5TMDMajxvHsb172f/6636XIyIiIrWYQtdpxFzUhwZ9+rBv2ssUHz7sdzkiIiJSSyl0BaDxuLEU7dtHzmtz/C5FREREaimFrgA06NWLmEsuIeuVVyjKy/e7HBEREamFFLoC1HjcWIpycsh59VW/SxEREZFaSKErQNHduhF7xRVk/fnPFOXm+l2OiIiI1DIKXWcgadxYig8cIHvGTL9LERERkVpGoesMRHfqRNw1V5M9fTpF+/f7XY6IiIjUIgpdZyjpnrEU5+WR9efpfpciIiIitYhC1xmKurAdcdcOIHvWLI7l5PhdjoiIiNQSCl1nofE99+AKCsh65RW/SxEREZFaQqHrLESefz4Nv38dObNf41hmpt/liIiISC2g0HWWGo8Zgyss1NkuERERCYhC11mKSEkhfuBAcubMpXDPHr/LERERkRpOoasKksbcjSsuJuull/wuRURERGo4ha4qiGjRgnMGDybnL/Mp3LXL73JERESkBlPoqqKku+/CgH0vvOh3KSIiIlKDKXRVUXizZpzzox+x/803Obpjh9/liIiISA2l0BUEiaNHY6Gh7Jsy1e9SREREpIZS6AqC8OQmNBoyhAMLFnDkiy/8LkdERERqIIWuIEkc/RMsMlJnu0RERKRCCl1BEpaYSMItwzn49tsc2bzZ73JERESkhlHoCqKE228nJDqaTJ3tEhERkXIUuoIorFEjGo0aSe4771CwYYPf5YiIiEgNotAVZIm33kpIXByZz0/2uxQRERGpQRS6giw0Pp6EW0eR9957HP58rd/liIiISA2h0FUNEkaNIjQ+nsznJ/ldioiIiNQQCl3VIDQ2loQf/5j8DxZzaMUKv8sRERGRGkChq5okDB9GaEIC+55/3u9SREREpAYIKHSZ2QAz22hmW8zswQo+v8vM1pjZSjP7yMw6lvnsodL1NppZ/2AWX5OFxMSQeMcd5H/8CYeWLPG7HBEREfHZaUOXmYUCU4BrgY7A0LKhqtRrzrkuzrnuwO+AZ0rX7QgMAToBA4CppdurFxoNHUJo4yQyJz2Pc87vckRERMRHgZzp6g1scc5tc84dBeYCA8sOcM4dLDMbAxxPGAOBuc65I865L4AtpdurF0Kio0kafSeHlizh0P/+53c5IiIi4qOwAMY0B3aUmc8A+pQfZGY/BX4GRABXlVm3bNrIKF1Wft3RwGiA5ORk0tPTAyiravLy8jzZD02TSWrUiC2//BU5P78fzKp/nzWQZ/0WQP32g3ruLfXbW+p3cAQSuipKCd+6VuacmwJMMbNhwCPAqDNYdxowDSA1NdWlpaUFUFbVpKen48V+AHKystj92OOkhoURe9llnuyzpvGy36J++0E995b67S31OzgCubyYAbQsM98C2HWK8XOBG85y3TrpnMGDCW/enMznJuneLhERkXoqkNC1BGhrZq3NLIKSG+MXlB1gZm3LzF4HbC6dXgAMMbNIM2sNtAU+q3rZtYtFRJA05m4KPv+cvEXpfpcjIiIiPjht6HLOHQPuAd4F1gPznHNrzewJM7u+dNg9ZrbWzFZScl/XqNJ11wLzgHXAO/9/e/cdHlWV/3H8fdLLTArphVAUEAFFQQQEEhKqS1EQ0F1RmoJ0RVY6CgiiAtJLqIqKASzoWtYFKRbEtr8FZRGkhoSQTnqZnN8fE9iIIAGSucnk+3oenmfKvXM/c54w851zzj0XGKW1tlTC+6jyvHv1wjkiguSlS9ElJUbHEUIIIYSNlWdOF1rrj4GPL3tsRpnb4/5k3xeBF280oL1Qzs4EjBpJwnOTyPr8X3h17WJ0JCGEEELYkKxIb0NePXrgUq8eKcuWoi01ssNPCCGEqLGk6LIh5eiI/+hRFBw9xoVPPzU6jhBCCCFsSIouG/Pq3h3XBg1IWbYcXVxsdBwhhBBC2IgUXTamHBzwHzOawhMnyPzoI6PjCCGEEMJGpOgygLlTJ1wbNyZlxUp0UZHRcYQQQghhA1J0GUA5OBAwZgxFp0+T+cEHRscRQgghhA1I0WUQU8co3O64w9rbVVhodBwhhBBCVDIpugyilLL2diUkkLF9u9FxhBBCCFHJpOgykGe7+3C/6y5SVq2mpKDA6DhCCCGEqERSdBlIKUXAuLEUJyWR8U6c0XGEEEIIUYmk6DKYZ+vWeLRqRcqaNZTk5RkdRwghhBCVRIquKiBg7BgsKSmkv73F6ChCCCGEqCRSdFUBHi1b4tm2LamxsZTk5BgdRwghhBCVQIquKiJg7Bgs6emkbX7T6ChCCCGEqARSdFUR7s2b4xnZgdT167FkZxsdRwghhBAVTIquKiRgzFhKMjNJ27TJ6ChCCCGEqGBSdFUh7k2bYOoUQ9rGTVgyM42OI4QQQogKJEVXFRMwZgwlWVmkbthgdBQhhBBCVCApuqoYt0aNMHfrRvrrb1Ccnm50HCGEEEJUECm6qqCA0aMoycsjbd06o6MIIYQQooJI0VUFud56K149epD25lsUp6QYHUcIIYQQFUCKrirKf+RT6IICUmPXGh1FCCGEEBVAiq4qyrVePbx79yZ9yxaKks4bHUcIIYQQN0mKrirMf9RItMVC6urVRkcRQgghxE2SoqsKcwkPx6dPHzK2bqUoIcEpZ9HeAAAgAElEQVToOEIIIYS4CVJ0VXH+I4YDkLJKeruEEEKI6kyKrirOOTQUn379yHj3XQrPnDE6jhBCCCFukBRd1YDf8OEoBwdSVqw0OooQQgghbpAUXdWAc1Agvo88TOYHH1B48qTRcYQQQghxA6Toqib8nngC5epKwrRpWDIyjI4jhBBCiOtUrqJLKdVNKXVEKXVMKTXpCs8/o5T6RSn1H6XUTqVUnTLPWZRS/y79t6Miw9ckTv7+hMx6gfz/+w8n+g+g4NgxoyMJIYQQ4jpcs+hSSjkCy4HuwO3AI0qp2y/b7Cegpdb6DmAb8HKZ5/K01s1L//WqoNw1knfPnkRs2kRJbi4nBzxM1q4vjI4khBBCiHIqT09XK+CY1vq41roQ2AL0LruB1voLrXVu6d39QHjFxhQXedx9F/W2xuFSpw7xo0aRsnoNWmujYwkhhBDiGspTdIUBZdcqiC997GqGAp+Uue+mlPpeKbVfKfXADWQUl3EOCaHOm5vx6t6d5EWLSJjwLCV5eUbHEkIIIcSfcCrHNuoKj12xa0Up9SjQEogs83CE1jpBKVUf2KWUOqi1/u2y/Z4EngQICgpi9+7d5cl+U7Kzs21ynErVswceLs7oD3aQeugQGU+NoMTX1+hUV2QX7V2NSHvbnrS5bUl725a0d8VQ1xqaUkq1AZ7XWnctvT8ZQGs977LtOgFLgUit9RWv0KyU2gh8pLXedrXjtWzZUn///ffX8x5uyO7du4mKiqr049hC1q4vSHj2WZSHB+FLluBx911GR/oDe2rv6kDa2/akzW1L2tu2pL2vTin1g9a6ZXm2Lc/w4ndAA6VUPaWUC/Aw8LuzEJVSdwGrgV5lCy6llK9SyrX0tj9wH/BL+d6GKC9zdEfqvrMFBw8PTj/+OBnb3zU6khDXrTA+nuQlSyhOSTE6ihBCVIprFl1a62JgNPAZcBiI01r/rJSapZS6eDbiK4AJ2HrZ0hCNge+VUv8HfAG8pLWWoqsSuDZoQL24d3Bv2YLEqVNJmjcPXVxsdCwhyqXo7FlOPfYYKStWcrxHTy58/LGcICKEsDvlmdOF1vpj4OPLHptR5nanq+z3NdDsZgKK8nP08SEiNpak+S+Ttul1Co4eI2zhAhx9fIyOJsRVFZ07x6lBgynJziHstUWkrt/A2WcmYP70M4JnzsDJz8/oiELUKCX5+eQfPkz+wUPk/3yIvEM/E5CUxK/OztYNVJmp3le6XfYhrrHt7/b73Y5//hrXeq3S13CJqENE7Jo/vkmDlKvoEtWHcnIieOoU3Bo1JPGFWZwYMIDaK1bgesstRkcT4g+Kzp/n9KDBWNLSiNiwHvc77sDcqROp6zeQsnQpx7/7juCZM/Hq1tXoqELYJV1URP6vv/6vwDp4iIKjR8FiAcAxwB/3ps3ICAvDLzzs9z3Qv7vNHx//XW+1LvP0FV7jSvtf9fbVXuuPr+EUGEhVIkWXnfJ56CFc6tcnfsxYTvYfQOirr2Du2NHoWEJcUpyWxukhQyg6f56ItWtxv+MOwPrDwf/JJzB3jCJh0mTOjh9P1v3dCZo+HacqenauENWBtlgoPH6cvIOHyD90iLxDhyj473/RhYUAOHp749a0KaaoSNybNcOtaVOcg4IA+G33boJlIv1Nk6LLjnncfTf1tsZxZvRo4keOIuCZp/EbNgylrrQKiBC2U5yezunBQyiKP0vtNauveMata4MG1H1nC6lr15G8fDk53x4g+PmZeHXubEBiIaoXrTVFp0+Td+gQ+QcPkXfoIPm/HEbnWtcxd/DwwK1JE3wffRT3pk1wa9YM5/Bw+X6oZFJ02Tnn0FDqvvkmCVOmkLxgIQVHfiVkzmwc3NyMjiZqKMuFC5wZOozCEyeovWolnq1aXXVb5eSE/4jhmDpGkTB5MmfHjCXrL38haNpU6fUSopTWmuJz5y4VWPmHDpH388+UZGYCoFxdcbvtNnz69MGtaRPcmzXDpV49lEO5Lr8sKpAUXTWAg7s7YQsXktroNpJfe43CEycIX74M5+Bgo6OJGsaSnc3pJ54g/+hRai9bimfbtuXaz61RI+q98w4pa9aQsnIVOd9+S8gLz2OOiankxParMD6ezPc/wO322zF1aI9ykq+D6qI4NdVaWJUZJrRcXGrFyQnXhg3w6tr1UoHleuutqIuT4IWh5H9ZDaGUwn/EcFwbNiDh2Ymc6NeP2kuX4t68udHRRA1RkpPDmeEjyP/5F8IXv4YpMvLaO5WhnJ0JGDUKc3Q0CZOnED9qNN69exE0ZQqO3t6VlNr+FCWdJ2XVSjK2bYeiIgCcgoPx6dsXn759cA4NNTihKMty4QL5P/9cpsA6SHFCovVJpXC5pT6mdu1wa9oU92ZNcW3USEYyqjApumoYc3Q0dd/ZwpmRozg18DGCX3gBnz4PGh1L2LmSvDzOjBxF3k8/EbZwwU31ULk1bky9uHdIWbWalNWryfn6G4JnvSAnilxDcVoaqWtiSX/7bbTFgk+/h/AfNoy8X34hI24rKStWkLJyJab27fHp3w9TZKT0ftlYSW6udamGi71YBw9SeOrUpeedIyLwaN4ct0cHWgusxrfjaPI0MLG4XvI/qgZybdCAunHvcPbpZ0icMoWCI0cInPisfMCKSlFSUED86DHkHjhA6Msv49Wt202/pnJxIWDsGEwx0SROnkL8UyPxfuABgqZMxtHLqwJS2w/LhQukbthA+qbXKcnPx7t3b/xHjcQlPBwA57AwvDp3pjD+LBnbt5G5bTvxo0bjFBiId98++PR9CJfwMIPfhf0pKSyk4MiR3xVYBb/9BiUlgLX30a1pE7wffNDai9W0iay5aAfkW7aGcvL1JSJ2TelCqpsoOFa6kKoM04gKpAsLOTt2HDlffUXIiy/i3bNHhb6+e5Mm1N1m7aVJjV1LzjffEDJ7FqYOHSr0ONVRSU4OaW9sJnX9ekouXMDcvRsBY8bgWr/+Fbd3CQ8jcNw4AkaNInvPHtLj4khdtZrUVavxbNcOn/79MEdFydygG1Scnk7Ovn3k/vijdbL7r79eGt519PXFrVlTzJ0749a0KW5Nm+BcxdaXEhVDiq4aTDk7EzxtKq6NGnJu1mxO9h9A+IrlspCqqBC6qIizEyaQvWcPwc8/j0/fPpVyHAcXFwLHj8cc04mEyZM48+RwvPv2IWjSJBzN5ko5ZlVWUlBAxpYtpKyJxZKaiikqioBxY3Fr3Lhc+ysnJ8wxMZhjYihKSCBj23Yytm/n7JixOAb449OnLz79HrrUUyaurvDMGbJ27iR75y5yf/wRLBYcTCbcmjbFb9DjuDWxzsNyCg2VpRpqCCm6BL79+uF6cSHVAQ8TtuDV657kLERZuriYhOeeI+vzfxE0dSq+Dw+o9GO6N2tKve3bSVm2nNR168j56mtC5szB1O6+Sj92VaCLisjY/i4pK1dSnJSER5vWBI5bdlMnyziHhhIwdgz+I58ie+8+MuLiSI2NJXXNGjzbtsWnf3/M0R2l96uULikh/+efLxVaBUePAtYpHX5PDMMcE4NbkyayVEMNJkWXAMCjRQvqbdvKmVGjOTPiKQInPEOtoUPl15e4btpiIXHqVC58/AmBEydSa+CjNju2g6srgROewdwphoTJUzgzbBg+/foR+NzfcTSZbJbDlrTFwoWPPiJ52XKKzpzBvXlzQufPx7P1vRV2DOXkhDm6I+bojhQlJpKx/V1r79e4cTj6++Pz4IPW3q+IiAo7ZnVRUlhI7v79ZO3aRfauLyg+fx4cHfFo0YKgyZMwRUfjUru20TFFFSFFl7jEupDqZhKmTOX8qwvIP/IrIbNnyenHotx0SQmJM2eS+cEOAsaPw2/oEENyuN95J/Xee5fkJUtI27CR7K++JHTOnHKvC1Yd6JISsv75OclLl1L422+43t6Y2qtX4dmhQ6X+WHIOCSFg9Cj8nxpB9r59ZMRtJXXdOlJjY/Fs26a09ysa5eJSaRmMZsnMJHvPHrJ27iJn3z5KcnNRHh6Y2rXDHBONZ4cOsnivuCIpusTvOHh4ELZoIam3NSL5tcX/W0i19PpbQlyN1pqkOXPI3LYd/5FP4T9ihKF5HFxdCZo4EXOnTiROnsLpIUPxeXgAgc9OrNan2Wutydm7l/OLF1Pwy2FcbrmFsNdew9yls02HrZSjI+aoKMxRURQlJZGxfTsZ27ZxdvzTONaqhU+fB63XgK1b12aZKlNh/Fmyd+0ka+cucr//HiwWHAP88erRA3NMNB6tW+Pg6mp0TFHFSdEl/sC6kOoIXBs0IGHi3znx0EPUXrYM9zvvNDqaTejCQnK//57sPXsBjd+IEfKr9Rq01px/aT7pb72N37Ch+I8ZY3SkSzzuuot6779H8muLSdu0iZx9XxLy4osVOvxmKzn7vyV58WLyfvoJ5/BwQl6ah3fPnihHR0NzOQcFETByJP7Dh5Pz9dfWuV8bNpK6dh0erVvj278fpk6dcKhGvV9aa/J//uVSoVVw5AgArg1uxW/oUMwx0bg1aybzs8R1kaJLXJU5JoY6W94m/uJCqrNewOeBB4yOVSmKks6Ts28v2Xv2kPPV19bhAhcXdEkJmf/4mOCZM+RCy1ehtSZ54SLSNm3C97GBBEyYUOXmAjq4uRE06TnMnTuRMGUKpwcNwvevfyVwwjM4eFb9Xq+8f/+b84sXk/vNfpyCgi6dDVrVJrArR0dM7dtjat+eovPnyXz3PTK2buXsMxNw9PXFu3Tul2u9ekZHvSJdWEjOtwfI2rXTOj8rKQkcHPC4+24Cn3sOc3RHXOrUMTqmqMak6BJ/yq1hQ+pujePs+KdJnDSZgv8eIfDZCdV+IVVtsZB/8CBZe/aQvWcPBb8cBqwLEnr17IkpsgOerVtTeOoUCVOmWi+0fH93gqZNw6lWLYPTVy0py5aTGhuLzyMPEzR5cpUruMryaNGC+u+/z/lFi0h/YzPZ+/YROvdFPO65x+hoV5R/+DDJi5eQvXs3jrVqETjpOXwfeaRaDGM5BwbiP2I4fk8+Qc7X35ARF0fa66+Ttn49Hq1aWed+de5k+HuxXLhA9p69ZO3aSc7efZTk5KDc3TG1uw9T9HhMUZHS0y0qTPX+5hQ24eTrS8TaWJJemk/axo3WhVQXvFrtFlK1ZGaS/eWX1t6sfV9iSU8HBwfc77qLgKefxhQViWvDhr8rGi5dciY21nqh5f3fEjxjBl7duhr4TqqOlNVrSFm+HO++fQiePr1KF1wXObi7EzxlCl6dO5MwZSqnBj6G78CBBD49HgcPD6PjAVBw/DjJS5eS9cmnOHh5ETB+PLUGPloteuUupxwcrAVMu/soTk4m4733ydi6lYRnn8XRxwfvBx7Ap3+/qy7aWhmKzp4la9cXZO3aSe5330NxMY7+/njd3x1TdDSebdrICUSiUkjRJcpFOTsTPH0arg0bcm72bE4OeJjwFStwrV81hwnAOuxVcPQo2aW9WXk//ds6+dXHB8/27TFFRmJqd981L62hnJ0JGDkSc0wnEidP5uz48Vzo2pXgGdNx8vOz0bupelI3bCR50SK8evUkZNasaje3xeOee6j/wfucX7CQ9DfeIHvvHkLnzsWjRQvDMhXGx5OyfAWZH3yAcnPD76kR+A0ebDeXNnIKCMD/ySfwGzaU3P37SY/bStrmzaRt3Ih7yxb4DhiAuUuXCu/90lqT/8svZO/6gqxduyg4bO3ZdqlfH7/BgzBFR+N+553V7m9YVD9SdInr4jugP6631Cd+7DhO9u9P2MIFVeqSKyV5eeTs328ttPbupTghEQDXxo3xe2IYpshI3O+444YmHrs1akjdd7aQum49KcuXc/zbbwmaPg2v+++vFj08FSlt85ucnz8fc7duhM6da/hE7hvl4OFB8PRpmDt3JnHqVE49OpBajz1GwPhxOLi72yxHUdJ5UlatJGPbdpRS1HrsMfyefMJuh7KVgwOebdvi2bYtxSkpZL7/PulxW0mY+Hcc5ryIzwO98enXD9dbb73hY+jCQnK++47snbvI+uILihMTQSnc776bwIkTMUV3rLJzy4T9kqJLXDePli2ptzWOM6PHcGb4CAKfnUCtIUMMKzwK4+PJ3r2H7L17yP32ALqgAOXhgWebNphGjMAUGVlhS14oZ2f8RwzHHBNNwtRpJEx4lqxPPyV4xgycAgIq5BhVXfo7cSTNmYOpUwxhr7xc7ef3AXi2vpf6Oz4g6dVXSdu0iew9ewiZNxePu+6q1OMWp6WRuiaW9LffRlss+DzUF/+nnqpRS7Q4+fvjN2wYtYYMIffAAevcr7feJm3T67jffTc+/fvh1a1buYb7LFlZZO/dS/bOXWTv3UtJdjbKzQ3P++7DPHo0po5RdlvIiuqh+n9aCkM4h4VZF1KdPIXzr7xK/pEjhMyebZNJsbqoiNwff7o0bFj422/WTHUi8BnQH1NkJB733FOpp6e7NmhA3bfeJG3jRpKXLOV4j54ETZuKV48edt3rlfHe+5x7/nk8IzsQtnBhlTt77mY4eHoSMnMmXl26kDB1Kqf+9ii1Bg0iYOyYCp/fY7lwgdQNG0jf9Dol+fl49+qF/+hRNfp6hsrBAc/WrfFs3ZqgtDQy33ufjLg4EidNJmnuPLx79cKnfz/cGjb83X5FiYlk7dxF9q5d5Hz3HRQV4VirFuauXTDHxFjnZ9mw11KIPyNFl7hhDh4ehL22iJSVK0lZspTCk6cIX7oU56DACj9WcUoK2Xv3lS7p8BUl2dng7IznPS2tawBFRtp8EUbl5ITfsGGYoqNJnDyFhIl/58LHnxD8/POV0gZGy/zoHyROnYpnmzaEL1lSrdZcuh6ebdpQf8cOzr/8Cmnr15O9ezeh8+ZWyDp1JTk5pL2xmdT16ym5cAFzt24EjBktF5m/jFOtWvgNHUKtIYPJPfAdGXFxZLzzDumbN+PevDnefR7E88ABji9ZcunMY5e6dan12EDMMTHW+VnVdMhb2DcpusRNUUoRMHKkdSHV5yZx8qGHCF+29Ka/oC5eONY6bLiX/IMHAXAKDMSrezc8O3TAs03bKrGyuGv9+tR5603SXn+D5Nde43jPngRNnoz3A73tptfrwmf/JOG55/Bo2ZLw5csMP82/sjmaTITMegFzly4kTp/OyUf+it/QIfiPHn1D772koICMLVtIWROLJTUVU1QUAePG4ta4cSWktx9KKTzvbYXnva0oTk8n8/0PyIiL49yMmXgqhUPz5gQ+OwFTdEyVPqlHiIuk6BIVwqtzZ1wi6hA/cuQNL6Rqycoi56uvrcOG+/ZhSUmxTny9804Cxo3FFBmJa+PGVbKQUY6O1rOgoiJJnDadxMmTufDpJ4S88ALOwcFGx7spWbt2cXbCBNzvvJPaK1fUqKEaU7v7rHO95s8nNXYtWV98Qei8ebg3a1au/XVRERnvvkfKypUUnzuHR5vWBIxdWulzxeyRk68vfoMHUWvQ4xQcPsyBY8fo0KuX0bGEuC5SdIkK49aoIXW3beXsuPHWhVR/PUrghGeu2s2vtabw+HFrb9aePeT++CMUF+Pg5YWpXTtMUZF4tm9frRYmdK1XjzpvvE765jc5v3Chda7XpOfw7tu3ShaL15K9bx9nx43H7fbbqb1mdbVcJ+pmOZrNhM6Zg1eXLiROn8HJhx/Bb9gw/EeNvOoQq7ZYuPDRRyQvW07RmTO4N29O6EsvVctLD1U1Sincbr+dkvPnjY4ixHWToktUKCdfXyLWrSVp3jzS1q+n4OhRwha8eun5kvx8cg8cuDRsWBQfD4Brw4b4DR6MKSrSOh+jGp8RpxwcqPXYQEyRHUicOo3EadO58MmnhMyehXNoqNHxyi3nm2+IHzUalwa3EhG7BkeTyehIhjJ16ED9D3eQNO8lUlevJnvXLkJemod7kyaXttElJWT983OSly6l8LffcG3cmPBVKzFFRlbLolsIUbGq7zebqLKUszPBM2bg2rAR5+bM4WT/Abi3uoczW94hZ/9+dH6+9TTuNm3wGzYUU4cO1aoYKS+XOnWIeH0T6W+/zfkFCznesxeBf/87Pv37Vfkv4NzvvuPMUyNxqVuXiHXrqt3VByqLo5cXofPmYu7ahXPTZ3Cy/wD8hz+J/4gRuBw8xInSid0u9esT9toizF26yIKbQohLpOgSlcb34QGXFlL1ittKQXg4Pn37YoqKxKNVK7ufjA2lvV5/+xumyEgSp07j3MyZZH32KcGzZuMSHmZ0vCvK/eknzgwfgXNYGBEb1ler4V1bMUdF4fHRhyTNnUvKipWkvfkWvpmZlISHE/LSPLx79pSz54QQfyBFl6hUHvfcwy2ffsLXn35Gu2rQw1NZXMLDidiwnoy4OM6//AonevUicOKz+AwYUKV6QvIOHuTME0/iFBBgLbhq8GWOrsXR25vQ+fMxd+1K+ttbSKwdTqtJk1B2upSGEOLmlevTXinVTSl1RCl1TCk16QrPP6OU+kUp9R+l1E6lVJ0yzz2ulDpa+u/xigwvqgdHb28sQYE1tuC6SDk44Pvww9T/cAfuzZtz7oVZnB40mMIzZ4yOBkD+4cOcHjoMRx8fIjZtxDnQ/tYaqwzm6GgiYteQ16GDFFxCiD91zaJLKeUILAe6A7cDjyilbr9ss5+AllrrO4BtwMul+9YCZgL3Aq2AmUopGasQNZpzWBi1160lePYs8n/+meO9epP2xmZ0SYlhmfJ//ZXTg4fgYPIkYuPGar/MhRBCVEXl6elqBRzTWh/XWhcCW4DeZTfQWn+htc4tvbsfuHgti67A51rrNK11OvA50K1iogtRfSml8O3Xj/offYhHy5Ykvfgipx97nMJTp2yepeD4cU4PHoJycaHOxo1Vdq6ZEEJUd+UpusKAsuMf8aWPXc1Q4JMb3FeIGsU5JITaa1YTMncu+UeOcLz3A6Ru3Ii2WGxy/MJTpzj9+CBQioiNG3GJiLDJcYUQoiZSWus/30CpfkBXrfWw0vsDgVZa6zFX2PZRYDQQqbUuUEpNBFy11nNKn58O5GqtF1y235PAkwBBQUEttmzZcvPv7Bqys7Mx1fB1h2xJ2vvaHNIz8HrrTVwPHqKwfn0uPDYQyw0O85WnvR1SUqm1YAGqqIi0Z57GYofLdtiS/I3blrS3bUl7X13Hjh1/0Fq3LM+25Tl7MR6oXeZ+OJBw+UZKqU7AVEoLrjL7Rl227+7L99VarwHWALRs2VJHRUVdvkmF2717N7Y4jrCS9i4f/UBvLuzYwbm583Cd9xIBY8dSa9Dj1738wLXauygxkVOzB2IpKaHO5jdoctttN5lcyN+4bUl725a0d8Uoz/Did0ADpVQ9pZQL8DCwo+wGSqm7gNVAL6112WszfAZ0UUr5lk6g71L6mBDiCpRSePfuTf0Pd+DZrh3nX3mFU3/9GwW//VZhxyhKOs+pQYOwZGYSsXYtblJwCSGETVyz6NJaF2MdMvwMOAzEaa1/VkrNUkpdvNroK4AJ2KqU+rdSakfpvmnAbKyF23fArNLHhBB/wjkwkPBlSwl99VUKT57kxIN9SImNRRcX39TrFqekcHrwYCzJKUSsjcW9WdMKSiyEEOJayrU4qtb6Y+Djyx6bUeZ2pz/Zdz2w/kYDClFTKaXw7vEXPFvfy7kXZpG8YCFZ//yckBfn4Naw4XW/XnF6OqcHD6EoMZGI2DW4N29eCamFEEJcTdVZClsIcUVO/v6ELVlM2KKFFMXHc7LvQ6SsWoUuKir3a1gyMzk9ZCiFp09Te8VyPFqWa86nEEKICiRFlxDVgFIKr+7dqf+PjzB1iiH5tcWcHPAw+UeOXHNfS1YWp4c9QeGxY4QvW4pnmzY2SCyEEOJyUnQJUY041apF+KJFhC1eTFFSEice6kfysuXowsIrbm/JzuHMk8PJP3yYsMWLMbVvb+PEQgghLpKiS4hqyKtrF+p/9CFeXbuSsmwZJ/oPIP/w4d9tU5KXR/xTT5H3n/8QtmAB5uiOBqUVQggBUnQJUW05+foS9uorhC9fRnFqCif69Sd5yRJrr1dREfGjRpH7ww+Ezp+PV9cuRscVQogar1xnLwohqi5zTAweLVqQNO8lUlasJOvzf+Hj6EDOkV8JmTsX7x5/MTqiEEIIpKdLCLvg6OND6PyXCF+5AktmJq7/PULwC8/j8+ADRkcTQghRSnq6hLAj5o4d8WjZkm/ee4/G/fsbHUcIIUQZ0tMlhJ1xNJspjogwOoYQQojLSNElhBBCCGEDUnQJIYQQQtiAFF1CCCGEEDYgRZcQQgghhA1I0SWEEEIIYQNKa210ht9RSiUDp2xwqAjgtA2OI6ykvW1L2tv2pM1tS9rbtqS9r66O1jqgPBtWuaLLVpRSyeVtJHHzpL1tS9rb9qTNbUva27akvStGTR5ezDA6QA0j7W1b0t62J21uW9LetiXtXQFqctGVaXSAGkba27akvW1P2ty2pL1tS9q7AtTkomuN0QFqGGlv25L2tj1pc9uS9rYtae8KUGPndAkhhBBC2FJN7ukSQgghhLAZuy66lFJORmeoSZRSjkZnqEmUUl5GZ6hplFIhSqkQo3PUFEopT6Mz1BRKKWV0hprALosupZSTUupVYIFSqpPReexdaXvPBeYqpTobnacmUEqNAvYopVqU3pcPzEqklHIo/Rv/FmimlHIxOpM9K/OZ8p5S6gmlVB2jM9UA7hdvyOdJ5bG7oqv0j2UJEAIcAJ5TSo1SSrkam8w+KaUigR8AX+Ao8KJSqq2xqexXmQ9DM5ALPAmgZXJmZRsI3AY001r/U2tdaHQge6WU8gXeAnyARcCDQCNDQ9kxpVSMUupLYLlS6lGQz5PKZI/Db2agOdBVa52llEoB7gf6AZsNTWafSoBXtdZvACilmgG9gK8NTWWntNZaKeUABAGrgPZKqb9prd9USjlqrS0GR7Q7pYVuA2CJ1jpTKdUSKACOSPFVKUxAXa11fwClVD+D89gtpVQtYA6wAOyIkK4AAANeSURBVEgFximl6mmtZyulHLTWJcYmtD92V3RprS8opU4Cg4ClwFdYe73aKKX+pbU+Z2A8e/QDcKDMF/5+4C6DM9mtix+EpT8mcoAvgJ5KqX3ABWQBwwpXWuj6A31Kf1Q8BpwAUpRSr2itTxib0L5orc8opXKVUhuBcKAu4KeUagq8JZ/hN6f0RxulBVUocBB4T2ttUUrFA/uVUmu11olKKSW9XhXL7oYXS70HNFdKhWits7H+URViLb5EBdJa52qtC8r0sHRFrs9Vacr88mwGfAZ8CtyO9cdFU5mLUWmWAy2AJlrre4C/Y+0ZGGFoKvvVD2tveYLW+lZgIRAM9DE0VTWnlBoMxAOzSx/KBtoA/gBa66PAm8AyQwLWAPZadH2J9QNxEIDW+gfgHspMFBQVSynlWGbY65PSx5rIGaSV5v+AFcBurD1c/wV+kV+lleYo8CvQCkBrfRI4hfVzRlQwrXUy1h/KKaX395Q+VWBYqGpOKWUCegPzge5KqUalf8c/Aq+V2XQaEK6UaiCfJxXPLosurXUi8D7WP6x+Sqm6QD5QbGQuO1cCOGP9kLxDKfUh8CxS6FYWByAQGKu17oD1g3OYsZHsl9Y6H5gEOCql+iqlGgOPYC14ReU4hvXLv7VSKhC4F8gzOFO1VTrqM1ZrvRj4J//r7RoJxCil2pTez8H6oy7f9intn12vSK+U6o61m7otsExrLV2mlUgp1RrrkMDXwAat9TqDI9ktpZS71jqv9LYCArXWSQbHsntKqXZANNADiNVaxxocyW4ppdyAp4CeWH9gLNFay6VoKoBSKhjYAbygtf5H6RI09wPbgIjS29211mkGxrRLdl10ASilnLHOhZVerkqmlArHemr9Qq21DAPYgFLKSf62bU/OFLUdpVQ9IF5rXWR0FnuilBoOPKq1bl96vzvQEQgDJmmtzxiZz17ZfdElhBBCiP8pcxb0NuAc1ukha4GDMo+rctnlnC4hhBBCXFlpweWBddh2AHBMa/0fKbgqn5xZJoQQQtQ8I7GegNNZpoPYjgwvCiGEEDWMrDhvDCm6hBBCCCFsQOZ0CSGEEELYgBRdQgghhBA2IEWXEEIIIYQNSNElhBBCCGEDUnQJIYQQQtiAFF1CCCGEEDYgRZcQQgghhA38PwA47SAE2LZqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d13dc3320>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Implementation on GSC dataset using subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(dataset):\n",
    "    \n",
    "    # Why do we have to process?  We do not needvindexes, we only need values.\n",
    "    #We are converting the dataset back to array \n",
    "    #for further processing them to binary form\n",
    "    data   = dataset.iloc[:133063,0:512]\n",
    "    labels = dataset.iloc[:133063,512]\n",
    "    #to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "    #processedData  = encodeData(data)\n",
    "    #processedLabel = encodeLabel(labels)\n",
    "    print (data)\n",
    "    print(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testData(dataset): \n",
    "    data = dataset.iloc[133063:,0:512] \n",
    "    labels = dataset.iloc[133063:,512]\n",
    "#to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "#processedData  = encodeData(data)\n",
    "#processedLabel = encodeLabel(labels)\n",
    "#print (data)\n",
    "#print(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "input_size = 512\n",
    "drop_out = 0.2\n",
    "first_dense_layer_nodes  = 512\n",
    "second_dense_layer = 512\n",
    "second_dense_layer_nodes = 1\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    # Why do we need a model? A model is a core data  srtucture in keras and used to organize layers.\n",
    "    # Why use Dense layer and then activation? We need to tell the system how the model is by specifying input and dense layer size,\n",
    "    #after specifying we apply activation.\n",
    "    # Why use sequential model with layers? sequential model is a linear way of stacking layers, \n",
    "    #where a layer connects just to the next layer. Here we have a fixed souce of input and output.\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    #relu always gives value such that if x<0 it will give 0 otherwise it will give the number itself\n",
    "    #activation function are used to map input to output\n",
    "    \n",
    "    # Why dropout? WE used dropout to avoid overfitting of model\n",
    "    #model.add(Dropout(drop_out))\n",
    "    #model.add(Dense(second_dense_layer))\n",
    "    #model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    # Why Softmax?\n",
    "    # softmax is an activation function used when we are doing classification \n",
    "    #and softmax will give probabilities of various classes involved\n",
    "    model.summary()\n",
    "    \n",
    "    # Why use categorical_crossentropy? We use categorial cross entropy when the target is in categorical format\n",
    "    # Here we are distribuiting the number in 4 categories, thus using categorical crossentropy\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # optimizer allows the internal learnable parameter (weights)to get adjusted.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 263,169\n",
      "Trainable params: 263,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0  1  1.1  0.1  0.2  0.3  0.4  0.5  0.6  0.7  ...    0.360  0.361  \\\n",
      "0       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1       0  1    1    0    0    0    0    0    0    0  ...        1      0   \n",
      "2       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "3       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "4       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "5       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "6       1  0    1    0    1    0    1    0    1    0  ...        0      0   \n",
      "7       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "8       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "9       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "10      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "11      0  1    0    0    1    0    0    0    0    0  ...        0      0   \n",
      "12      0  0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "13      1  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "14      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "15      0  0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "16      0  1    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "17      1  1    1    0    0    0    1    1    1    0  ...        0      0   \n",
      "18      0  1    1    0    0    0    0    1    1    0  ...        0      0   \n",
      "19      0  0    0    0    0    0    1    0    0    0  ...        0      0   \n",
      "20      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "21      1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "22      0  0    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "23      1  0    1    0    1    0    0    0    0    0  ...        0      0   \n",
      "24      0  0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "25      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "26      1  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "27      0  1    1    0    0    0    0    0    1    0  ...        0      0   \n",
      "28      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "29      0  1    1    0    1    0    0    1    0    0  ...        0      0   \n",
      "...    .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...    ...   \n",
      "143032  1  1    1    0    1    0    0    1    1    0  ...        1      0   \n",
      "143033  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143034  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143035  0  1    1    0    0    0    0    0    1    0  ...        0      0   \n",
      "143036  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143037  0  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143038  0  0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "143039  1  1    0    0    0    0    0    1    0    0  ...        0      0   \n",
      "143040  0  1    0    0    0    0    0    0    0    0  ...        1      0   \n",
      "143041  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143042  0  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143043  0  1    0    0    1    0    0    0    0    0  ...        0      0   \n",
      "143044  0  0    0    1    1    1    1    0    0    0  ...        0      0   \n",
      "143045  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143046  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143047  1  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143048  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143049  1  0    1    0    1    0    0    0    1    0  ...        0      0   \n",
      "143050  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143051  0  0    0    0    1    0    0    0    0    0  ...        1      0   \n",
      "143052  0  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143053  0  1    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "143054  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143055  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143056  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143057  0  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143058  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143059  0  0    0    0    0    0    0    0    0    0  ...        1      0   \n",
      "143060  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "143061  0  1    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "\n",
      "        0.362  0.363  0.364  0.365  0.366  0.367  0.368  1.143  \n",
      "0           0      0      0      0      0      0      0      1  \n",
      "1           0      0      0      0      0      0      0      1  \n",
      "2           0      0      0      0      0      0      0      1  \n",
      "3           0      0      0      0      0      0      0      1  \n",
      "4           0      0      0      0      0      0      0      0  \n",
      "5           0      0      0      0      0      0      0      1  \n",
      "6           0      0      0      0      0      0      0      1  \n",
      "7           0      0      0      0      0      0      0      1  \n",
      "8           0      0      0      0      0      0      0      0  \n",
      "9           0      0      0      0      0      0      0      1  \n",
      "10          0      0      0      0      0      0      0      0  \n",
      "11          0      0      0      0      0      0      0      1  \n",
      "12          0      0      0      0      0      0      0      0  \n",
      "13          0      0      0      0      0      0      0      1  \n",
      "14          0      0      0      0      0      0      0      0  \n",
      "15          0      0      0      0      0      0      0      1  \n",
      "16          0      0      0      0      0      0      0      0  \n",
      "17          0      0      0      0      0      0      0      0  \n",
      "18          0      0      0      0      0      0      0      0  \n",
      "19          0      0      0      0      0      0      0      1  \n",
      "20          0      0      0      0      0      0      0      1  \n",
      "21          0      0      0      0      0      0      0      1  \n",
      "22          0      0      0      0      0      0      0      0  \n",
      "23          0      0      0      0      0      0      0      0  \n",
      "24          0      0      0      0      0      0      0      1  \n",
      "25          0      0      0      0      0      0      0      1  \n",
      "26          0      0      0      0      0      0      0      0  \n",
      "27          0      0      0      0      0      0      0      1  \n",
      "28          0      0      0      0      0      0      0      1  \n",
      "29          0      0      0      0      0      0      0      1  \n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "143032      0      0      0      0      0      0      0      0  \n",
      "143033      0      0      0      0      0      0      0      1  \n",
      "143034      0      0      0      0      0      0      0      1  \n",
      "143035      0      0      0      0      0      0      0      1  \n",
      "143036      0      0      0      0      0      0      0      0  \n",
      "143037      0      0      0      0      0      0      0      1  \n",
      "143038      0      0      0      0      0      0      0      0  \n",
      "143039      0      0      0      0      0      0      0      1  \n",
      "143040      0      0      0      0      0      0      0      1  \n",
      "143041      0      0      0      0      0      0      0      1  \n",
      "143042      0      0      0      0      0      0      0      0  \n",
      "143043      0      0      0      0      0      0      0      0  \n",
      "143044      0      0      0      0      0      0      0      1  \n",
      "143045      0      0      0      0      0      0      0      1  \n",
      "143046      0      0      0      0      0      0      0      0  \n",
      "143047      0      0      0      0      0      0      0      0  \n",
      "143048      0      0      0      0      0      0      0      1  \n",
      "143049      0      0      0      0      0      0      0      0  \n",
      "143050      0      0      0      0      0      0      0      1  \n",
      "143051      0      0      0      0      0      0      0      1  \n",
      "143052      0      0      0      0      0      0      0      1  \n",
      "143053      0      0      0      0      0      0      0      0  \n",
      "143054      0      0      0      0      0      0      0      1  \n",
      "143055      0      0      0      0      0      0      0      1  \n",
      "143056      0      0      0      0      0      0      0      0  \n",
      "143057      0      0      0      0      0      0      0      1  \n",
      "143058      0      0      0      0      0      0      0      0  \n",
      "143059      0      0      0      0      0      0      0      0  \n",
      "143060      0      0      0      0      0      0      0      0  \n",
      "143061      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[143062 rows x 513 columns]\n",
      "        0  1  1.1  0.1  0.2  0.3  0.4  0.5  0.6  0.7  ...    0.359  0.360  \\\n",
      "0       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1       0  1    1    0    0    0    0    0    0    0  ...        0      1   \n",
      "2       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "3       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "4       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "5       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "6       1  0    1    0    1    0    1    0    1    0  ...        0      0   \n",
      "7       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "8       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "9       0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "10      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "11      0  1    0    0    1    0    0    0    0    0  ...        0      0   \n",
      "12      0  0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "13      1  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "14      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "15      0  0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "16      0  1    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "17      1  1    1    0    0    0    1    1    1    0  ...        0      0   \n",
      "18      0  1    1    0    0    0    0    1    1    0  ...        0      0   \n",
      "19      0  0    0    0    0    0    1    0    0    0  ...        0      0   \n",
      "20      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "21      1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "22      0  0    1    0    0    0    0    1    0    0  ...        0      0   \n",
      "23      1  0    1    0    1    0    0    0    0    0  ...        0      0   \n",
      "24      0  0    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "25      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "26      1  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "27      0  1    1    0    0    0    0    0    1    0  ...        0      0   \n",
      "28      0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "29      0  1    1    0    1    0    0    1    0    0  ...        0      0   \n",
      "...    .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...    ...   \n",
      "133033  1  1    1    0    0    0    1    1    1    0  ...        0      0   \n",
      "133034  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133035  1  1    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "133036  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133037  1  1    0    0    0    0    0    1    0    0  ...        0      0   \n",
      "133038  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133039  1  0    0    0    0    0    0    1    1    0  ...        0      0   \n",
      "133040  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133041  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133042  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133043  0  0    0    0    0    0    0    0    0    0  ...        0      1   \n",
      "133044  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133045  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133046  0  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133047  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133048  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133049  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133050  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133051  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133052  0  1    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "133053  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133054  1  1    1    0    0    0    1    1    0    0  ...        0      0   \n",
      "133055  0  1    0    0    0    0    0    0    1    0  ...        0      0   \n",
      "133056  0  1    1    0    0    0    0    0    0    0  ...        1      0   \n",
      "133057  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133058  0  1    1    0    0    0    0    0    0    0  ...        0      0   \n",
      "133059  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "133060  0  0    0    0    0    0    0    0    0    0  ...        1      0   \n",
      "133061  1  0    0    1    1    0    1    0    0    0  ...        0      0   \n",
      "133062  0  1    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "\n",
      "        0.361  0.362  0.363  0.364  0.365  0.366  0.367  0.368  \n",
      "0           0      0      0      0      0      0      0      0  \n",
      "1           0      0      0      0      0      0      0      0  \n",
      "2           0      0      0      0      0      0      0      0  \n",
      "3           0      0      0      0      0      0      0      0  \n",
      "4           0      0      0      0      0      0      0      0  \n",
      "5           0      0      0      0      0      0      0      0  \n",
      "6           0      0      0      0      0      0      0      0  \n",
      "7           0      0      0      0      0      0      0      0  \n",
      "8           0      0      0      0      0      0      0      0  \n",
      "9           0      0      0      0      0      0      0      0  \n",
      "10          0      0      0      0      0      0      0      0  \n",
      "11          0      0      0      0      0      0      0      0  \n",
      "12          0      0      0      0      0      0      0      0  \n",
      "13          0      0      0      0      0      0      0      0  \n",
      "14          0      0      0      0      0      0      0      0  \n",
      "15          0      0      0      0      0      0      0      0  \n",
      "16          0      0      0      0      0      0      0      0  \n",
      "17          0      0      0      0      0      0      0      0  \n",
      "18          0      0      0      0      0      0      0      0  \n",
      "19          0      0      0      0      0      0      0      0  \n",
      "20          0      0      0      0      0      0      0      0  \n",
      "21          0      0      0      0      0      0      0      0  \n",
      "22          0      0      0      0      0      0      0      0  \n",
      "23          0      0      0      0      0      0      0      0  \n",
      "24          0      0      0      0      0      0      0      0  \n",
      "25          0      0      0      0      0      0      0      0  \n",
      "26          0      0      0      0      0      0      0      0  \n",
      "27          0      0      0      0      0      0      0      0  \n",
      "28          0      0      0      0      0      0      0      0  \n",
      "29          0      0      0      0      0      0      0      0  \n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "133033      0      0      0      0      0      0      0      0  \n",
      "133034      0      0      0      0      0      0      0      0  \n",
      "133035      0      0      0      0      0      0      0      0  \n",
      "133036      0      0      0      0      0      0      0      0  \n",
      "133037      0      0      0      0      0      0      0      0  \n",
      "133038      0      0      0      0      0      0      0      0  \n",
      "133039      0      0      0      0      0      0      0      0  \n",
      "133040      0      0      0      0      0      0      0      0  \n",
      "133041      0      0      0      0      0      0      0      0  \n",
      "133042      0      0      0      0      0      0      0      0  \n",
      "133043      0      0      0      0      0      0      0      0  \n",
      "133044      0      0      0      0      0      0      0      0  \n",
      "133045      0      0      0      0      0      0      0      0  \n",
      "133046      0      0      0      0      0      0      0      0  \n",
      "133047      0      0      0      0      0      0      0      0  \n",
      "133048      0      0      0      0      0      0      0      0  \n",
      "133049      0      0      0      0      0      0      0      0  \n",
      "133050      0      0      0      0      0      0      0      0  \n",
      "133051      0      0      0      0      0      0      0      0  \n",
      "133052      0      0      0      0      0      0      0      0  \n",
      "133053      0      0      0      0      0      0      0      0  \n",
      "133054      0      0      0      0      0      0      0      0  \n",
      "133055      0      0      0      0      0      0      0      0  \n",
      "133056      0      0      0      0      0      0      0      0  \n",
      "133057      0      0      0      0      0      0      0      0  \n",
      "133058      0      0      0      0      0      0      0      0  \n",
      "133059      0      0      0      0      0      0      0      0  \n",
      "133060      0      0      0      0      0      0      0      0  \n",
      "133061      0      0      0      0      0      0      0      0  \n",
      "133062      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[133063 rows x 512 columns]\n",
      "0         1\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         0\n",
      "5         1\n",
      "6         1\n",
      "7         1\n",
      "8         0\n",
      "9         1\n",
      "10        0\n",
      "11        1\n",
      "12        0\n",
      "13        1\n",
      "14        0\n",
      "15        1\n",
      "16        0\n",
      "17        0\n",
      "18        0\n",
      "19        1\n",
      "20        1\n",
      "21        1\n",
      "22        0\n",
      "23        0\n",
      "24        1\n",
      "25        1\n",
      "26        0\n",
      "27        1\n",
      "28        1\n",
      "29        1\n",
      "         ..\n",
      "133033    1\n",
      "133034    1\n",
      "133035    1\n",
      "133036    1\n",
      "133037    1\n",
      "133038    0\n",
      "133039    1\n",
      "133040    1\n",
      "133041    0\n",
      "133042    1\n",
      "133043    0\n",
      "133044    1\n",
      "133045    0\n",
      "133046    1\n",
      "133047    0\n",
      "133048    0\n",
      "133049    0\n",
      "133050    0\n",
      "133051    0\n",
      "133052    1\n",
      "133053    1\n",
      "133054    1\n",
      "133055    0\n",
      "133056    0\n",
      "133057    1\n",
      "133058    0\n",
      "133059    1\n",
      "133060    0\n",
      "133061    1\n",
      "133062    0\n",
      "Name: 1.143, Length: 133063, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 106450 samples, validate on 26613 samples\n",
      "Epoch 1/50\n",
      "106450/106450 [==============================] - 6s 60us/step - loss: 0.4753 - acc: 0.7710 - val_loss: 0.4491 - val_acc: 0.7899\n",
      "Epoch 2/50\n",
      "106450/106450 [==============================] - 6s 54us/step - loss: 0.3706 - acc: 0.8349 - val_loss: 0.3744 - val_acc: 0.8308\n",
      "Epoch 3/50\n",
      "106450/106450 [==============================] - 6s 57us/step - loss: 0.3130 - acc: 0.8654 - val_loss: 0.4041 - val_acc: 0.8205\n",
      "Epoch 4/50\n",
      "106450/106450 [==============================] - 5s 52us/step - loss: 0.2654 - acc: 0.8896 - val_loss: 0.3614 - val_acc: 0.8475\n",
      "Epoch 5/50\n",
      "106450/106450 [==============================] - 6s 54us/step - loss: 0.2230 - acc: 0.9097 - val_loss: 0.3718 - val_acc: 0.8436\n",
      "Epoch 6/50\n",
      "106450/106450 [==============================] - 6s 54us/step - loss: 0.1852 - acc: 0.9269 - val_loss: 0.3634 - val_acc: 0.8536\n",
      "Epoch 7/50\n",
      "106450/106450 [==============================] - 6s 55us/step - loss: 0.1493 - acc: 0.9432 - val_loss: 0.3995 - val_acc: 0.8520\n",
      "Epoch 8/50\n",
      "106450/106450 [==============================] - 6s 55us/step - loss: 0.1202 - acc: 0.9550 - val_loss: 0.4184 - val_acc: 0.8460\n",
      "Epoch 9/50\n",
      "106450/106450 [==============================] - 6s 57us/step - loss: 0.0942 - acc: 0.9662 - val_loss: 0.4241 - val_acc: 0.8545\n",
      "Epoch 10/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 0.0730 - acc: 0.9751 - val_loss: 0.4388 - val_acc: 0.8564\n",
      "Epoch 11/50\n",
      "106450/106450 [==============================] - 6s 57us/step - loss: 0.0553 - acc: 0.9822 - val_loss: 0.4669 - val_acc: 0.8552\n",
      "Epoch 12/50\n",
      "106450/106450 [==============================] - 6s 58us/step - loss: 0.0431 - acc: 0.9865 - val_loss: 0.5215 - val_acc: 0.8541\n",
      "Epoch 13/50\n",
      "106450/106450 [==============================] - 6s 58us/step - loss: 0.0317 - acc: 0.9906 - val_loss: 0.5350 - val_acc: 0.8571\n",
      "Epoch 14/50\n",
      "106450/106450 [==============================] - 6s 57us/step - loss: 0.0253 - acc: 0.9928 - val_loss: 0.7194 - val_acc: 0.8282\n",
      "Epoch 15/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 0.0197 - acc: 0.9947 - val_loss: 0.6135 - val_acc: 0.8554\n",
      "Epoch 16/50\n",
      "106450/106450 [==============================] - 6s 58us/step - loss: 0.0152 - acc: 0.9958 - val_loss: 0.6109 - val_acc: 0.8562\n",
      "Epoch 17/50\n",
      "106450/106450 [==============================] - 6s 59us/step - loss: 0.0130 - acc: 0.9963 - val_loss: 0.8573 - val_acc: 0.8380\n",
      "Epoch 18/50\n",
      "106450/106450 [==============================] - 6s 58us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.6781 - val_acc: 0.8588\n",
      "Epoch 19/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.6979 - val_acc: 0.8578\n",
      "Epoch 20/50\n",
      "106450/106450 [==============================] - 6s 61us/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.7213 - val_acc: 0.8580\n",
      "Epoch 21/50\n",
      "106450/106450 [==============================] - 5s 51us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.7522 - val_acc: 0.8566\n",
      "Epoch 22/50\n",
      "106450/106450 [==============================] - 5s 51us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.8045 - val_acc: 0.8563\n",
      "Epoch 23/50\n",
      "106450/106450 [==============================] - 5s 51us/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.8361 - val_acc: 0.8569\n",
      "Epoch 24/50\n",
      "106450/106450 [==============================] - 5s 49us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.8185 - val_acc: 0.8589\n",
      "Epoch 25/50\n",
      "106450/106450 [==============================] - 5s 50us/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.8435 - val_acc: 0.8560\n",
      "Epoch 26/50\n",
      "106450/106450 [==============================] - 6s 52us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.8554 - val_acc: 0.8597\n",
      "Epoch 27/50\n",
      "106450/106450 [==============================] - 5s 52us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.8818 - val_acc: 0.8589\n",
      "Epoch 28/50\n",
      "106450/106450 [==============================] - 5s 51us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.8902 - val_acc: 0.8597\n",
      "Epoch 29/50\n",
      "106450/106450 [==============================] - 5s 51us/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.9274 - val_acc: 0.8591\n",
      "Epoch 30/50\n",
      "106450/106450 [==============================] - 5s 51us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.9332 - val_acc: 0.8595\n",
      "Epoch 31/50\n",
      "106450/106450 [==============================] - 5s 52us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.9534 - val_acc: 0.8591\n",
      "Epoch 32/50\n",
      "106450/106450 [==============================] - 5s 52us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.9392 - val_acc: 0.8597\n",
      "Epoch 33/50\n",
      "106450/106450 [==============================] - 6s 52us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.9676 - val_acc: 0.8599\n",
      "Epoch 34/50\n",
      "106450/106450 [==============================] - 7s 62us/step - loss: 9.3535e-04 - acc: 0.9997 - val_loss: 0.9923 - val_acc: 0.8602\n",
      "Epoch 35/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 1.0055 - val_acc: 0.8597\n",
      "Epoch 36/50\n",
      "106450/106450 [==============================] - 6s 55us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.0473 - val_acc: 0.8606\n",
      "Epoch 37/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.0700 - val_acc: 0.8569\n",
      "Epoch 38/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.0549 - val_acc: 0.8586\n",
      "Epoch 39/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 1.0567 - val_acc: 0.8591\n",
      "Epoch 40/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 6.8986e-04 - acc: 0.9998 - val_loss: 1.0635 - val_acc: 0.8618\n",
      "Epoch 41/50\n",
      "106450/106450 [==============================] - 6s 54us/step - loss: 3.7068e-04 - acc: 0.9999 - val_loss: 1.0846 - val_acc: 0.8597\n",
      "Epoch 42/50\n",
      "106450/106450 [==============================] - 6s 57us/step - loss: 2.7353e-04 - acc: 0.9999 - val_loss: 1.1295 - val_acc: 0.8596\n",
      "Epoch 43/50\n",
      "106450/106450 [==============================] - 6s 52us/step - loss: 7.6127e-04 - acc: 0.9997 - val_loss: 1.0940 - val_acc: 0.8613\n",
      "Epoch 44/50\n",
      "106450/106450 [==============================] - 5s 52us/step - loss: 2.0083e-04 - acc: 0.9999 - val_loss: 1.1240 - val_acc: 0.8610\n",
      "Epoch 45/50\n",
      "106450/106450 [==============================] - 5s 51us/step - loss: 6.0916e-04 - acc: 0.9998 - val_loss: 1.1369 - val_acc: 0.8605\n",
      "Epoch 46/50\n",
      "106450/106450 [==============================] - 6s 52us/step - loss: 4.6423e-04 - acc: 0.9999 - val_loss: 1.1406 - val_acc: 0.8591\n",
      "Epoch 47/50\n",
      "106450/106450 [==============================] - 6s 52us/step - loss: 1.6497e-04 - acc: 1.0000 - val_loss: 1.1371 - val_acc: 0.8600\n",
      "Epoch 48/50\n",
      "106450/106450 [==============================] - 6s 56us/step - loss: 3.4142e-04 - acc: 0.9999 - val_loss: 1.1597 - val_acc: 0.8598\n",
      "Epoch 49/50\n",
      "106450/106450 [==============================] - 6s 59us/step - loss: 3.3378e-04 - acc: 0.9999 - val_loss: 1.1794 - val_acc: 0.8590\n",
      "Epoch 50/50\n",
      "106450/106450 [==============================] - 6s 52us/step - loss: 9.3096e-04 - acc: 0.9997 - val_loss: 1.1764 - val_acc: 0.8593\n"
     ]
    }
   ],
   "source": [
    "validation_data_split = 0.2\n",
    "num_epochs = 50\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 20\n",
    "early_patience = 100\n",
    "#tensorboard is used for visualization\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "#earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "#Early stopping happens when the quantity monitored stops increasing or decreasing\n",
    "# Read Dataset\n",
    "dataset = pd.read_csv('finalGSCsub.csv')\n",
    "print(dataset)\n",
    "# Process Dataset\n",
    "processedData, processedLabel = processData(dataset)\n",
    "history = model.fit(processedData\n",
    "                    , processedLabel\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb]\n",
    "                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest = pd.read_csv('finalGSCsub.csv')\n",
    "datatest1,datalabel = testData(datatest)\n",
    "#np.set_printoptions(precision=4, suppress=True)\n",
    "k,l = datatest1.shape\n",
    "print(k)\n",
    "eval_results = model.predict(datatest1)\n",
    "#print(\"\\nLoss, accuracy on test data: \")\n",
    "#print(\"%0.4f %0.2f%%\" % (eval_results[0], \\\n",
    " #eval_results[1]*100))\n",
    "\n",
    "for i in range(9999):\n",
    "    if(eval_results[i]>0.5):\n",
    "        eval_results[i] = 1\n",
    "    else:\n",
    "        eval_results[i] = 0\n",
    "        \n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.69\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(k):\n",
    "    if (eval_results[i] == datalabel[133063+i]):\n",
    "        correct = correct +1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "        \n",
    "print (correct/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1c37302908>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c389a74e0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c3898def0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c38953b00>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c392aae80>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Creation for human observed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import csv\\nimport pandas\\nimport numpy as np\\ndata1 = []\\nwith open ('same_pairs.csv') as csv_file:\\n    readCSV = csv.reader(csv_file, delimiter=',')\\n    for row in readCSV:\\n        data1.append(row)\\ndf1 = pandas.DataFrame(data = data1)        \\ndata2 = []        \\nwith open ('diffn_pairs.csv') as csvfile:\\n    readCSV = csv.reader(csvfile, delimiter=',')\\n    for row in readCSV:\\n        data2.append(row)\\ndf2 = pandas.DataFrame(data = data2)    \\ndata3 = []        \\nwith open ('HumanObserved-Features-Data.csv') as csvfile2:\\n    readCSV = csv.reader(csvfile2, delimiter=',')\\n    for row in readCSV:\\n        data3.append(row)\\ndf3 = pandas.DataFrame(data = data3)    \\n\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''import csv\n",
    "import pandas\n",
    "import numpy as np\n",
    "data1 = []\n",
    "with open ('same_pairs.csv') as csv_file:\n",
    "    readCSV = csv.reader(csv_file, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        data1.append(row)\n",
    "df1 = pandas.DataFrame(data = data1)        \n",
    "data2 = []        \n",
    "with open ('diffn_pairs.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        data2.append(row)\n",
    "df2 = pandas.DataFrame(data = data2)    \n",
    "data3 = []        \n",
    "with open ('HumanObserved-Features-Data.csv') as csvfile2:\n",
    "    readCSV = csv.reader(csvfile2, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        data3.append(row)\n",
    "df3 = pandas.DataFrame(data = data3)    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data4 = []\\ndata5 =[]\\nn,l = df1.shape\\nk,l = df3.shape\\n\\nfor i in range(n):\\n    for j in range(k):\\n        if(i==0):\\n            break\\n        if(data1[i][0] == data3[j][1]):\\n            break;\\n    data4.append(data3[j][2:11])\\nfor i in range(n):\\n    for j in range(k):\\n        if i ==0 :\\n            break\\n        if(data1[i][1] == data3[j][1]):\\n            break;\\n    data5.append(data3[j][2:11])'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data4 = []\n",
    "data5 =[]\n",
    "n,l = df1.shape\n",
    "k,l = df3.shape\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "        if(i==0):\n",
    "            break\n",
    "        if(data1[i][0] == data3[j][1]):\n",
    "            break;\n",
    "    data4.append(data3[j][2:11])\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "        if i ==0 :\n",
    "            break\n",
    "        if(data1[i][1] == data3[j][1]):\n",
    "            break;\n",
    "    data5.append(data3[j][2:11])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data6 = []\\ndata7 =[]\\nn,l = df2.shape\\nk,l = df3.shape\\n\\nfor i in range(n):\\n    for j in range(k):\\n        if(i==0):\\n            break\\n        if(data2[i][0] == data3[j][1]):\\n            break;\\n    data6.append(data3[j][2:11])\\nfor i in range(n):\\n    for j in range(k):\\n        if i ==0 :\\n            break\\n        if(data2[i][1] == data3[j][1]):\\n            break;\\n    data7.append(data3[j][2:11])'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data6 = []\n",
    "data7 =[]\n",
    "n,l = df2.shape\n",
    "k,l = df3.shape\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "        if(i==0):\n",
    "            break\n",
    "        if(data2[i][0] == data3[j][1]):\n",
    "            break;\n",
    "    data6.append(data3[j][2:11])\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "        if i ==0 :\n",
    "            break\n",
    "        if(data2[i][1] == data3[j][1]):\n",
    "            break;\n",
    "    data7.append(data3[j][2:11])'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df4 = pandas.DataFrame(data = data4)\\nm,t = df4.shape\\ndf6 = pandas.DataFrame(data = data6)\\nk,l = df6.shape\\ndatafinal = [[0 for i in range(t+10)]for j in range(m-1)]\\ndatafinal2 = [[0 for i in range(t+10)]for j in range(k-1)]\\nfor i in range(m-1):\\n    for j in range(t):\\n        datafinal[i][j] = data4[i+1][j]\\n        datafinal[i][j+9] = data5[i+1][j]\\n        datafinal[i][j+10] = data1[i+1][2]\\nfor i in range(k-1):\\n    for j in range(l):\\n        datafinal2[i][j] = data6[i+1][j]\\n        datafinal2[i][j+9] = data7[i+1][j]\\n        datafinal2[i][j+10] = data2[i+1][2]   \\nimport numpy as np\\n\\ndatafinal2 = np.asarray(datafinal2)\\n#f4 = pandas.DataFrame(data = datafinal)\\n#a, b =f4.shape\\n#a\\n\\nnp.random.shuffle(datafinal2)\\n\\nz = 2*m\\nprint (z)\\ndff = [[0 for i in range(t+10)]for j in range(z-1)]\\nfor i in range(m-1):\\n    for j in range(t+10):\\n        dff[i][j] = datafinal[i][j]\\n\\nfor i in range(m-1):\\n    for j in range(t+10):\\n        dff[m+i][j] = datafinal2[i][j]\\n        \\n        \\ndff = np.asarray(dff)\\nnp.random.shuffle(dff)\\n#k,l =dff.shape\\n#k\\ndffinal2 = pandas.DataFrame(data= dff)\\ndffinal2.to_csv('final1600.csv',header =0 , index =0)\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df4 = pandas.DataFrame(data = data4)\n",
    "m,t = df4.shape\n",
    "df6 = pandas.DataFrame(data = data6)\n",
    "k,l = df6.shape\n",
    "datafinal = [[0 for i in range(t+10)]for j in range(m-1)]\n",
    "datafinal2 = [[0 for i in range(t+10)]for j in range(k-1)]\n",
    "for i in range(m-1):\n",
    "    for j in range(t):\n",
    "        datafinal[i][j] = data4[i+1][j]\n",
    "        datafinal[i][j+9] = data5[i+1][j]\n",
    "        datafinal[i][j+10] = data1[i+1][2]\n",
    "for i in range(k-1):\n",
    "    for j in range(l):\n",
    "        datafinal2[i][j] = data6[i+1][j]\n",
    "        datafinal2[i][j+9] = data7[i+1][j]\n",
    "        datafinal2[i][j+10] = data2[i+1][2]   \n",
    "import numpy as np\n",
    "\n",
    "datafinal2 = np.asarray(datafinal2)\n",
    "#f4 = pandas.DataFrame(data = datafinal)\n",
    "#a, b =f4.shape\n",
    "#a\n",
    "\n",
    "np.random.shuffle(datafinal2)\n",
    "\n",
    "z = 2*m\n",
    "print (z)\n",
    "dff = [[0 for i in range(t+10)]for j in range(z-1)]\n",
    "for i in range(m-1):\n",
    "    for j in range(t+10):\n",
    "        dff[i][j] = datafinal[i][j]\n",
    "\n",
    "for i in range(m-1):\n",
    "    for j in range(t+10):\n",
    "        dff[m+i][j] = datafinal2[i][j]\n",
    "        \n",
    "        \n",
    "dff = np.asarray(dff)\n",
    "np.random.shuffle(dff)\n",
    "#k,l =dff.shape\n",
    "#k\n",
    "dffinal2 = pandas.DataFrame(data= dff)\n",
    "dffinal2.to_csv('final1600.csv',header =0 , index =0)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for creation of GSC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import csv\n",
    "import pandas\n",
    "import numpy as np\n",
    "data1 = []\n",
    "with open ('same_pairsGSC.csv') as csv_file:\n",
    "    readCSV = csv.reader(csv_file, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        data1.append(row)\n",
    "df1 = pandas.DataFrame(data = data1)  \n",
    "k,l = df1.shape\n",
    "print(k,l)\n",
    "data2 = []        \n",
    "with open ('diffn_pairsGSC.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        data2.append(row)\n",
    "df2 = pandas.DataFrame(data = data2)\n",
    "m,n =df2.shape\n",
    "print(m,n)\n",
    "data3 = []        \n",
    "with open ('GSC-Features.csv') as csvfile2:\n",
    "    readCSV = csv.reader(csvfile2, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        data3.append(row)\n",
    "df3 = pandas.DataFrame(data = data3)    \n",
    "df3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df = np.asarray(df2)\n",
    "#f4 = pandas.DataFrame(data = datafinal)\n",
    "#a, b =f4.shape\n",
    "#a\n",
    "\n",
    "np.random.shuffle(df)\n",
    "s,t = df.shape\n",
    "print(s,t)\n",
    "print(df)\n",
    "#df = pandas.DataFrame(data = df)\n",
    "#datafinal =[[ 0 for j in range(l)]for i in range(k)]\n",
    "#for i in range(k):\n",
    "#    for j in range(l):\n",
    "#        datafinal[i][j] = df[i][j]\n",
    " \n",
    "datafinal = df[:71532,:]\n",
    "\n",
    "dfk = pandas.DataFrame(data = datafinal)\n",
    "dfk.shape\n",
    "\n",
    "data4 = []\n",
    "data5 =[]\n",
    "n,l = df1.shape\n",
    "k,l = df3.shape\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "        if(i==0):\n",
    "            break\n",
    "        if(data1[i][0] == data3[j][0]):\n",
    "            break;\n",
    "    data4.append(data3[j][1:513])\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "        if i ==0 :\n",
    "            break\n",
    "        if(data1[i][1] == data3[j][0]):\n",
    "            break;\n",
    "    data5.append(data3[j][1:513])\n",
    "    \n",
    "data4\n",
    "\n",
    "df4 = pandas.DataFrame(data = data4)\n",
    "m,t = df4.shape\n",
    "df6 = pandas.DataFrame(data = data6)\n",
    "k,l = df6.shape\n",
    "print(k,l)\n",
    "dataf2 = [[0 for i in range(t+513)]for j in range(m-1)]\n",
    "datafinal2 = [[0 for i in range(l+513)]for j in range(k-1)]\n",
    "#datafinal2.shape\n",
    "for i in range(m-1):\n",
    "    for j in range(t):\n",
    "        dataf2[i][j] = data4[i+1][j]\n",
    "        dataf2[i][j+512] = data5[i+1][j]\n",
    "    dataf2[i][1024] = data1[i+1][2]\n",
    "for i in range(k-1):\n",
    "    for j in range(l):\n",
    "        datafinal2[i][j] = data6[i+1][j]\n",
    "        datafinal2[i][j+512] = data7[i+1][j]\n",
    "    datafinal2[i][1024] = data2[i+1][2]        \n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "datafinal2 = np.asarray(datafinal2)\n",
    "#f4 = pandas.DataFrame(data = datafinal)\n",
    "#a, b =f4.shape\n",
    "#a\n",
    "\n",
    "#np.random.shuffle(datafinal2)\n",
    "\n",
    "z = m + k\n",
    "print (z)\n",
    "dff = [[0 for i in range(1025)]for j in range(z)]\n",
    "for i in range(m-1):\n",
    "    for j in range(1025):\n",
    "        dff[i][j] = dataf2[i][j]\n",
    "\n",
    "for i in range(k-1):\n",
    "    for j in range(1025):\n",
    "        dff[m-1+i][j] = datafinal2[i][j]\n",
    "        \n",
    "        \n",
    "dff = np.asarray(dff)\n",
    "np.random.shuffle(dff)\n",
    "#k,l =dff.shape\n",
    "#k\n",
    "dffinal2 = pandas.DataFrame(data= dff)\n",
    "dffinal2.to_csv('finalGSC.csv',header =0 , index =0)\n",
    "\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
